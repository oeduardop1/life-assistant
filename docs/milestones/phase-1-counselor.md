# Fase 1: Conselheira (v1.x)

> **Objetivo:** Implementar a feature principal de ajudar o usu√°rio atrav√©s de chat com IA e mem√≥ria gerenciada pela IA (ADR-012).
> **Refer√™ncias:** `docs/specs/product.md` ¬ß2.1, ¬ß6.1, ¬ß6.2, `docs/specs/ai.md`, `docs/specs/system.md` ¬ß3.2, ¬ß3.6

---

## M1.1 ‚Äî Package: AI (LLM Abstraction + Tool Use) üü¢

**Objetivo:** Criar abstra√ß√£o de LLM com suporte a Tool Use (Function Calling).

**Refer√™ncias:** `docs/specs/engineering.md` ¬ß8, `docs/specs/ai.md` ¬ß2, `ADR-012`

**Tasks:**

- [x] Criar interface `LLMPort` conforme `docs/specs/engineering.md` ¬ß8.2:
  ```typescript
  interface LLMPort {
    chat(params: ChatParams): Promise<ChatResponse>;
    chatWithTools(params: ChatWithToolsParams): Promise<ChatWithToolsResponse>;
    stream(params: ChatParams): AsyncIterable<StreamChunk>;
    streamWithTools(params: ChatWithToolsParams): AsyncIterable<StreamChunk>;
    getInfo(): ProviderInfo;
  }
  ```
- [x] Criar `ToolDefinition` schema com Zod (incluir `inputExamples`)
- [x] **Implementar Tool Use Examples por provider:**
  - [x] Claude: usar campo `input_examples` com beta header `advanced-tool-use-2025-11-20`
  - [x] Gemini: criar m√©todo `enrichDescriptionWithExamples()` para workaround
  - [x] Adicionar exemplos para todas as 7 tools conforme `docs/specs/ai.md` ¬ß6.2
- [x] Implementar `GeminiAdapter` com suporte a Function Calling
- [x] Implementar `ClaudeAdapter` com suporte a Tool Use
- [x] Criar `LLMFactory` que retorna adapter baseado em ENV
- [x] Implementar rate limiting
- [x] Implementar retry com backoff exponencial
- [x] Criar `ToolExecutorService` (executa tools chamadas pela LLM)
- [x] Implementar tool loop com max iterations (5)
- [x] Testes para ambos adapters (incluindo Tool Use)
- [x] Criar `zod-to-gemini.ts` (conversor Zod ‚Üí Gemini Type)
- [x] Criar `examples-enricher.ts` (workaround inputExamples para Gemini)
- [x] Criar `message.schema.ts` (tipos Message, ChatParams, etc.)
- [x] Criar `ai.errors.ts` (erros customizados do m√≥dulo AI)

**Definition of Done:**
- [x] `LLM_PROVIDER=gemini` usa Gemini com Tool Use
- [x] `LLM_PROVIDER=claude` usa Claude com Tool Use
- [x] Streaming funciona
- [x] Tool calls s√£o retornados corretamente
- [x] Tool loop funciona (LLM ‚Üí tool ‚Üí LLM ‚Üí resposta)
- [x] **Tool Use Examples funcionam corretamente:**
  - [x] Claude recebe `input_examples` via API
  - [x] Gemini recebe description enriquecida com exemplos
  - [x] Todas as 7 tools t√™m 2-4 exemplos definidos
- [x] Rate limiting aplicado
- [x] Testes passam

**Notas (2025-01-12):**
- Package `@life-assistant/ai` implementado em `packages/ai/`
- Adapters: `GeminiAdapter` (Google GenAI SDK) e `ClaudeAdapter` (Anthropic SDK)
- Factory: `createLLM()` e `createLLMFromEnv()` para cria√ß√£o baseada em ENV vars
- Tool Use Examples: Claude usa beta header `advanced-tool-use-2025-11-20`, Gemini usa `enrichDescriptionWithExamples()`
- Rate limiting com token bucket algorithm
- Retry com backoff exponencial (1s, 2s, 4s)
- Tool loop com max 5 itera√ß√µes e suporte a confirma√ß√£o
- **Cobertura de testes: 162 testes passando**
  - adapters: claude.adapter.test.ts (21 testes), gemini.adapter.test.ts (26 testes)
  - services: tool-loop.service.test.ts (19 testes), tool-executor.service.test.ts (12 testes), llm.factory.test.ts (16 testes)
  - utils: rate-limiter.test.ts (14 testes), retry.test.ts (20 testes), zod-to-gemini.test.ts (23 testes), examples-enricher.test.ts (11 testes)

---

## M1.2 ‚Äî M√≥dulo: Chat B√°sico üü¢

**Objetivo:** Implementar chat com IA com streaming de resposta.

**Refer√™ncias:** `docs/specs/system.md` ¬ß3.2, `docs/specs/ai.md` ¬ß4

**Tasks:**

**Backend:**
- [x] Criar m√≥dulo `chat` com Clean Architecture:
  - [x] `ChatController` - endpoints REST + SSE
  - [x] `ChatService` - orquestra envio de mensagem e streaming
  - [x] `ConversationRepository` - CRUD de conversas
  - [x] `MessageRepository` - CRUD de mensagens
  - [x] `ContextBuilderService` - monta system prompt
- [x] Implementar endpoints REST:
  - [x] POST /chat/conversations - criar conversa
  - [x] GET /chat/conversations - listar conversas
  - [x] GET /chat/conversations/:id - detalhes da conversa
  - [x] GET /chat/conversations/:id/messages - hist√≥rico de mensagens
  - [x] POST /chat/conversations/:id/messages - enviar mensagem
  - [x] DELETE /chat/conversations/:id - soft delete (90 dias reten√ß√£o)
- [x] Implementar DTOs com class-validator
- [x] Implementar streaming via Server-Sent Events (SSE)
- [x] Implementar system prompt base conforme `docs/specs/ai.md` ¬ß4.1
- [ ] ~~Implementar rate limiting por plano~~ ‚Üí Migrado para **M3.6**
- [x] Salvar mensagens no banco
- [x] Implementar tipos de conversa: general, counselor
- [x] Implementar `@SkipTransform()` decorator para SSE
- [x] Implementar `SseAuthGuard` para autentica√ß√£o via query param

**Frontend:**
- [x] Criar p√°gina `/chat`:
  - [x] Lista de conversas (sidebar)
  - [x] √Årea de mensagens com scroll
  - [x] Input de mensagem
  - [x] Bot√£o enviar
- [x] Implementar streaming de resposta (SSE)
- [x] Implementar typing indicator
- [x] Implementar auto-scroll
- [x] Criar nova conversa
- [x] Hist√≥rico de conversas
- [x] Implementar empty state (sem conversas)
- [x] Implementar loading states
- [x] Implementar error handling (rate limit, LLM errors)
- [x] Adicionar link Chat no sidebar de navega√ß√£o
- [x] Persist√™ncia de conversa via URL (?c=conversationId)

**Testes:**
- [x] Testes unit√°rios:
  - [x] ChatService (streaming, error handling)
  - [x] ConversationRepository
  - [x] MessageRepository
  - [x] ContextBuilderService
- [x] Testes de integra√ß√£o:
  - [x] API de chat (CRUD + mensagens)
  - [ ] ~~Rate limiting~~ ‚Üí Migrado para **M3.6**
  - [x] SSE streaming
- [x] Testes E2E:
  - [x] Enviar mensagem e receber resposta com streaming
  - [x] Criar nova conversa
  - [x] Alternar entre conversas
  - [ ] ~~Rate limit error handling~~ ‚Üí Migrado para **M3.6**

**Definition of Done:**
- [x] Usu√°rio envia mensagem e recebe resposta com streaming
- [x] Hist√≥rico de conversa √© mantido
- [x] M√∫ltiplas conversas funcionam
- [x] Testes passam

**Notas (13 Janeiro 2026):**
- Chat funcional com streaming SSE via `@life-assistant/ai` package
- Autentica√ß√£o SSE via query param token (EventSource n√£o suporta headers)
- `@SkipTransform()` decorator criado para bypass do `TransformInterceptor` em SSE
- URL-based state: conversa persiste em refresh via `?c=conversationId`
- **Tasks de rate limiting migradas para M3.6 (Stripe/Pagamentos)** ‚Äî rate limiting depende de defini√ß√£o de planos de neg√≥cio (Free/Pro/Premium), que ser√° implementado junto com billing

---

## M1.3 ‚Äî Sistema de Mem√≥ria (Tool Use + Memory Consolidation) üü¢

**Objetivo:** Implementar sistema de mem√≥ria com Tool Use e consolida√ß√£o autom√°tica.

**Refer√™ncias:** `docs/specs/ai.md` ¬ß6-7, `docs/specs/data-model.md` ¬ß7, `ADR-012`

**Tasks:**

**Banco de Dados:**
- [x] Criar migration para tabela `user_memories`
- [x] Criar migration para tabela `knowledge_items`
- [x] Criar migration para tabela `memory_consolidations`
- [x] Criar enums: `knowledge_item_type`, `knowledge_item_source`, `consolidation_status`
- [x] Implementar RLS para novas tabelas

**Backend - Servi√ßos:**
- [x] Criar m√≥dulo `memory`:
  - [x] `UserMemoryService` - CRUD de perfil do usu√°rio
  - [x] `KnowledgeItemsService` - CRUD de knowledge items
  - [x] `MemoryConsolidationProcessor` - job de consolida√ß√£o (Processor pattern)
  - [x] `ContextBuilderService` - monta system prompt com mem√≥ria
- [x] Implementar `ContextBuilder`:
  - [x] Carregar user_memory (sempre presente, ~500-800 tokens)
  - [x] Montar se√ß√£o de mem√≥ria do system prompt
  - [x] Injetar tools dispon√≠veis no contexto

**Backend - Tools:**
- [x] Criar tool `search_knowledge`:
  - [x] Busca por texto em knowledge_items
  - [x] Filtros por √°rea, tipo, tags
  - [x] Ordena√ß√£o por relev√¢ncia/data
- [x] Criar tool `add_knowledge`:
  - [x] Adicionar novo fato/prefer√™ncia
  - [x] Validar com Zod
  - [x] Requer confirma√ß√£o do usu√°rio

**Backend - Tool Integration:**
- [x] Criar `MemoryToolExecutor` implementando interface `ToolExecutor`
- [x] Integrar `runToolLoop()` com `ChatService`
- [x] Handle de confirma√ß√£o de tools via SSE (event type: tool_confirmation)
- [x] Atualizar message metadata para armazenar tool calls e results

**Backend - Memory API Endpoints:**
- [x] GET /api/memory - Ver mem√≥ria do usu√°rio
- [x] GET /api/memory/knowledge - Listar knowledge items (paginado)
- [x] DELETE /api/memory/knowledge/:id - Deletar knowledge item

**Backend - Memory Consolidation Job:**
- [x] Criar job BullMQ `memory-consolidation`:
  - [x] Executa a cada 24h por usu√°rio (3:00 AM timezone local)
  - [x] Busca mensagens desde √∫ltima consolida√ß√£o
  - [x] Envia para LLM com prompt de extra√ß√£o
  - [x] Parseia resposta JSON estruturada
  - [x] Cria/atualiza knowledge_items
  - [x] Atualiza user_memory
  - [x] Salva registro em memory_consolidations
- [x] Criar consolidation prompt builder conforme docs/specs/ai.md ¬ß6.5.2
- [x] Criar response parser com valida√ß√£o Zod
- [x] Implementar scheduling timezone-aware via BullMQ `tz` option

**Testes:**
- [x] Testes unit√°rios:
  - [x] ContextBuilderService monta prompt corretamente (5 tests)
  - [x] KnowledgeItemsService CRUD funciona (31 tests)
  - [x] Tools validam par√¢metros com Zod
  - [x] UserMemoryService formatForPrompt respeita ~800 tokens (19 tests)
  - [x] MemoryToolExecutor execute e requiresConfirmation (18 tests)
  - [x] ConsolidationPrompt build e parse (18 tests)
  - [x] MemoryConsolidationProcessor (8 tests)
  - [x] MemoryConsolidationScheduler (7 tests)
- [x] Testes de integra√ß√£o:
  - [x] Memory consolidation extrai fatos de conversas
  - [x] search_knowledge retorna itens relevantes
  - [x] user_memory √© atualizado ap√≥s consolida√ß√£o
  - [x] Tool executor retorna resultados corretos com DB real
  - [x] Tool loop completa e salva metadata na mensagem
  - [x] Fluxo de confirma√ß√£o funciona via SSE (N/A - add_knowledge tem requiresConfirmation: false)
  - [x] API endpoints /memory/* funcionam com auth
  - [x] Job executa via BullMQ com Redis real (QueueEvents pattern)

**Definition of Done:**
- [x] user_memory √© sempre inclu√≠do no contexto
- [x] Tools search_knowledge e add_knowledge funcionam
- [x] Memory consolidation roda a cada 24h
- [x] Knowledge items s√£o criados/atualizados automaticamente
- [x] Usu√°rio pode ver o que a IA sabe (via API)
- [x] Testes unit√°rios passam (106 novos tests)

**Notas (2026-01-13):**
- Implementa√ß√£o completa de M1.3 Sistema de Mem√≥ria
- Memory module: `UserMemoryService`, `KnowledgeItemsService`, `MemoryToolExecutorService`
- Repositories: `UserMemoryRepository`, `KnowledgeItemRepository` (com RLS)
- Context builder enhanced com user memory formatting (~500-800 tokens)
- Chat service integrado com tool loop via `runToolLoop()` e `continueToolLoop()`
- Memory consolidation job usando BullMQ com timezone-aware scheduling (`tz` option)
- Scheduler cria um job por timezone √∫nico (n√£o por usu√°rio, para escalabilidade)
- Consolidation prompt usa Zod schema para valida√ß√£o de resposta LLM
- 106 novos testes unit√°rios adicionados
- 7 testes de integra√ß√£o para BullMQ job com Redis real usando QueueEvents pattern
- API endpoints: `/api/memory`, `/api/memory/knowledge`, `/api/memory/knowledge/:id`
- Arquivos cr√≠ticos:
  - `apps/api/src/modules/memory/` - Memory module completo
  - `apps/api/src/jobs/memory-consolidation/` - Consolidation job
  - `packages/ai/src/schemas/tools/` - Tool definitions
  - `packages/database/src/schema/` - user_memories, knowledge_items, memory_consolidations

**Notas (2026-01-14):**
- Testes de integra√ß√£o completos para M1.3 Sistema de Mem√≥ria
- 3 arquivos de teste criados em `apps/api/test/integration/memory/`:
  - `memory-endpoints.integration.spec.ts` - 14 testes (API /memory/*)
  - `memory-tool-executor.integration.spec.ts` - 14 testes (search/add/analyze tools)
  - `memory-consolidation.integration.spec.ts` - 18 testes (prompt build, parsing, fact extraction)
- Total: 46 testes de integra√ß√£o para memory module
- Padr√£o: inline controllers com JWT auth via `jose`, mock services
- 116 testes de integra√ß√£o passando (total geral)

### Ferramentas de Desenvolvimento (M1.3)

- [x] Admin endpoint para disparo manual do Memory Consolidation Job
  - [x] Criar AdminModule (`apps/api/src/modules/admin/`)
  - [x] Criar AdminJobsController com endpoint `POST /admin/jobs/memory-consolidation/trigger`
  - [x] Proteger endpoint para `NODE_ENV=development`
  - [x] Documentar uso em `docs/specs/engineering.md` ¬ß7.6

---

## M1.4 ‚Äî Memory View (Visualiza√ß√£o de Mem√≥ria) üü¢

**Objetivo:** Implementar tela para visualizar e gerenciar o que a IA sabe sobre o usu√°rio.

**Refer√™ncias:** `docs/specs/product.md` ¬ß6.2, `ADR-012`

**Tasks:**

**Backend:**
- [x] Criar endpoints de mem√≥ria:
  - [x] `GET /memory` - user_memory + estat√≠sticas
  - [x] `GET /memory/items` - lista de knowledge_items com filtros
  - [x] `PATCH /memory/items/:id` - corrigir item
  - [x] `DELETE /memory/items/:id` - deletar item
  - [x] `POST /memory/items/:id/validate` - validar item
  - [x] `POST /memory/items` - adicionar item manualmente
  - [x] `GET /memory/export` - exportar todos os items (JSON)
- [x] Renomear endpoint existente `/memory/knowledge` ‚Üí `/memory/items`
- [x] Implementar filtros:
  - [x] Por √°rea (health, financial, career, etc.)
  - [x] Por tipo (fact, preference, insight, person, memory)
  - [x] Por confian√ßa (high, medium, low)
  - [x] Por fonte (conversation, user_input, ai_inference)
  - [x] Por data
- [x] Implementar busca full-text em knowledge_items

**Frontend:**
- [x] Criar p√°gina `/memory`:
  - [x] Resumo do user_memory (perfil, objetivos, desafios)
  - [x] Lista de knowledge_items organizada por √°rea
  - [x] Filtros por tipo, confian√ßa, fonte
  - [x] Busca por texto
- [x] Componentes:
  - [x] MemoryOverview (resumo do perfil)
  - [x] KnowledgeItemsList (lista com filtros)
  - [x] KnowledgeItemCard (item com a√ß√µes)
  - [x] ConfidenceIndicator (alta/m√©dia/baixa)
  - [x] EditItemModal (para corre√ß√µes)
  - [x] AddItemModal (para adi√ß√µes manuais)
- [x] A√ß√µes por item:
  - [x] Confirmar (confirmar que est√° correto)
  - [x] Corrigir (editar conte√∫do)
  - [x] Deletar (remover permanentemente)
  - [x] Ver fonte (link para conversa original)

**Testes:**
- [x] Testes unit√°rios para filtros e novos m√©todos do service
- [x] Testes de integra√ß√£o para novos endpoints:
  - [x] PATCH /memory/items/:id
  - [x] POST /memory/items/:id/validate
  - [x] POST /memory/items
  - [x] GET /memory/export
  - [x] Filtros expandidos (confidence, source, date)
- [ ] Teste E2E: confirmar item ‚Üí verificar flag
- [ ] Teste E2E: corrigir item ‚Üí verificar novo valor
- [ ] Teste E2E: deletar item ‚Üí verificar remo√ß√£o
- [ ] Teste E2E: adicionar item manualmente ‚Üí verificar cria√ß√£o

**Definition of Done:**
- [x] Usu√°rio v√™ todos os knowledge_items
- [x] Filtros funcionam (√°rea, tipo, confian√ßa)
- [x] Busca por texto funciona
- [x] Confirmar item marca como confirmado
- [x] Corrigir item atualiza conte√∫do
- [x] Deletar item remove permanentemente
- [x] Testes passam (unit/integration - E2E pendentes)

**Notas (14/01/2026):**
- Implementa√ß√£o completa de backend e frontend
- Endpoints: GET /memory, GET/POST /memory/items, PATCH/DELETE /memory/items/:id, POST /memory/items/:id/validate, GET /memory/export
- Filtros: √°rea, tipo, confian√ßa (min/max), fonte, busca, data
- UI: p√°gina /memory com overview, lista paginada, filtros, modais de adi√ß√£o/edi√ß√£o
- Testes E2E pendentes para pr√≥xima itera√ß√£o

---

## M1.5 ‚Äî Temporal Knowledge Management üü¢

**Objetivo:** Implementar gerenciamento temporal de conhecimento com detec√ß√£o de mudan√ßas de estado (padr√£o Zep/Graphiti Temporal Knowledge Graphs).

**Refer√™ncias:** `docs/specs/ai.md` ¬ß6.7, `docs/specs/data-model.md` ¬ß4.5

**Contexto:**
Sistema detectava contradi√ß√µes de forma inconsistente:
- "solteiro" ‚Üí "namorando" = detectado ‚úì
- "tem d√≠vida" ‚Üí "quitou d√≠vida" = N√ÉO detectado ‚úó

Solu√ß√£o: reformular prompt para detectar "mudan√ßas de estado atual" + UI toggle "Ver hist√≥rico".

**Tasks:**

**Backend:**
- [x] Corrigir prompt de detec√ß√£o de contradi√ß√µes (`contradiction-detector.adapter.ts`)
  - [x] Reformular para detectar "mudan√ßas de estado" em vez de "contradi√ß√µes"
  - [x] Exemplos claros: estado civil, situa√ß√£o financeira, local, valores num√©ricos
- [x] Adicionar suporte a `includeSuperseded` no reposit√≥rio
  - [x] Atualizar `KnowledgeItemSearchParams` com campo `includeSuperseded`
  - [x] Modificar `search()` e `countSearch()` para filtrar quando necess√°rio
- [x] Atualizar DTOs para incluir filtro temporal
  - [x] `ListKnowledgeItemsQueryDto.includeSuperseded`
  - [x] `KnowledgeItemResponseDto.supersededById/supersededAt`
- [x] Atualizar export para incluir metadados temporais
  - [x] `ExportMemoryResponseDto` com stats (active/superseded)
  - [x] Incluir todos os items (ativos + superseded) no export

**Frontend:**
- [x] Adicionar campos `supersededById`, `supersededAt` aos types
- [x] Implementar toggle "Ver hist√≥rico" na FilterBar
- [x] Estilizar items superseded com badge e opacidade

**Documenta√ß√£o:**
- [x] Atualizar docs/specs/data-model.md com campos temporais
- [x] Adicionar se√ß√£o 6.7 ao docs/specs/ai.md (Contradiction Detection)

**Testes:**
- [x] Atualizar unit tests para `KnowledgeItemsService.exportAll()`
- [x] Atualizar unit tests para `MemoryController.exportMemory()`
- [x] Atualizar integration tests para temporal queries

**Definition of Done:**
- [x] "Tem d√≠vida" ‚Üí "Quitou d√≠vida" detectado como mudan√ßa de estado
- [x] UI mostra apenas items ativos por padr√£o
- [x] Toggle "Ver hist√≥rico" mostra items superseded
- [x] Export inclui todos os items com metadados temporais
- [x] Testes passando (338 unit tests)

**Notas (14/01/2026):**
- Padr√£o de Temporal Knowledge Graphs (Zep/Graphiti)
- Bi-temporal model: `supersededById` + `supersededAt`
- Items superseded N√ÉO s√£o deletados, preservam hist√≥rico
- UI: Switch "Ver hist√≥rico" + badge "Substitu√≠do em {data}"
- Arquivos modificados: 12 backend, 4 frontend, 2 docs, 4 test files

---

## M1.6 ‚Äî Racioc√≠nio Inferencial Real-time üü¢

**Objetivo:** Permitir que a IA fa√ßa conex√µes entre fatos e detecte contradi√ß√µes em tempo real durante conversas.

**Refer√™ncias:** `docs/specs/ai.md` ¬ß6.6, `ADR-014`

**Tasks:**

**Backend:**
- [x] Criar tool `analyze_context`:
  - [x] Definir schema em `packages/ai/src/schemas/tools/analyze-context.tool.ts`
  - [x] Par√¢metros: currentTopic, relatedAreas, lookForContradictions
  - [x] Retornar fatos relacionados, padr√µes existentes, conex√µes potenciais, contradi√ß√µes
- [x] Implementar executor para `analyze_context`:
  - [x] Buscar knowledge_items das √°reas relacionadas
  - [x] Buscar learnedPatterns com confidence >= 0.7
  - [x] Detectar conex√µes via keyword matching
  - [x] Estrutura para contradi√ß√µes (LLM faz an√°lise)
- [x] Atualizar system prompt:
  - [x] Adicionar `analyze_context` √†s capacidades
  - [x] Adicionar se√ß√£o "Racioc√≠nio Inferencial" com instru√ß√µes
- [x] Exportar tool no `packages/ai/src/index.ts`

**Documenta√ß√£o:**
- [x] Criar ADR-014: Real-time Inference Architecture
- [x] Atualizar docs/specs/ai.md (¬ß4.1, ¬ß6.2, ¬ß6.6, ¬ß9.1, ¬ß9.2)

**Testes:**
- [x] Testes unit√°rios para `analyze_context`:
  - [x] Retorna fatos relacionados das √°reas
  - [x] Inclui padr√µes com alta confian√ßa
  - [x] Deduplica fatos de m√∫ltiplas √°reas
  - [x] Encontra conex√µes potenciais com padr√µes
  - [x] Inclui hint quando lookForContradictions=true
  - [x] Ordena fatos por confidence descending
  - [x] Retorna erro para par√¢metros inv√°lidos

**Definition of Done:**
- [x] Tool `analyze_context` definida e implementada
- [x] Executor busca fatos e padr√µes corretamente
- [x] System prompt inclui instru√ß√µes de racioc√≠nio inferencial
- [x] ADR-014 documenta arquitetura
- [x] Testes unit√°rios passam

**Notas (13/01/2026):**
- Implementado como parte do plano de "Real-time Inference Architecture"
- Arquitetura de dois n√≠veis: Batch (Job 3AM) + Real-time (analyze_context)
- Padr√µes do batch s√£o reutilizados no real-time (confidence >= 0.7)
- LLM decide quando usar a tool baseado nas instru√ß√µes do system prompt
- Detec√ß√£o de contradi√ß√µes √© feita pelo LLM, n√£o por c√≥digo

---

## M1.7 ‚Äî Perspectiva Crist√£ üî¥

**Objetivo:** Implementar feature opt-in de perspectiva crist√£ no chat.

**Refer√™ncias:** `docs/specs/product.md` ¬ß8, `docs/specs/ai.md` ¬ß4.3

**Tasks:**

**Backend:**
- [ ] Adicionar configura√ß√£o `christianPerspective: boolean` no user_settings
- [ ] Implementar system prompt de perspectiva crist√£ (conforme `docs/specs/ai.md` ¬ß4.3)
- [ ] Integrar com chat: aplicar prompt quando habilitado

**Frontend:**
- [ ] Criar toggle nas configura√ß√µes do usu√°rio (`/settings/preferences`)
- [ ] Adicionar se√ß√£o "Perspectiva Crist√£" com explica√ß√£o
- [ ] Componente ToggleWithDescription para o setting
- [ ] Adicionar op√ß√£o de habilitar perspectiva crist√£ na etapa 2 do onboarding (toggle opcional junto com sele√ß√£o de √°reas) ‚Äî conforme `docs/specs/product.md` ¬ß7.1 item 2c

**Testes:**
- [ ] Teste unit√°rio: prompt correto √© aplicado quando habilitado
- [ ] Teste unit√°rio: prompt crist√£o N√ÉO √© aplicado quando desabilitado
- [ ] Teste de integra√ß√£o: resposta da IA inclui perspectiva b√≠blica (quando habilitado)
- [ ] Teste de integra√ß√£o: resposta da IA N√ÉO menciona religi√£o (quando desabilitado)
- [ ] Teste E2E: toggle de configura√ß√£o persiste corretamente
- [ ] Teste E2E: toggle no onboarding habilita perspectiva crist√£ corretamente

**Definition of Done:**
- [ ] Usu√°rio pode habilitar/desabilitar perspectiva crist√£
- [ ] IA integra princ√≠pios b√≠blicos naturalmente quando habilitado
- [ ] Nunca menciona aspectos religiosos quando desabilitado
- [ ] Toggle no onboarding funciona corretamente
- [ ] Testes passam

---

## M1.8 ‚Äî Guardrails de Seguran√ßa üî¥

**Objetivo:** Implementar guardrails para t√≥picos sens√≠veis.

**Refer√™ncias:** `docs/specs/ai.md` ¬ß8

**Tasks:**

**Backend:**
- [ ] Criar `GuardrailService` para verifica√ß√£o de conte√∫do:
  - [ ] Suic√≠dio/autoles√£o ‚Üí CVV (188) + acolhimento
  - [ ] Abuso/viol√™ncia ‚Üí recursos (180, 190)
  - [ ] Diagn√≥sticos m√©dicos ‚Üí sugerir profissional
  - [ ] Aconselhamento financeiro ‚Üí n√£o dar recomenda√ß√µes espec√≠ficas
  - [ ] Conte√∫do ilegal ‚Üí recusar educadamente
- [ ] Implementar respostas padr√£o para cada guardrail (templates)
- [ ] Integrar verifica√ß√£o no fluxo de chat (antes de responder)

**Logging Seguro:**
- [ ] Implementar filtro de dados sens√≠veis em tool call logging:
  - [ ] Criar `SensitiveDataFilter` utility em `packages/ai/src/utils/`
  - [ ] Campos a mascarar:
    - `add_knowledge.content` ‚Üí `"[CONTENT REDACTED - ${length} chars]"`
    - `search_knowledge.query` ‚Üí `"[QUERY REDACTED]"` (se contiver dados pessoais)
  - [ ] Aplicar filtro em:
    - `memory-tool-executor.service.ts:139` (add_knowledge params)
    - `memory-tool-executor.service.ts:89` (search_knowledge params)
  - [ ] Manter log de tool_name, duration, success/failure sem filtro
- [ ] Revisar metadata de mensagens no banco:
  - [ ] Avaliar se `toolCalls.arguments` deve ser armazenado completo (chat.service.ts:278-282)
  - [ ] Op√ß√£o 1: N√£o armazenar argumentos (apenas id, name)
  - [ ] Op√ß√£o 2: Aplicar SensitiveDataFilter antes de salvar
  - [ ] Considerar impacto em debugging

**Testes:**
- [ ] Testes unit√°rios para cada tipo de guardrail:
  - [ ] Detec√ß√£o de conte√∫do sobre suic√≠dio/autoles√£o
  - [ ] Detec√ß√£o de conte√∫do sobre abuso/viol√™ncia
  - [ ] Detec√ß√£o de solicita√ß√£o de diagn√≥stico m√©dico
  - [ ] Detec√ß√£o de solicita√ß√£o de aconselhamento financeiro espec√≠fico
  - [ ] Detec√ß√£o de conte√∫do ilegal
- [ ] Teste de integra√ß√£o: mensagem sens√≠vel ‚Üí resposta apropriada
- [ ] Teste que guardrails N√ÉO disparam para conte√∫do normal
- [ ] Teste E2E: fluxo completo de guardrail (mensagem ‚Üí resposta de suporte)

**Definition of Done:**
- [ ] Todos os guardrails funcionam conforme especificado
- [ ] Respostas incluem recursos de ajuda apropriados
- [ ] Testes passam

---

## M1.9 ‚Äî UI/UX Polish v1 üü°

**Objetivo:** Finalizar refinamentos de interface e implementar responsividade para lan√ßamento da v1.

> **Contexto:** Componentes base (EmptyState, LoadingSpinner, Skeleton, Toast, AlertDialog,
> ErrorBoundary) foram implementados em M0.6, M1.2, M1.4. Este milestone finaliza ajustes
> pendentes e implementa responsividade completa.

**Tasks:**

**Finalizar componentes de estado:**
- [x] ErrorBoundary: adicionar link "Precisa de ajuda?" para suporte

**Alinhar Empty States com `docs/specs/system.md` ¬ß4.1:**
- [x] Chat: ajustar mensagem para "Converse com sua assistente" + CTA "Iniciar conversa"
- [x] Mem√≥ria: ajustar mensagem para "A IA ainda est√° aprendendo sobre voc√™" + CTA "Iniciar conversa"

**Finalizar Error Handling:**
- [x] Chat: adicionar bot√£o "Tentar novamente" expl√≠cito no error state inline
- [x] Mem√≥ria: adicionar ErrorState persistente quando fetch de items falha (al√©m do toast)

**Adicionar Toasts faltantes:**
- [x] Chat: toast de sucesso ao criar conversa ("Nova conversa criada")
- [x] Chat: toast de sucesso ao deletar conversa ("Conversa exclu√≠da")

**Chat UX:**
- [x] Renderizar Markdown nas respostas da IA (Streamdown + @tailwindcss/typography)

**Dashboard:**
- [x] Adicionar loading skeleton (prepara√ß√£o para quando buscar dados reais)

**Responsividade:**
- [x] Implementar hamburger menu em mobile (< 640px) ‚Äî j√° existia em header.tsx
- [x] Implementar sidebar como overlay em mobile (backdrop + translate-x animation)
- [x] Revisar layout do Chat em mobile (conversation list hidden, chat area full-width)
- [x] Revisar layout da Mem√≥ria em mobile (overview full-width, filters wrap)
- [x] Revisar layout em tablet (768px) ‚Äî sidebar always visible
- [x] Verificar e ajustar layouts em desktop (> 1024px) ‚Äî confirmado funcional

**Testes (pendente):**
- [ ] Testes unit√°rios para ajustes em ErrorBoundary
- [ ] Teste E2E: verificar empty states em Chat e Mem√≥ria
- [ ] Teste E2E: verificar error states com retry
- [ ] Teste E2E: verificar toasts em opera√ß√µes CRUD
- [ ] Testes de responsividade (Playwright viewports: mobile 375px, tablet 768px, desktop 1280px)

**Definition of Done:**
- [x] Empty states alinhados com docs/specs/system.md ¬ß4.1
- [x] Error states com bot√£o retry e link suporte
- [x] Toasts em todas as opera√ß√µes CRUD (Chat + Mem√≥ria)
- [x] App responsivo e funcional em mobile, tablet e desktop
- [x] Sidebar com hamburger menu em mobile
- [ ] Todos os testes passam

**Notas (2026-01-15):**
- 14 tasks de UI implementadas (Estados, Toasts, Dashboard, Responsividade)
- Sidebar: transform-based com backdrop em mobile, sempre vis√≠vel em desktop (md+)
- Chat: conversation list hidden em mobile, usa empty state para iniciar conversa
- Memory: overview full-width em mobile (lg:flex-row), error state persistente com retry
- Dashboard: skeleton durante loading inicial, textos atualizados para "Mem√≥ria"
- Testes ser√£o implementados em etapa posterior
- **Bug fix (M1.2):** Typing indicator corrigido ‚Äî adicionado ThinkingIndicator + typewriter effect + auto-scroll
- **Nova feature:** Markdown rendering com Streamdown (lida com markdown incompleto durante typewriter)
- **Bug fix:** Memory area cards ‚Äî √≠cones Lucide (Sparkles, Sun) + truncate em textos longos

---

## M1.10 ‚Äî Context Management (Compaction) üî¥

**Objetivo:** Gerenciar contexto de conversas longas usando compaction autom√°tico, similar ao Claude Code.

**Refer√™ncias:**
- [Automatic Context Compaction - Claude Docs](https://platform.claude.com/cookbook/tool-use-automatic-context-compaction)
- [Effective Context Engineering - Anthropic](https://www.anthropic.com/engineering/effective-context-engineering-for-ai-agents)
- `docs/specs/ai.md` ¬ß4

**Problema:**
- Atualmente s√≥ as √∫ltimas 20 mensagens s√£o enviadas ao LLM
- Conversas longas perdem contexto importante
- N√£o h√° sumariza√ß√£o de mensagens antigas

**Tasks:**

**Backend - Compaction Service:**
- [ ] Criar `CompactionService` em `packages/ai`:
  - [ ] Monitorar token usage por conversa
  - [ ] Detectar quando threshold √© atingido (80% do context window)
  - [ ] Gerar summary usando prompt especializado
  - [ ] Retornar summary formatado
- [ ] Criar schema para summary prompt:
  - [ ] Template para resumo de conversa
  - [ ] Preservar: fatos aprendidos, t√≥picos discutidos
  - [ ] Descartar: mensagens repetitivas, sauda√ß√µes, confirma√ß√µes
- [ ] Implementar token counting (estimativa: 4 chars = 1 token)

**Backend - Integra√ß√£o com Chat:**
- [ ] Modificar `ChatService.processStreamResponse`:
  - [ ] Calcular tokens totais da conversa
  - [ ] Verificar threshold antes de chamar LLM
  - [ ] Se threshold atingido, chamar compaction
  - [ ] Usar summary + √∫ltimas N mensagens como contexto
- [ ] Criar tabela ou coluna para armazenar summaries:
  - [ ] `conversations.summary` (text, nullable)
  - [ ] `conversations.summary_updated_at` (timestamp)
  - [ ] `conversations.messages_summarized_count` (integer)
- [ ] Implementar migration para nova coluna

**Backend - Context Builder:**
- [ ] Modificar `ContextBuilderService`:
  - [ ] Carregar summary da conversa se existir
  - [ ] Incluir summary no in√≠cio do contexto
  - [ ] Manter user_memories + knowledge como contexto persistente
- [ ] Ajustar n√∫mero de mensagens recentes (20 ‚Üí din√¢mico baseado em tokens)

**Configura√ß√£o:**
- [ ] Adicionar configs em `ConfigService`:
  - [ ] `CONTEXT_COMPACTION_THRESHOLD` (default: 100000 tokens)
  - [ ] `CONTEXT_COMPACTION_ENABLED` (default: true)
  - [ ] `CONTEXT_RECENT_MESSAGES_LIMIT` (default: 20)
  - [ ] `CONTEXT_COMPACTION_MODEL` (default: mesmo modelo, opcional haiku)

**Testes:**
- [ ] Teste unit√°rio: CompactionService gera summary v√°lido
- [ ] Teste unit√°rio: Token counting funciona corretamente
- [ ] Teste unit√°rio: Threshold detection funciona
- [ ] Teste integra√ß√£o: Conversa longa trigger compaction
- [ ] Teste integra√ß√£o: Summary √© persistido corretamente
- [ ] Teste integra√ß√£o: Contexto inclui summary + mensagens recentes

**Definition of Done:**
- [ ] Conversas longas n√£o perdem contexto importante
- [ ] Compaction acontece automaticamente quando necess√°rio
- [ ] Summary √© persistido e reutilizado
- [ ] Token usage √© reduzido em conversas longas
- [ ] Testes passam
- [ ] Documenta√ß√£o atualizada (docs/specs/ai.md)
