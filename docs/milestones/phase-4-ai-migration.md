# Fase 4: Migra√ß√£o da IA para Python (v4.x)

> **Objetivo:** Migrar toda a camada de intelig√™ncia artificial (packages/ai/ + tool executors + memory workers) de TypeScript/NestJS para um servi√ßo Python independente com FastAPI + LangGraph, seguindo o padr√£o Strangler Fig.
> **Refer√™ncias:** `docs/ai-python-service-migration-plan.md`, `docs/adr-012-tool-use-vs-rag-analysis.md`, `docs/specs/core/architecture.md`

> **Contexto:** O ecossistema Python domina AI/ML (LangGraph, LangChain, LangSmith, scikit-learn, pandas). A implementa√ß√£o atual em TypeScript (`packages/ai/` ‚Äî 7.677 linhas, 49 arquivos) foi adequada para o MVP mas limita a evolu√ß√£o para multi-agente, RAG futuro, e ferramentas avan√ßadas de observabilidade de AI. A migra√ß√£o cria um servi√ßo Python dedicado (`services/ai/`) mantendo NestJS como API REST + auth + dashboard.
>
> **Filosofia:**
> - **Strangler Fig:** Sistema TypeScript e Python coexistem via feature flag (`USE_PYTHON_AI`). Rollback instant√¢neo em qualquer ponto.
> - **Milestones at√¥micos:** Cada milestone produz um sistema funcional e test√°vel. Nunca h√° estado quebrado entre milestones.
> - **LangGraph substitui, n√£o porta:** Muitos componentes TypeScript custom (~1.639 linhas) s√£o substitu√≠dos por primitivas LangGraph, n√£o portados 1:1.
> - **Python independente do Turbo:** O servi√ßo Python **N√ÉO** faz parte do pnpm workspace nem do Turborepo pipeline. Python √© gerido 100% com ferramentas nativas (uv, ruff, mypy, pytest). O `pnpm dev` usa `concurrently` para iniciar Turbo + Python em paralelo. CI roda jobs Node e Python separados. Decis√£o baseada em [Turborepo multi-language docs](https://turborepo.dev/docs/guides/multi-language) e an√°lise de trade-offs ‚Äî o pattern de package.json wrapper √© oficialmente suportado pelo Turbo, mas gera artefatos artificiais (node_modules, lockfile entries) sem benef√≠cio real de cache para Python.

### Insight: O que LangGraph substitui

A migra√ß√£o **N√ÉO √© um port 1:1** do TypeScript. LangGraph substitui v√°rios componentes custom:

| Componente TypeScript | Linhas | Equivalente LangGraph/LangChain | Resultado |
|---|---|---|---|
| `tool-loop.service.ts` | 310 | `create_react_agent()` (`langgraph.prebuilt`) | **Eliminado** |
| `LLMPort` interface | 245 | `ChatGoogleGenerativeAI` (`langchain-google-genai`) / `ChatAnthropic` (`langchain-anthropic`) | **Eliminado** |
| `retry.ts` + `rate-limiter.ts` | 382 | `max_retries` + `.with_retry()` + `InMemoryRateLimiter` (LangChain built-in) | **Eliminado** |
| `zod-to-gemini.ts` | 227 | `.bind_tools()` converte Pydantic ‚Üí formato do provider automaticamente | **Eliminado** |
| `confirmation-state.service.ts` (Redis TTL 5min) | 475 | `interrupt()` / `Command(resume=)` (`langgraph.types`) com PostgreSQL checkpoint (`AsyncPostgresSaver`) | **Redesenhado** |
| Tool definitions (Zod schemas) | ~1.000 | Pydantic models + `@tool` decorator | **Reescrito** |

> ~1.639 linhas de `packages/ai/` n√£o precisam ser portadas ‚Äî s√£o substitu√≠das por primitivas LangGraph. O c√≥digo Python ser√° mais enxuto que o TypeScript equivalente.

### Invent√°rio do c√≥digo afetado

**packages/ai/ (7.677 linhas, 49 arquivos) ‚Äî ser√° DELETADO:**

| Categoria | Linhas | Arquivos | Destino |
|---|---|---|---|
| Adapters (Claude + Gemini) | 1.932 | 4 | Substitu√≠dos por `langchain-google-genai` / `langchain-anthropic` |
| Services (Factory, ToolLoop, Executor) | 1.503 | 7 | Substitu√≠dos por LangGraph `create_react_agent()` |
| Tool definitions (22 tools + schemas) | 2.159 | 27 | Reescritos como Pydantic + `@tool` decorator |
| Utilities (retry, rate-limit, zod-to-gemini) | 1.484 | 8 | Substitu√≠dos por primitivas LangChain |
| Ports/Interfaces | 245 | 1 | Eliminados (LangGraph abstrai) |
| Errors + Core | 354 | 2 | Python exception hierarchy |

**apps/api/ ‚Äî c√≥digo AI-related (~5.700 linhas) ‚Äî ser√° DELETADO ou SIMPLIFICADO:**

| Arquivo | Linhas | A√ß√£o |
|---|---|---|
| `chat.service.ts` | 1.232 | Simplificado para ~200L (proxy SSE) |
| `finance-tool-executor.service.ts` | 1.047 | Deletado (migra para Python) |
| `tracking-tool-executor.service.ts` | 587 | Deletado (migra para Python) |
| `memory-consolidation.processor.ts` | 557 | Simplificado para ~50L (BullMQ trigger ‚Üí HTTP POST para Python) |
| `confirmation-state.service.ts` | 475 | Deletado (LangGraph interrupt) |
| `contradiction-detector.adapter.ts` | 435 | Deletado (migra para Python) |
| `context-builder.service.ts` | 337 | Deletado (migra para Python) |
| `memory-tool-executor.service.ts` | 297 | Deletado (migra para Python) |
| `consolidation-prompt.ts` | 337 | Deletado (migra para Python) |
| `contradiction-resolution.service.ts` | 311 | Deletado (migra para Python) |
| `contradiction-detector.port.ts` | 86 | Deletado (interface eliminada) |

**Total:** ~11.600 linhas deletadas + ~2.700 simplificadas (~1.800 delta removido) ‚Üí ~5.000-7.000 linhas Python novas

### Paralelismo entre milestones

- M4.5 (Finance Tools) e M4.6 (Memory Tools) podem rodar **em paralelo** (ambos dependem de M4.4 mas s√£o independentes entre si)
- M4.1 pode come√ßar **imediatamente** sem afetar trabalho nas outras fases
- Feature flag permite **rollback instant√¢neo** em qualquer ponto da migra√ß√£o

---

## M4.1 ‚Äî Python Service: Scaffold + Infra + CI üü¢

**Objetivo:** Servi√ßo Python boot√°vel com FastAPI, integrado no fluxo de dev local (`pnpm infra:up` + `pnpm dev`) e CI. Nenhuma l√≥gica de AI ‚Äî apenas infraestrutura.

**Refer√™ncias:** `docs/ai-python-service-migration-plan.md` ¬ß3, ¬ß10

**Depend√™ncias:** Nenhuma (pode come√ßar imediatamente)

> **Decis√£o arquitetural:** O servi√ßo Python N√ÉO faz parte do pnpm workspace nem do Turborepo. Python √© gerido com ferramentas nativas (uv, ruff, mypy, pytest). `pnpm dev` usa `concurrently` para iniciar Turbo (JS/TS) + uvicorn (Python) em paralelo. Esta decis√£o segue o princ√≠pio de separa√ß√£o de concerns ‚Äî cada linguagem com seu toolchain nativo, sem artefatos artificiais.

**Tasks:**

**Scaffold do projeto Python (via CLI):**
- [x] Inicializar projeto: `uv init --app --python 3.12 services/ai`
  - Cria: `pyproject.toml`, `.python-version`, `.gitignore`, `README.md`, `main.py`
  - Flag `--no-workspace` se existir `pyproject.toml` na raiz do monorepo (evita auto-join)
- [x] Adicionar depend√™ncias runtime:
  ```bash
  cd services/ai
  uv add fastapi 'uvicorn[standard]' 'sqlalchemy[asyncio]' asyncpg langgraph langgraph-checkpoint-postgres langchain-google-genai langchain-anthropic pydantic pydantic-settings sse-starlette
  ```
- [x] Adicionar depend√™ncias dev:
  ```bash
  uv add --dev pytest pytest-asyncio ruff mypy httpx
  ```
- [x] Configurar tool settings no `pyproject.toml` (se√ß√µes `[tool.ruff]`, `[tool.mypy]`, `[tool.pytest.ini_options]`)
- [x] Remover `main.py` gerado pelo scaffold e reorganizar para estrutura `app/`:
  ```
  services/ai/
  ‚îú‚îÄ‚îÄ app/
  ‚îÇ   ‚îú‚îÄ‚îÄ __init__.py
  ‚îÇ   ‚îú‚îÄ‚îÄ main.py          # FastAPI app + lifespan (startup/shutdown)
  ‚îÇ   ‚îú‚îÄ‚îÄ config.py         # Pydantic Settings (BaseSettings)
  ‚îÇ   ‚îú‚îÄ‚îÄ dependencies.py   # FastAPI Depends() ‚Äî DB session, config
  ‚îÇ   ‚îî‚îÄ‚îÄ api/
  ‚îÇ       ‚îú‚îÄ‚îÄ routes/
  ‚îÇ       ‚îÇ   ‚îî‚îÄ‚îÄ health.py # GET /health (status + DB check)
  ‚îÇ       ‚îî‚îÄ‚îÄ middleware/
  ‚îÇ           ‚îî‚îÄ‚îÄ auth.py   # Service-to-service auth (Bearer token)
  ‚îú‚îÄ‚îÄ tests/
  ‚îú‚îÄ‚îÄ pyproject.toml
  ‚îú‚îÄ‚îÄ uv.lock
  ‚îî‚îÄ‚îÄ .python-version
  ```
- [x] Criar `app/main.py` com FastAPI lifespan:
  - Startup: `AsyncPostgresSaver.setup()` (cria tabelas de checkpoint: `checkpoints`, `checkpoint_blobs`, `checkpoint_writes`, `checkpoint_migrations`)
  - Shutdown: dispose engine
- [x] Criar `app/config.py` com Pydantic Settings:
  - `DATABASE_URL`, `GEMINI_API_KEY`, `SERVICE_SECRET`, `ANTHROPIC_API_KEY` (opcional)
  - Loads from root `.env` via `model_config = SettingsConfigDict(env_file="../../.env")`
- [x] Criar `app/dependencies.py` ‚Äî FastAPI `Depends()` com generator `yield` para DB session
- [x] Criar `app/api/routes/health.py` ‚Äî GET /health (status + vers√£o + check de DB)
- [x] Criar `app/api/middleware/auth.py` ‚Äî service-to-service auth via shared secret (Bearer token)
- [x] Estender `.gitignore` gerado pelo uv: adicionar `__pycache__/`, `.mypy_cache/`, `.pytest_cache/`, `.ruff_cache/`

> **Nota:** `sse-starlette` √© depend√™ncia expl√≠cita ‚Äî FastAPI n√£o tem classe SSE built-in. Usar `EventSourceResponse` para streaming.
> **Nota:** `REDIS_URL` removido da config Python ‚Äî n√£o necess√°rio na fase inicial. Confirma√ß√£o usa PostgreSQL (LangGraph checkpoints), n√£o Redis TTL. BullMQ scheduling permanece no NestJS.

**Integra√ß√£o com `pnpm dev` (via `concurrently`):**
- [x] Instalar concurrently: `pnpm add -Dw concurrently`
- [x] Atualizar `package.json` root:
  ```json
  {
    "scripts": {
      "dev": "concurrently -k -p [{name}] -n turbo,ai -c blue,yellow \"turbo run dev\" \"cd services/ai && uv run uvicorn app.main:app --reload --host 0.0.0.0 --port 8000\"",
      "dev:js": "turbo run dev",
      "dev:ai": "cd services/ai && uv run uvicorn app.main:app --reload --host 0.0.0.0 --port 8000"
    }
  }
  ```
- [x] Verificar que `Ctrl+C` mata todos os processos (flag `-k` do concurrently)
- [x] Verificar que output mostra prefixos `[turbo]` e `[ai]` no terminal

**Integra√ß√£o com `pnpm infra:up` (dev-start.sh):**
- [x] Adicionar porta 8000 ao `check_ports()` existente
- [x] Criar novo Step (entre Service Status e Database Schema):
  ```
  Step 4: Python AI Service Setup
    ‚úì Check Python 3.12+
    ‚úì Check uv package manager
    ‚úì Install dependencies (uv sync)
    ‚úì Python environment ready
  ```
- [x] Implementar `check_python()`:
  - Verificar `python3 --version` >= 3.12
  - Se n√£o encontrado: mensagem com instru√ß√µes de instala√ß√£o
- [x] Implementar `check_uv()`:
  - Verificar `uv --version`
  - Se n√£o encontrado: sugerir `curl -LsSf https://astral.sh/uv/install.sh | sh`
- [x] Implementar `setup_python_env()`:
  - `cd services/ai && uv sync` (cria .venv + instala deps)
  - Idempotente: <2s em runs subsequentes
  - Verifica√ß√£o: `uv run python -c "import fastapi; print('OK')"`
- [x] Atualizar summary final para mostrar Python AI Service URL (localhost:8000)
- [x] Renumerar steps: 1-Docker, 2-Supabase, 3-Status, **4-Python**, 5-Database

**Docker (produ√ß√£o + CI):**
- [x] Criar `services/ai/Dockerfile`:
  ```dockerfile
  FROM python:3.12-slim AS base
  WORKDIR /app
  RUN pip install uv

  FROM base AS deps
  COPY pyproject.toml uv.lock ./
  RUN uv sync --frozen --no-dev

  FROM base AS runner
  COPY --from=deps /app/.venv /app/.venv
  COPY app/ app/
  ENV PATH="/app/.venv/bin:$PATH"
  EXPOSE 8000
  CMD ["uvicorn", "app.main:app", "--host", "0.0.0.0", "--port", "8000"]
  ```
- [x] Criar `services/ai/.dockerignore` ‚Äî `.venv/`, `__pycache__/`, `.git/`, `tests/`, `.mypy_cache/`
- [x] **N√ÉO** adicionar Python ao docker-compose.yml (Python roda nativo em dev, Docker s√≥ para produ√ß√£o)

**Vari√°veis de ambiente:**
- [x] Adicionar ao `.env.example`:
  ```bash
  # Python AI Service
  PYTHON_AI_URL=http://localhost:8000
  SERVICE_SECRET=dev-secret-change-me
  USE_PYTHON_AI=false
  ```
- [x] Adicionar `PYTHON_AI_URL` ao `packages/config/`

**CI (GitHub Actions ‚Äî job separado):**
- [x] Criar `services/ai/tests/conftest.py` ‚Äî fixtures base (async test client via `httpx.AsyncClient`, test DB session)
- [x] Adicionar job `python` no workflow CI:
  ```yaml
  python:
    runs-on: ubuntu-latest
    defaults:
      run:
        working-directory: services/ai
    steps:
      - uses: actions/checkout@v4
      - uses: astral-sh/setup-uv@v5
        with:
          python-version: "3.12"
      - run: uv sync
      - run: uv run ruff check .
      - run: uv run ruff format --check .
      - run: uv run mypy app/
      - run: uv run pytest
  ```
- [x] Job Python roda em **paralelo** com job Node (n√£o sequencial)

**Documenta√ß√£o:**
- [x] Atualizar `CLAUDE.md`:
  - Requirements: adicionar `Python >=3.12, uv`
  - Commands: adicionar `pnpm dev:ai` e explicar `pnpm dev` (agora usa concurrently)
  - Estrutura do monorepo: adicionar `services/ai/`
- [x] Atualizar `DEVELOPMENT.md` (se existir) com setup Python

**Definition of Done:**
- [x] `pnpm infra:up` verifica Python, instala deps via `uv sync`
- [x] `pnpm dev` inicia web (:3000) + api (:4000) + python (:8000) em paralelo
- [x] `curl http://localhost:8000/health` retorna 200
- [x] Request sem Bearer token retorna 401
- [x] CI passa: job Node (turbo) + job Python (ruff, mypy, pytest) em paralelo
- [x] `Ctrl+C` no `pnpm dev` mata todos os processos
- [x] `services/ai/` N√ÉO aparece em `pnpm-workspace.yaml` nem `pnpm-lock.yaml`

### Notas

_Conclu√≠do em 2026-02-22._

**Melhorias sobre o plano original:**
- Adicionada depend√™ncia `psycopg[binary]` ‚Äî necess√°ria para `langgraph-checkpoint-postgres` funcionar sem `libpq` nativo instalado no sistema
- Dockerfile usa `COPY --from=ghcr.io/astral-sh/uv:latest /uv /uvx /bin/` em vez de `RUN pip install uv` ‚Äî mais eficiente (layer de cache, sem pip)
- CI usa `astral-sh/setup-uv@v7` (plano dizia `@v5`, Context7 confirmou v7 como latest)
- `AsyncPostgresSaver.from_conn_string()` retorna context manager (`async with`) ‚Äî validado via Context7 docs + source code inspection. Plano n√£o especificava esse detalhe
- Entradas Python adicionadas no `.gitignore` root em vez de criar `.gitignore` separado em `services/ai/` (j√° coberto pelo root)
- `README.md` gerado pelo `uv init` removido (desnecess√°rio)
- Auth middleware implementado como `BaseHTTPMiddleware` do Starlette com `PUBLIC_PATHS` incluindo `/health`, `/docs`, `/openapi.json`, `/redoc`
- Testes do `@life-assistant/config` e `apps/api/test/setup.ts` atualizados para incluir `SERVICE_SECRET` nos fixtures (campo obrigat√≥rio adicionado ao `envSchema`)

**Verifica√ß√£o local:**
- Python: ruff check (0), ruff format (15 files OK), mypy (0 issues, 11 files), pytest (5/5)
- JS/TS: typecheck (10/10), lint (5/6 ‚Äî web failure preexistente), test (5/6 ‚Äî web failures preexistentes)
- Health endpoint: `curl localhost:8000/health` ‚Üí 200 `{"status":"ok","version":"0.1.0","database":"connected"}`
- Auth: endpoint sem Bearer ‚Üí 401, `/health` sem auth ‚Üí 200
- Isolamento: `services/ai/` n√£o aparece em `pnpm-workspace.yaml` nem `pnpm-lock.yaml`
- Concurrently rodando com flags corretos (`-k -p [{name}] -n turbo,ai -c blue,yellow`)

---

## M4.2 ‚Äî SQLAlchemy Data Layer + RLS üü¢

**Objetivo:** Python consegue ler/escrever no PostgreSQL com Row Level Security, mapeando tabelas do Drizzle.

**Refer√™ncias:** `docs/ai-python-service-migration-plan.md` ¬ß8, `docs/specs/core/data-conventions.md`, `docs/specs/core/auth-security.md`

**Depend√™ncias:** M4.1

> **Contexto:** Drizzle (NestJS) √© o source of truth para schema e migrations. SQLAlchemy models s√£o mapeamentos passivos ‚Äî n√£o geram migrations. PostgreSQL garante integridade via constraints, foreign keys e RLS policies independente de qual ORM escreve.

**Tasks:**

**Engine + Session:**
- [x] Criar `app/db/engine.py`:
  - `create_async_engine("postgresql+asyncpg://...")` com pool config
  - `async_sessionmaker(engine, expire_on_commit=False)` ‚Äî `expire_on_commit=False` obrigat√≥rio para evitar lazy-loading I/O em async
- [x] Criar `app/db/session.py` ‚Äî context managers RLS-aware que executam `SET LOCAL request.jwt.claim.sub = '{user_id}'` antes de cada opera√ß√£o (matching NestJS `set_config('request.jwt.claim.sub', ...)` e RLS policies que usam `auth.uid()`)
  - Deve ser **obrigat√≥rio** ‚Äî imposs√≠vel fazer query sem user_id setado
  - Testes que tentam query sem middleware devem falhar com RLS

**Models (mapeamento passivo das tabelas Drizzle):**
- [x] Criar `app/db/models/base.py` ‚Äî `DeclarativeBase` + mixins comuns (`TimestampMixin`, `SoftDeleteMixin`)
- [x] Criar `app/db/models/enums.py` ‚Äî Enums Python (`StrEnum`) espelhando os PostgreSQL `CREATE TYPE` (22 enums usados pelas tabelas modeladas)
- [x] Criar `app/db/models/users.py` ‚Äî `users`, `user_memories` (read-only para Python)
- [x] Criar `app/db/models/tracking.py` ‚Äî `tracking_entries`, `custom_metric_definitions`, `habits`, `habit_completions`
- [x] Criar `app/db/models/finance.py` ‚Äî `incomes`, `bills`, `variable_expenses`, `debts`, `debt_payments`, `investments`, `budgets`
- [x] Criar `app/db/models/memory.py` ‚Äî `knowledge_items`, `memory_consolidations`
- [x] Criar `app/db/models/chat.py` ‚Äî `conversations`, `messages`
- [x] Todos os `Numeric` fields com `asdecimal=False` na defini√ß√£o do model (retorna `float` ao inv√©s de `Decimal`):
  ```python
  amount = mapped_column(Numeric(precision=12, scale=2, asdecimal=False))  # ‚Üí float
  ```

> **NUNCA criar SQLAlchemy models para tabelas de checkpoint do LangGraph** (`checkpoints`, `checkpoint_blobs`, `checkpoint_writes`, `checkpoint_migrations`). Essas tabelas s√£o gerenciadas exclusivamente pelo `AsyncPostgresSaver.setup()` chamado no lifespan do FastAPI (M4.1).

**Repositories:**
- [x] Criar `app/db/repositories/tracking.py` ‚Äî TrackingRepository (create, find, aggregate, update, delete)
- [x] Criar `app/db/repositories/finance.py` ‚Äî FinanceRepository (summary, bills, expenses, incomes, investments, debts)
- [x] Criar `app/db/repositories/memory.py` ‚Äî MemoryRepository (search knowledge, add knowledge, get user memories)
- [x] Criar `app/db/repositories/chat.py` ‚Äî ChatRepository (save message, get history, get conversation)
- [x] Criar `app/db/repositories/user.py` ‚Äî UserRepository (get user, get settings ‚Äî read-only)

**Schema Drift CI Check:**
- [x] Criar script `services/ai/scripts/check_schema_drift.py`:
  - Conecta ao DB, l√™ `information_schema` real
  - Compara com SQLAlchemy models declarados
  - Falha se tabela/coluna/tipo existir no DB mas n√£o no model (ou vice-versa)
- [x] Integrar no CI: roda a cada PR que toca `packages/database/src/schema/` ou `services/ai/app/db/models/`

**Testes:**
- [x] Teste de integra√ß√£o: RLS impede User A de ler dados do User B
- [x] Teste de integra√ß√£o: DECIMAL fields retornam `float`, n√£o `Decimal`
- [x] Teste de integra√ß√£o: CRUD completo em cada repository (tracking, finance, memory, chat)
- [x] Teste: session RLS rejeita session sem user_id

**Definition of Done:**
- [x] Python l√™/escreve em todas as tabelas necess√°rias
- [x] RLS funciona: user A n√£o v√™ dados de user B
- [x] DECIMAL ‚Üí float em todas as queries
- [x] CI detecta schema drift quando Drizzle muda e SQLAlchemy n√£o acompanha
- [x] Testes de integra√ß√£o passam

> **Riscos:**
> - DECIMAL handling: Drizzle retorna **string**, SQLAlchemy retorna **`Decimal`** por default. Solu√ß√£o: usar `Numeric(asdecimal=False)` em todos os money fields nos models SQLAlchemy. Testes de integra√ß√£o que comparam outputs dos dois ORMs para as mesmas queries.
> - RLS com SQLAlchemy async pode ter edge cases com connection pooling (`expire_on_commit=False` √© obrigat√≥rio). Testar com m√∫ltiplos users concorrentes.
> - Concurrent writes: ambos os servi√ßos escrevem na mesma tabela (ex: `tracking_entries`). Usar `ON CONFLICT` / upsert patterns. Idempotency keys para write operations via chat.

### Notas

_Conclu√≠do em 2026-02-23._

**Melhorias sobre o plano original:**
- RLS implementado como context managers em `app/db/session.py` (`get_user_session`, `get_service_session`) em vez de middleware HTTP (`app/db/middleware.py` no plano original). Context managers s√£o mais seguros ‚Äî garantem que `SET LOCAL` e a transa√ß√£o estejam sempre no mesmo escopo, e permitem uso direto em workers/scripts sem depender do ciclo HTTP. `get_service_session()` adicional para worker jobs que bypassam RLS via `SET LOCAL role = 'service_role'`
- 22 enums implementados (dos 30 no DB) ‚Äî apenas os referenciados pelas tabelas que Python modela. Enums n√£o utilizados (ex: `vault_item_type`, `notification_type`, `export_status`) ficam de fora at√© que Python precise dessas tabelas
- Colunas `metadata` nos modelos `TrackingEntry`, `Conversation` e `Message` renomeadas no Python (`entry_metadata`, `conversation_metadata`, `message_metadata`) com mapeamento expl√≠cito `mapped_column("metadata", JSON)` porque `metadata` √© atributo reservado do `DeclarativeBase` do SQLAlchemy. A coluna no banco continua `metadata`
- `app/main.py` refatorado para usar `get_async_engine()` e `get_session_factory()` do novo m√≥dulo `app/db/engine`, com `session_factory` armazenado em `app.state`
- `app/dependencies.py` estendido com `get_db_session()` que injeta sess√£o RLS-scoped via FastAPI `Depends()`
- Schema drift check integrado no job `e2e` do CI (ap√≥s migrations, antes do build) ‚Äî requer Supabase rodando, por isso roda no e2e e n√£o no job `python`
- Testes de integra√ß√£o (RLS + repositories) usam flag `--run-db` e s√£o skipped automaticamente no CI sem Supabase. 16 testes unit√°rios (models) passam sem DB

**Verifica√ß√£o local:**
- Python: ruff check (0 errors), ruff format (34 files OK), mypy (0 issues, 26 files), pytest (16 passed, 14 skipped)
- JS/TS: typecheck (10/10 cached) ‚Äî nenhuma regress√£o

---

## M4.3 ‚Äî LangGraph Basic Chat + NestJS Proxy üü¢

**Objetivo:** Primeira mensagem end-to-end pelo Python service: Frontend ‚Üí NestJS ‚Üí Python ‚Üí resposta. Chat funcional sem tools.

**Refer√™ncias:** `docs/ai-python-service-migration-plan.md` ¬ß2, ¬ß4, ¬ß9

**Depend√™ncias:** M4.2

> **Contexto:** Este milestone estabelece o "pipe" completo. Depois que mensagens fluem end-to-end, os milestones seguintes adicionam tools incrementalmente. O frontend N√ÉO muda ‚Äî NestJS proxeia SSE transparentemente.

**Tasks:**

**LangGraph Core:**
- [x] Criar `app/agents/state.py` ‚Äî `AgentState` TypedDict:
  ```python
  class AgentState(TypedDict):
      messages: Annotated[list, add_messages]
      user_id: str
      conversation_id: str
      current_agent: str | None
  ```
- [x] Criar `app/agents/llm.py` ‚Äî LLM factory baseado em `LLM_PROVIDER` env (Gemini/Anthropic)
- [x] Criar `app/agents/domains/general.py` ‚Äî agente conversacional (sem tools, s√≥ responde)
  - Usa LLM factory (model configur√°vel via `LLM_MODEL` env, default `gemini-2.5-flash`)
- [x] Criar `app/agents/graph.py` ‚Äî StateGraph b√°sico:
  - START ‚Üí general_agent ‚Üí save_response ‚Üí END
  - `AsyncPostgresSaver` como checkpointer (persist√™ncia de threads)
  - Import: `from langgraph.checkpoint.postgres.aio import AsyncPostgresSaver`
  - `.setup()` chamado no lifespan do FastAPI (M4.1) ‚Äî cria tabelas `checkpoints`, `checkpoint_blobs`, `checkpoint_writes`, `checkpoint_migrations`
- [x] Criar `app/agents/save_response.py` ‚Äî node que salva mensagem do assistente no DB via SQLAlchemy

**Context Builder (vers√£o simplificada):**
- [x] Criar `app/prompts/system.py` ‚Äî system prompt base:
  - Nome do usu√°rio, timezone, data atual
  - Personalidade conforme `docs/specs/core/ai-personality.md`
- [x] Criar `app/prompts/context_builder.py` (vers√£o m√≠nima):
  - User memories formatadas do `user_memories` table
  - Apenas campos essenciais: bio, goals, topOfMind
  - Context builder completo ser√° expandido em M4.6

**SSE Streaming (via `sse-starlette`):**
- [x] Criar `app/api/routes/chat.py`:
  - POST `/chat/invoke` ‚Äî recebe `{ user_id, conversation_id, message }`, retorna SSE stream
  - Usar `EventSourceResponse` de `sse-starlette` (FastAPI n√£o tem SSE built-in)
  - SSE events compat√≠veis com formato atual do frontend:
    - `{ data: { content: "...", done: false } }` ‚Äî text delta
    - `{ data: { content: "...", done: true } }` ‚Äî resposta final
    - `{ data: { content: "", done: true, error: "..." } }` ‚Äî erro (matching NestJS format)
- [x] Carregar hist√≥rico de mensagens do DB quando n√£o existe checkpoint (conversas originadas no TypeScript)

**NestJS Proxy:**
- [x] Consumir `pythonAiSchema` no API module via `AppConfigService` (getters: `pythonAiUrl`, `serviceSecret`, `usePythonAi`)
- [x] Criar m√©todo `proxyToPython()` no `chat.service.ts`:
  - POST para Python `/chat/invoke` com Bearer `SERVICE_SECRET`
  - Parseia SSE stream do Python via `ReadableStream` reader e emite para o frontend
- [x] Quando `USE_PYTHON_AI=true`: proxy para Python. Quando `false`: usa l√≥gica TypeScript atual

**Testes:**
- [x] Teste E2E: enviar mensagem simples ‚Üí receber resposta via Python (SSE streaming)
- [x] Teste: save response node persiste mensagem no DB
- [x] Teste: context builder inclui user memories no system prompt
- [x] Teste: feature flag alterna corretamente entre TypeScript e Python
- [x] Teste: frontend recebe SSE events no formato esperado (sem mudan√ßas no frontend)

**Definition of Done:**
- [x] Com `USE_PYTHON_AI=true`, chat funciona end-to-end pelo Python (sem tools)
- [x] Com `USE_PYTHON_AI=false`, sistema TypeScript continua funcionando normalmente
- [x] Frontend n√£o percebe diferen√ßa (mesmos SSE events)
- [x] Mensagens s√£o salvas no DB pelo Python

> **Decis√£o tomada:** Feature flag via environment variable (`USE_PYTHON_AI`), j√° definida em `packages/config/src/schemas/python-ai.ts`.

**Notas (2026-02-23):**
Implementa√ß√£o completa do pipe Python end-to-end. **Python (16 arquivos criados, 2 modificados):** `app/agents/` (state.py, llm.py, graph.py, save_response.py, domains/general.py) ‚Äî StateGraph com `general_agent ‚Üí save_response`, `AsyncPostgresSaver` checkpointer, LLM factory suportando Gemini + Anthropic via `LLM_PROVIDER` env. `app/prompts/` (system.py, context_builder.py) ‚Äî system prompt completo com personalidade ¬ß4, guardrails ¬ß7 (CVV 188, Ligue 180), counselor mode ¬ß5.1, user memories (bio, occupation, family, goals, challenges, topOfMind, values, communication_style). `app/api/routes/chat.py` ‚Äî POST `/chat/invoke` com `EventSourceResponse`, checkpoint-or-DB-fallback para conversas originadas no TypeScript (carrega hist√≥rico do DB se checkpoint n√£o existe), `convert_db_messages()` com IDs preservados para dedup do `add_messages` reducer, `await request.is_disconnected()` para disconnect detection. Error SSE retorna mensagem gen√©rica "Erro ao gerar resposta" (n√£o vaza `str(e)` ao cliente). Modificados: `app/main.py` (build graph no lifespan + registra chat router), `app/dependencies.py` (get_checkpointer helper). Reusa c√≥digo existente de M4.2: `get_user_session()` (RLS), `ChatRepository`, `UserRepository`, `get_settings()`. **NestJS (3 arquivos modificados):** `config.service.ts` (3 getters: pythonAiUrl, serviceSecret, usePythonAi), `chat.service.ts` (`AppConfigService` injetado como 1¬∫ param do constructor + feature flag check no topo de `processStreamResponse()` + `proxyToPython()` com native `fetch` + `ReadableStream` reader para SSE parsing + `reader.releaseLock()` no finally), `chat.service.spec.ts` (mock do `AppConfigService` com `usePythonAi: false`). **Testes:** 26 Python (pytest) ‚Äî test_llm_factory (4), test_agents (4), test_context_builder (6), test_chat_endpoint (5), test_graph (2), conftest + existing (5). 853 NestJS (jest). Todos passando. `ruff check .` + `mypy app/` + `pnpm typecheck` + `pnpm lint` limpos.

---

## M4.4 ‚Äî Tracking Tools + Habits + Confirmation Framework üü¢

**Objetivo:** Primeiros tools funcionando no Python com confirma√ß√£o via `interrupt()`. Tracking √© o dom√≠nio mais simples ‚Äî ideal para validar o framework.

**Refer√™ncias:** `docs/ai-python-service-migration-plan.md` ¬ß4.5, `docs/specs/domains/tracking.md`, `ADR-015`

**Depend√™ncias:** M4.3

> **Contexto:** O framework de confirma√ß√£o com `interrupt()` / `Command(resume=)` do LangGraph (import de `langgraph.types`) substitui o sistema atual de Redis TTL (5 min) do `confirmation-state.service.ts`. A persist√™ncia passa a ser via PostgreSQL (`AsyncPostgresSaver`), sem TTL por default. Isso √© uma **melhoria**: confirma√ß√µes n√£o expiram, sobrevivem a crashes do processo, e o thread pode ser retomado a qualquer momento. Este milestone valida o padr√£o que ser√° usado por todos os write tools.
>
> **Mudan√ßa de infra:** Confirmation state migra de Redis (ioredis SETEX 5min) ‚Üí PostgreSQL (LangGraph checkpoint tables). Python **n√£o precisa de Redis** para confirma√ß√µes.

**Tasks:**

**Confirmation Framework:**
- [x] Criar `app/tools/common/confirmation.py`:
  - Wrapper de `interrupt()` que padroniza o formato de confirma√ß√£o
  - `generate_confirmation_message()` ‚Äî mensagens em PT (ex: "Registrar peso: 75 kg em 2026-02-23?")
  - `generate_batch_confirmation_message()` ‚Äî batch (ex: "Remover 3 registros?")
  - Constraint de idempot√™ncia documentada: c√≥digo antes de `interrupt()` re-executa no resume ‚Äî sem side effects antes do interrupt
  - `expiresAt` = now + 24h (soft limit ‚Äî checkpoints PostgreSQL n√£o expiram, frontend usa para UX)
- [x] Criar `app/tools/common/confirmable_tool_node.py` ‚Äî `ConfirmableToolNode`:
  - Substitui `ToolNode` do `create_react_agent` para agents com WRITE tools
  - Separa READ tools (executa imediatamente) de WRITE tools (batch em √∫nico `interrupt()`)
  - 3 a√ß√µes no resume: `confirm` (executa), `reject` (cancela), `edit` (corrige args e executa)
  - Emite SSE events `tool_calls` (antes) e `tool_result` (ap√≥s cada tool)
- [x] Adicionar endpoint POST `/chat/resume` em `app/api/routes/chat.py`:
  - Recebe `{ thread_id, action: "confirm" | "reject" | "edit", edited_args?: dict }`
  - Executa `Command(resume={"action": ..., "args": ...})`
  - Retorna SSE stream com resultado (reutiliza l√≥gica de streaming)
- [x] Atualizar streaming em `app/api/routes/chat.py`:
  - `stream_mode="messages"` ‚Üí `stream_mode=["messages", "updates"]` para detectar `__interrupt__`
  - Chunks "updates" com `__interrupt__` ‚Üí SSE `confirmation_required` + `{ done: true, awaitingConfirmation: true }`
  - Chunks "updates" com tool data ‚Üí SSE `tool_calls` e `tool_result`
- [x] Implementar detec√ß√£o de confirma√ß√£o por mensagem em `/chat/invoke`:
  - Verificar interrupt pendente via `graph.get_state(config)` antes de processar
  - Classificar intent via LLM: confirm / reject / correction / unrelated
  - Confirm ‚Üí `Command(resume={"action": "confirm"})`; Reject ‚Üí `Command(resume={"action": "reject"})`
  - Correction ‚Üí `Command(resume={"action": "edit", "args": corrected_args})`
  - Unrelated ‚Üí rejeitar pendente + processar como nova mensagem
- [x] **NestJS:** Proxy de confirma√ß√£o para Python:
  - `confirm/:confirmationId` ‚Üí Python `/chat/resume` action "confirm"
  - `reject/:confirmationId` ‚Üí Python `/chat/resume` action "reject"
  - Proxy SSE response de volta ao frontend
- [x] SSE event `confirmation_required` compat√≠vel com frontend atual:
  ```json
  {
    "type": "confirmation_required",
    "data": {
      "confirmationId": "uuid",
      "toolName": "record_metric",
      "toolArgs": { "type": "water", "value": 2000 },
      "message": "Registrar √°gua: 2000ml em 2026-02-22",
      "expiresAt": "ISO string"
    }
  }
  ```
- [x] SSE event `tool_result` ap√≥s execu√ß√£o:
  ```json
  { "type": "tool_result", "data": { "toolName": "record_metric", "result": "...", "success": true } }
  ```

**Tracking Tools (4 tools):**
- [x] Criar `app/tools/tracking/record_metric.py` ‚Äî registra m√©trica (WRITE, confirmation)
  - Params: metric_type, value, date (opcional, default hoje), unit (opcional, auto-fill), notes (opcional)
  - Valida√ß√£o de ranges por tipo (weight 0.1‚Äì500, water 1‚Äì20000, mood 1‚Äì10, sleep 0.1‚Äì24, etc.)
  - Mapeamento autom√°tico metric_type ‚Üí area/sub_area (ex: weight‚Üíhealth/physical, mood‚Üíhealth/mental)
  - Usa TrackingRepository para INSERT, retorna JSON com entryId
- [x] Criar `app/tools/tracking/get_history.py` ‚Äî hist√≥rico de m√©tricas (READ)
  - Params: metric_type, days (opcional, default 30)
  - Retorna entries com UUIDs (para update/delete), stats (count, avg, min, max, sum, trend), varia√ß√£o %
  - Inclui `_note` instruindo o LLM a usar IDs exatos para update/delete
- [x] Criar `app/tools/tracking/update_metric.py` ‚Äî atualiza m√©trica existente (WRITE, confirmation)
  - Params: entry_id (UUID exato), value, unit (opcional), reason (opcional ‚Äî audit trail)
  - Ownership verificada via RLS (SET LOCAL request.jwt.claim.sub)
- [x] Criar `app/tools/tracking/delete_metric.py` ‚Äî deleta m√©trica (WRITE, confirmation)
  - Params: entry_id (UUID exato), reason (opcional)
  - Delete individual (batch removido ‚Äî LLM alucinava IDs em batch, mesma decis√£o do TypeScript M2.1)

**Habit Tools (2 tools):**
- [x] Criar `app/tools/tracking/record_habit.py` ‚Äî registra h√°bito (WRITE, confirmation)
  - Params: habit_name, date (opcional, default hoje), notes (opcional)
  - Fuzzy match por nome: exact case-insensitive ‚Üí contains bidirecional
  - Detec√ß√£o de duplicata (j√° completado na data), c√°lculo de streak ap√≥s registro
- [x] Criar `app/tools/tracking/get_habits.py` ‚Äî lista h√°bitos (READ)
  - Params: include_streaks (bool, default true), include_today_status (bool, default true)
  - Retorna h√°bitos com streak atual, longest streak, status de hoje

> **Nota:** `analyze_context` est√° mapeado para o executor `'memory'` no c√≥digo (chat.service.ts:121), n√£o tracking. Esse tool √© implementado em M4.6 (Memory Tools).

**Tracking Agent:**
- [x] Criar `app/agents/domains/tracking.py`:
  - Exporta `TRACKING_TOOLS` (6 tools) e `TRACKING_WRITE_TOOLS` (4 nomes) para uso pelo graph builder
  - Graph constru√≠do via `build_domain_agent_graph()` factory reutiliz√°vel (agent_factory.py)
  - System prompt vem do context_builder.py (centralizado, n√£o embarcado no agente)
- [x] Atualizar graph principal: `build_domain_agent_graph(llm, TRACKING_TOOLS, TRACKING_WRITE_TOOLS, checkpointer)`
  - Grafo: agent ‚Üí should_continue ‚Üí tools (ConfirmableToolNode) ‚Üí agent (loop) ou save_response ‚Üí END
  - Loop guard em agent_node previne Gemini de re-chamar WRITE tool ap√≥s sucesso (for√ßa resposta textual)

**Confirmation Flow Hardening (bugs encontrados durante E2E testing):**
- [x] Salvar mensagem de confirma√ß√£o no DB ao detectar `__interrupt__` no stream (espelha NestJS L1189-1201)
  - Mensagem persiste ap√≥s page refresh. Metadata inclui `pendingConfirmation` (confirmationId, toolName, toolArgs)
- [x] Reject usa `graph.ainvoke()` em vez de `graph.astream()` ‚Äî resposta curta enviada como evento SSE √∫nico
  - Corrige bug onde resposta de rejei√ß√£o n√£o aparecia no frontend (perdia-se no pipeline streaming multi-camada)
- [x] Loop guard para re-chamada de WRITE tools ‚Äî Gemini chamava `record_metric` em loop ap√≥s sucesso
  - Detecta ToolMessage de WRITE tool seguida de nova chamada ao mesmo tool; for√ßa AIMessage textual
- [x] Guard de content blocks vazios do Gemini ‚Äî `[{"type":"text","text":""}]` √© truthy mas sem conte√∫do
  - `tokens_streamed` s√≥ √© setado como `True` quando token extra√≠do √© non-empty
- [x] `skip_save_response` para intent "unrelated" ‚Äî rejei√ß√£o silenciosa n√£o salva "Opera√ß√£o cancelada" como mensagem separada
  - Nova mensagem do fluxo normal inclui men√ß√£o ao cancelamento em resposta √∫nica combinada
- [x] JSON format para ToolMessage de rejei√ß√£o ‚Äî `json.dumps({"success": False, "message": "..."})` em vez de plain text
  - Gemini interpretava plain text como resultado de tool a ser re-processado
- [x] Frontend: safety net `useEffect` em `use-chat.ts` ‚Äî quando `done:true` chega sem streaming content, chama `finishStreaming()` diretamente
  - Cobre edge case onde backend termina sem ter feito stream de tokens (ex: resposta via ainvoke)

**Testes:**
- [x] Teste: pipeline SSE de interrupt ‚Äî salva confirma√ß√£o no DB (`test_invoke_interrupt_saves_confirmation_to_db`), reject via ainvoke envia content (`test_invoke_reject_uses_ainvoke_and_sends_content`). Nota: testa pipeline de streaming, n√£o o tool record_metric com ConfirmableToolNode end-to-end (coberto por E2E manual)
- [x] Teste: get_tracking_history retorna dados corretos (`test_get_history_returns_formatted_entries`)
- [x] Teste: update_metric retorna erro quando entry n√£o existe (`test_update_metric_not_found`). Nota: ownership real √© garantida por RLS (`SET LOCAL`) mas n√£o h√° teste de integra√ß√£o com 2 users ‚Äî requer DB real
- [x] Teste: record_habit com fuzzy match de nome (`test_record_habit_fuzzy_matching`, `test_record_habit_already_completed`)
- [x] Teste: SSE events de confirma√ß√£o compat√≠veis com frontend (`test_invoke_interrupt_saves_confirmation_to_db`, `test_resume_confirm_returns_sse`)
- [x] Teste: flow completo "Registra 2L de √°gua hoje" end-to-end (verifica√ß√£o manual ‚Äî 4 cen√°rios: confirm, reject, unrelated, e reject‚Üíre-register‚Üíconfirm)
- [x] Teste: loop guard previne re-chamada de WRITE tool (`test_loop_guard_breaks_write_tool_re_call`)
- [x] Teste: empty Gemini blocks n√£o escondem loop guard (`test_invoke_empty_gemini_blocks_do_not_shadow_loop_guard`)
- [x] Teste: DB failure no interrupt n√£o quebra stream (`test_invoke_interrupt_db_failure_still_streams`)

**Definition of Done:**
- [x] "Registra 2L de √°gua hoje" funciona end-to-end pelo Python (card de confirma√ß√£o no frontend)
- [x] Confirma√ß√£o, rejei√ß√£o, mensagem n√£o-relacionada e re-registro funcionam corretamente
- [x] Dados escritos pelo Python aparecem no dashboard (persistem ap√≥s page refresh)
- [x] Todos os 6 tools passam em testes isolados (82 passed, 14 skipped)

### Notas

_Conclu√≠do em 2026-02-23._

**Desvios do plano original:**
- `delete_metric` batch removido do tool (reposit√≥rio mant√©m `delete_batch()` para uso futuro). Decis√£o alinhada com TypeScript M2.1 ‚Äî LLM alucinava IDs quando recebia opera√ß√£o batch. Chamadas paralelas de `delete_metric` individual com UUIDs reais do `get_history` √© mais confi√°vel
- `update_metric` n√£o suporta altera√ß√£o de `entry_date` (plano previa). Params reais: `entry_id`, `value`, `unit?`, `reason?`. `reason` adiciona audit trail de corre√ß√µes
- `record_habit` sem param `completed` (plano previa). Sempre registra como conclu√≠do ‚Äî "registrar h√°bito" no chat implica completude. Param `notes` adicionado
- Tracking agent implementado como bridge (`tracking.py` exporta tools/write_tools) + factory reutiliz√°vel (`agent_factory.py`) em vez de graph customizado por dom√≠nio. Factory ser√° reusada por M4.5 (Finance) e M4.6 (Memory) sem duplica√ß√£o

**Melhorias sobre o plano original:**
- `record_metric` inclui valida√ß√£o de ranges por tipo (weight 0.1‚Äì500 kg, water 1‚Äì20000 ml, mood 1‚Äì10, etc.) ‚Äî n√£o previsto no plano
- `get_history` retorna estat√≠sticas completas (count, avg, min, max, sum, trend, varia√ß√£o %) + `_note` instruindo LLM a usar IDs exatos ‚Äî n√£o previsto no plano
- `get_habits` retorna streaks (atual e recorde) e status de hoje com params configur√°veis ‚Äî excede spec original
- `build_domain_agent_graph()` factory em `agent_factory.py` ‚Äî pattern reutiliz√°vel com agent ‚Üí ConfirmableToolNode ‚Üí agent loop + save_response, compilado com checkpointer. Elimina duplica√ß√£o para M4.5/M4.6
- Loop guard no agent_node ‚Äî detecta quando Gemini re-chama WRITE tool ap√≥s ToolMessage de sucesso e for√ßa resposta textual. Essencial para estabilidade com Gemini
- 7 bugs de confirmation flow descobertos e corrigidos durante E2E testing (vide se√ß√£o "Confirmation Flow Hardening")
- Frontend `use-chat.ts` safety net ‚Äî `useEffect` que detecta `done:true` sem conte√∫do streamed e chama `finishStreaming()` direto

**Verifica√ß√£o local:**
- Python: ruff check (0 errors), mypy (0 issues, 51 files), pytest (82 passed, 14 skipped)
- TypeScript: typecheck compilado sem erros
- E2E manual: 4 cen√°rios testados (confirm, reject, unrelated intent, reject‚Üíre-register‚Üíconfirm) ‚Äî todos funcionando

---

## M4.5 ‚Äî Finance Tools üü¢

**Objetivo:** Todos os 11 tools financeiros migrados para Python. Maior executor em linhas de c√≥digo (~1.047L no TypeScript).

**Refer√™ncias:** `docs/specs/domains/finance.md`, `apps/api/src/modules/finance/application/services/finance-tool-executor.service.ts`

**Depend√™ncias:** M4.4

> **Contexto:** O `finance-tool-executor.service.ts` √© o maior executor (1.047 linhas) com l√≥gica complexa de agrega√ß√£o, c√°lculos mensais, proje√ß√µes e breakdown por categoria. Requer aten√ß√£o especial ao handling de DECIMAL (string no Drizzle, float no Python).

**Tasks:**

**Finance Tools ‚Äî Shared Helpers:**
- [x] Criar `app/tools/finance/_helpers.py` ‚Äî TZ utils + ensure_recurring
  - Fun√ß√µes: get_current_month_tz, get_today_tz, get_days_until_due_day, resolve_month_year, get_previous_month, months_diff
  - `ensure_recurring_for_month()` ‚Äî gera√ß√£o lazy de itens recorrentes (bills, incomes, expenses)
- [x] Adicionar m√©todos ao `app/db/repositories/finance.py`:
  - get_debt_by_id, get_debt_payments_for_debts (batch), sum_payments_by_month_year

**Finance Tools ‚Äî READ (9 tools):**
- [x] Criar `app/tools/finance/get_finance_summary.py` ‚Äî resumo financeiro mensal
  - Params: period (Literal["current_month", "last_month", "year"], default: "current_month")
  - Retorna: KPIs (income, budgeted, spent, balance), breakdown por entidade, ensure_recurring para 3 tabelas
- [x] Criar `app/tools/finance/get_pending_bills.py` ‚Äî contas pendentes
  - Params: month, year (opcionais, default: m√™s atual via TZ)
  - Retorna: bills com status pending, daysUntilDue, reclassifica overdue, ensure_recurring
- [x] Criar `app/tools/finance/get_bills.py` ‚Äî todas as contas com status
  - Params: month, year, status (opcionais, status default: "all")
  - Retorna: lista de bills com paid/pending/overdue, daysUntilDue, ensure_recurring
- [x] Criar `app/tools/finance/get_expenses.py` ‚Äî despesas vari√°veis
  - Params: month, year (opcionais)
  - Retorna: lista de expenses com variance, percentUsed, ensure_recurring
- [x] Criar `app/tools/finance/get_incomes.py` ‚Äî receitas
  - Params: month, year (opcionais)
  - Retorna: lista de incomes com variance, receivedCount/pendingCount, ensure_recurring
- [x] Criar `app/tools/finance/get_investments.py` ‚Äî investimentos
  - Params: nenhum
  - Retorna: lista com progress, remainingToGoal, monthsToGoal
- [x] Criar `app/tools/finance/get_debt_progress.py` ‚Äî progresso de d√≠vidas
  - Params: debt_id (opcional), month_year (opcional, YYYY-MM)
  - Retorna: total pago, percentual, parcelas restantes, proje√ß√£o de quita√ß√£o, regras de visibilidade ¬ß3.6
- [x] Criar `app/tools/finance/get_debt_payment_history.py` ‚Äî hist√≥rico de pagamentos de d√≠vida
  - Params: debt_id (obrigat√≥rio), limit (opcional, default 50)
  - Retorna: lista de pagamentos com paidEarly flag, contexto da d√≠vida
- [x] Criar `app/tools/finance/get_upcoming_installments.py` ‚Äî pr√≥ximas parcelas
  - Params: month_year (opcional, YYYY-MM, default: m√™s atual)
  - Retorna: installments com status (paid/paid_early/overdue/pending), regras de visibilidade ¬ß3.6

**Finance Tools ‚Äî WRITE (2 tools):**
- [x] Criar `app/tools/finance/mark_bill_paid.py` ‚Äî marcar conta como paga (WRITE, confirmation)
  - Params: bill_id, paid_date (opcional, default: hoje)
  - Verifica que bill pertence ao user e est√° pendente
- [x] Criar `app/tools/finance/create_expense.py` ‚Äî criar despesa vari√°vel (WRITE, confirmation)
  - Params: description, amount, category, date (opcional)
  - Mapeamento de categorias PT‚ÜíEN preservado (alimentacao‚Üífood, transporte‚Üítransport, etc.)

**Finance Agent Bridge + Graph:**
- [x] Criar `app/agents/domains/finance.py` ‚Äî bridge (re-export FINANCE_TOOLS, FINANCE_WRITE_TOOLS)
- [x] Atualizar `app/agents/graph.py` ‚Äî merge finance + tracking tools no grafo √∫nico

**L√≥gica de agrega√ß√£o:**
- [x] Implementar c√°lculos mensais: income - expenses - bills = balance
- [x] Implementar breakdown por categoria com percentuais
- [x] Implementar proje√ß√µes baseadas em hist√≥rico
- [x] Garantir que todos os c√°lculos usam `float` (n√£o `Decimal` nem `string`)

**Testes:**
- [x] Teste: cada READ tool isoladamente com mocks (41 testes)
- [x] Teste: get_finance_summary com KPI aggregation e breakdown correto
- [x] Teste: helpers TZ (20 testes) + ensure_recurring (4 testes)
- [x] Teste: mark_bill_paid com confirma√ß√£o (5 testes: success, not_found, already_paid, overdue_success, invalid_uuid)
- [x] Teste: create_expense com mapeamento de categoria PT‚ÜíEN (5 testes: success, category_mapping 7x, defaults, invalid_category, budgeted_fallback)
- [x] Teste cross-ORM: coberto por M4.2 integration tests (DECIMAL‚Üífloat) + E2E manual verification
- [x] Teste: queries complexas ‚Äî verificadas via E2E manual (Playwright)

**Definition of Done:**
- [x] Todos os 11 finance tools funcionam no Python
- [x] Valores financeiros s√£o precisos (cross-ORM verification)
- [x] Confirma√ß√£o funciona para mark_bill_paid e create_expense
- [x] Categorias PT‚ÜíEN mapeadas corretamente

**Notas (2026-02-23) ‚Äî READ tools session:**
- 9 READ tools implementados: get_finance_summary, get_pending_bills, get_bills, get_expenses, get_incomes, get_investments, get_debt_progress, get_debt_payment_history, get_upcoming_installments
- `_helpers.py`: TZ utils (6 fun√ß√µes) + `ensure_recurring_for_month()` gen√©rico para 3 entidades (Bill, Income, VariableExpense) via `_ENTITY_CONFIG` dict
- `__init__.py`: exports FINANCE_TOOLS (list de 9) e FINANCE_WRITE_TOOLS (set vazio, preparado para WRITE tools)
- Repository: +3 m√©todos (get_debt_by_id, get_debt_payments_for_debts batch com guard lista vazia, sum_payments_by_month_year com func.coalesce)
- Graph atualizado: ALL_TOOLS = TRACKING_TOOLS + FINANCE_TOOLS (15 tools total)
- `pyproject.toml`: adicionado `"app/tools/finance/*.py" = ["TCH002"]` per-file-ignores (RunnableConfig necess√°rio em runtime, mesmo padr√£o de tracking)
- 41 testes unit√°rios (mocked), 112 total suite passando (ruff + mypy + pytest limpos)
- Corre√ß√µes do milestone: params alinhados com NestJS (period em vez de month/year para summary, month_year YYYY-MM para debts, limit para payment_history)
- E2E manual via Playwright: 9/9 tools testados com dados reais do seed, todos os valores conferem com o banco de dados
- Verifica√ß√£o de tool calls via LangGraph checkpoints: confirmado que a IA chama tools corretamente (paralelo quando poss√≠vel, sequencial para resolver IDs como debt_id)
- WRITE tools (mark_bill_paid, create_expense) ser√£o implementados na pr√≥xima sess√£o

**Notas (2026-02-23) ‚Äî WRITE tools session:**
- 2 WRITE tools implementados: mark_bill_paid, create_expense
- `mark_bill_paid`: validates UUID, checks bill exists (via new `get_bill_by_id` repo method), verifies status is pending/overdue, defaults paid_date to today in user TZ
- `create_expense`: 7 PT‚ÜíEN category mappings (alimentacao‚Üífood, etc.), defaults expected_amount to actual_amount or 0, generates UUID client-side
- Confirmation templates fixed: old templates used mismatched PT arg names ({nome}, {data}, {valor}, {categoria}) that never matched Python tool params ‚Äî always fell back to generic. New templates use actual Python param names or static messages
- `_OPTIONAL_DEFAULTS` extended for mark_bill_paid and create_expense
- `FINANCE_WRITE_TOOLS = {"mark_bill_paid", "create_expense"}` ‚Äî graph.py already merges with TRACKING_WRITE_TOOLS via set union
- 12 new unit tests (5 mark_bill_paid + 5 create_expense + 2 graph integration), confirmation tests updated
- All checks pass: ruff (0), mypy (0 issues, 65 files), pytest (134 passed, 14 skipped)
- M4.5 complete: 11 finance tools (9 READ + 2 WRITE) fully migrated from TypeScript

---

## M4.6 ‚Äî Memory Tools + Context Builder Completo üî¥

**Objetivo:** Tools de mem√≥ria migrados e context builder completo (system prompt com todas as instru√ß√µes de tools).

**Refer√™ncias:** `docs/specs/domains/memory.md`, `docs/specs/core/ai-personality.md` ¬ß4-8, `ADR-012`

**Depend√™ncias:** M4.4

> **Nota:** Este milestone pode rodar **em paralelo** com M4.5 (Finance Tools).

**Tasks:**

**Memory Tools (3 tools):**
- [ ] Criar `app/tools/memory/search_knowledge.py` ‚Äî busca em knowledge_items (READ)
  - Params: query, type (opcional), area (opcional), sub_area (opcional)
  - Busca por keyword/filtros em knowledge_items
- [ ] Criar `app/tools/memory/add_knowledge.py` ‚Äî adicionar fato/prefer√™ncia/insight (WRITE, confirmation)
  - Params: content, type (fact/preference/insight), area, sub_area (opcionais)
  - Detecta duplicatas antes de inserir
- [ ] Criar `app/tools/memory/analyze_context.py` ‚Äî an√°lise de contexto mem√≥ria (READ)
  - Params: query
  - Retorna knowledge_items relevantes para contexto da conversa

**Memory Agent:**
- [ ] Criar `app/agents/domains/memory.py`:
  - Graph customizado com `ConfirmableToolNode` (confirmation de write tools)
  - 3 tools (2 READ + 1 WRITE)
  - System prompt com regras de mem√≥ria (tipos de knowledge, √°reas, quando adicionar vs buscar)

**Context Builder Completo:**
- [ ] Expandir `app/prompts/context_builder.py` (iniciado em M4.3):
  - User memories completas: bio, occupation, family, goals, challenges, topOfMind, values, learnedPatterns
  - Tool instructions completas (~88 linhas):
    - Memory tools: quando usar search_knowledge vs add_knowledge
    - Tracking tools: confirma√ß√£o obrigat√≥ria, nunca inventar IDs, timezone do user
    - Finance tools: mapeamento de categorias, formata√ß√£o monet√°ria
    - Habits tools: match por nome, regras de registro
  - Regras expl√≠citas: "sempre confirme antes de registrar", "nunca invente IDs para update/delete"
  - Counselor mode: instru√ß√µes especiais para conversas tipo "counselor"
- [ ] Integrar context builder no graph principal (substituir vers√£o simplificada de M4.3)

**Testes:**
- [ ] Teste: search_knowledge com filtros por type/area
- [ ] Teste: add_knowledge com detec√ß√£o de duplicata
- [ ] Teste: context builder produz system prompt equivalente ao TypeScript
- [ ] Teste: counselor mode altera instru√ß√µes corretamente
- [ ] Teste: tool instructions est√£o presentes e completas no prompt

**Definition of Done:**
- [ ] Memory tools funcionam no Python
- [ ] Context builder produz system prompt completo e equivalente ao TypeScript
- [ ] "O que voc√™ sabe sobre mim?" retorna informa√ß√µes corretas das user_memories

---

## M4.7 ‚Äî Multi-Agent: Triage + Domain Routing üî¥

**Objetivo:** Arquitetura multi-agente com triage inteligente roteando mensagens para agentes especializados.

**Refer√™ncias:** `docs/ai-python-service-migration-plan.md` ¬ß4

**Depend√™ncias:** M4.4, M4.5, M4.6

> **Contexto:** At√© este ponto, o graph usa um √∫nico agente com todos os tools. Este milestone implementa a arquitetura final: triage node classifica a inten√ß√£o e roteia para domain agents especializados. Isso permite usar modelo r√°pido (Flash) para triagem e modelo capaz (Pro) para execu√ß√£o, reduzindo custo e lat√™ncia.

**Tasks:**

**Triage Node:**
- [ ] Criar `app/agents/triage.py`:
  - Usa modelo r√°pido: `ChatGoogleGenerativeAI(model="gemini-2.0-flash")`
  - Triage prompt com exemplos de roteamento:
    - "Registra 2L de √°gua" ‚Üí tracking_agent
    - "Quanto gastei este m√™s?" ‚Üí finance_agent
    - "O que voc√™ sabe sobre mim?" ‚Üí memory_agent
    - "Estou me sentindo ansioso" ‚Üí wellbeing_agent
    - "Bom dia!" ‚Üí general_agent
  - Retorna `{ current_agent: "tracking_agent" | "finance_agent" | "memory_agent" | "wellbeing_agent" | "general_agent" }`

**Wellbeing Agent (novo):**
- [ ] Criar `app/agents/domains/wellbeing.py`:
  - Sem tools (modo counselor puro)
  - System prompt com instru√ß√µes de counselor mode: reflex√£o profunda, perguntas explorat√≥rias, menos emojis

**Graph Atualizado:**
- [ ] Atualizar `app/agents/graph.py`:
  - START ‚Üí triage ‚Üí conditional_edges ‚Üí [tracking_agent, finance_agent, memory_agent, wellbeing_agent, general_agent] ‚Üí save_response ‚Üí END
  - `route_to_agent()` baseado em `state["current_agent"]`
  - Fallback para `general_agent` quando triage retorna inten√ß√£o desconhecida

**Agent Registry:**
- [ ] Cada domain agent usa graph customizado com `ConfirmableToolNode` (WRITE tools) ou `create_react_agent()` (agents sem tools):
  - `tracking_agent`: 6 tools (M4.4)
  - `finance_agent`: 11 tools (M4.5)
  - `memory_agent`: 3 tools (M4.6)
  - `wellbeing_agent`: 0 tools (counselor mode)
  - `general_agent`: 0 tools (conversacional)

> **Nota sobre `create_react_agent`:** Verificado via Context7 (Fev 2026): `create_react_agent` de `langgraph.prebuilt` √© a API est√°vel atual. Sem evid√™ncia de deprecation. Usar `create_react_agent` para agents sem WRITE tools (general, wellbeing). Para agents com WRITE tools (tracking, finance, memory), usar graph customizado com `ConfirmableToolNode` para suportar batch confirmation.

**Testes:**
- [ ] Teste: 20+ mensagens classificadas corretamente pelo triage (cobrindo todos os 5 agents)
- [ ] Teste: mensagens amb√≠guas caem no general_agent
- [ ] Teste: mensagens multi-dom√≠nio ("como estou financeiramente e na sa√∫de?") ‚Äî definir estrat√©gia (rota para o primeiro, ou executa sequencialmente)
- [ ] Teste: wellbeing agent responde com tom de counselor
- [ ] Teste: triage com modelo Flash √© significativamente mais r√°pido que Pro

**Definition of Done:**
- [ ] Mensagens s√£o roteadas para o agente correto
- [ ] Cada agente executa seus tools especializados
- [ ] Triage usa modelo r√°pido, agents usam modelo capaz
- [ ] Fallback funciona para inten√ß√µes amb√≠guas

---

## M4.8 ‚Äî Workers: Memory Consolidation + Contradiction Detection üî¥

**Objetivo:** Migrar jobs ass√≠ncronos (memory consolidation, contradiction detection) para Python, mantendo BullMQ como scheduler.

**Refer√™ncias:** `docs/ai-python-service-migration-plan.md` ¬ß11 Fase 3, `docs/specs/domains/memory.md`

**Depend√™ncias:** M4.6

> **Contexto:** `memory-consolidation.processor.ts` (557L) e `contradiction-detector.adapter.ts` (435L) usam LLM para extrair fatos de conversas e detectar contradi√ß√µes. A estrat√©gia recomendada √© manter BullMQ no NestJS como scheduler e chamar Python via HTTP para a l√≥gica de AI. Isso minimiza mudan√ßas na infraestrutura de jobs.

**Tasks:**

**Memory Consolidation:**
- [ ] Criar `app/workers/consolidation.py`:
  - Recebe: `{ user_id, timezone, date }`
  - Busca mensagens desde √∫ltima consolida√ß√£o (via ChatRepository)
  - Usa LLM para extrair fatos, prefer√™ncias, insights das mensagens
  - Atualiza `user_memories`: bio, occupation, family, goals, challenges, topOfMind, values, learnedPatterns
  - Cria novos `knowledge_items` (com contradiction detection)
  - Atualiza `knowledge_items` existentes quando informa√ß√£o evolui
  - Registra consolidation log em `memory_consolidations`
- [ ] Criar endpoint POST `/workers/consolidation` em `app/api/routes/workers.py`:
  - Auth via SERVICE_SECRET
  - Recebe job data, executa consolidation, retorna resultado
  - Retorna: `{ usersProcessed, usersConsolidated, usersSkipped, errors, completedAt }`

**Contradiction Detection:**
- [ ] Criar `app/memory/contradiction.py`:
  - Single item: "novo fato torna fato existente obsoleto?"
  - Batch items: check novo fato contra 3+ fatos existentes em uma chamada LLM
  - Parse JSON response do LLM com fallback para output truncado
  - Retorna: `{ is_contradiction, confidence, explanation }`
- [ ] Integrar com consolidation: antes de salvar knowledge_item, detectar contradi√ß√µes

**NestJS Bridge:**
- [ ] Atualizar `memory-consolidation.processor.ts`:
  - Quando `USE_PYTHON_AI=true`: POST para Python `/workers/consolidation` via HTTP
  - Quando `false`: executa l√≥gica TypeScript atual
  - BullMQ scheduler permanece no NestJS (sem mudan√ßas no cron/trigger)

**Testes:**
- [ ] Teste: consolidation extrai fatos corretos de conversas
- [ ] Teste: contradictions detectadas (ex: "gosta de caf√©" ‚Üí "parou de tomar caf√©")
- [ ] Teste: user_memories atualizadas corretamente ap√≥s consolidation
- [ ] Teste: knowledge_items criados sem duplicatas
- [ ] Teste: endpoint /workers/consolidation retorna resultado esperado
- [ ] Teste: batch contradiction detection com m√∫ltiplos fatos

**Definition of Done:**
- [ ] Consolidation job roda via BullMQ ‚Üí HTTP ‚Üí Python ‚Üí resultado
- [ ] Fatos extra√≠dos corretamente de conversas
- [ ] Contradictions detectadas com confian√ßa adequada
- [ ] Resultado equivalente ao sistema TypeScript

> **Decis√£o tomada:** NestJS BullMQ mant√©m o scheduling e chama Python via HTTP (op√ß√£o A ‚Äî menor mudan√ßa). Existe um pacote oficial `bullmq` para Python (v2.19.5) com classe `Worker`, mas est√° classificado como **Alpha** e n√£o suporta todas as features do Node.js ‚Äî por isso a decis√£o de manter o scheduler no NestJS. Se no futuro Python precisar de jobs pr√≥prios, considerar APScheduler ou Celery.
>
> **Padr√£o de comunica√ß√£o:** NestJS BullMQ (cron trigger + retry + job history) ‚Üí HTTP POST ‚Üí Python (AI/LLM execution logic) ‚Üí JSON response. BullMQ retry config permanece no NestJS ‚Äî Python n√£o precisa implementar retry de job.

---

## M4.9 ‚Äî Feature Parity + Parallel Validation üî¥

**Objetivo:** Validar que o sistema Python produz resultados funcionalmente equivalentes ao TypeScript em todos os cen√°rios antes de deletar c√≥digo.

**Refer√™ncias:** Todos os milestones anteriores (M4.1-M4.8)

**Depend√™ncias:** M4.7, M4.8

> **Contexto:** Este milestone √© uma "safety net" antes da limpeza. Roda ambos os sistemas em paralelo e compara resultados. Qualquer discrep√¢ncia √© corrigida antes de prosseguir para M4.10.

**Tasks:**

**Suite de Paridade (50+ cen√°rios):**
- [ ] Mensagens simples:
  - "Bom dia" ‚Üí general agent responde
  - "Como voc√™ est√°?" ‚Üí general agent
  - Conversa tipo counselor ‚Üí wellbeing agent
- [ ] Tracking com confirma√ß√£o:
  - "Registra 2L de √°gua hoje" ‚Üí confirm ‚Üí verificar DB
  - "Registra 2L de √°gua hoje" ‚Üí reject ‚Üí nada salvo
  - "Quanto peso eu registrei esta semana?" ‚Üí read ‚Üí dados corretos
  - "Apaga o registro de √°gua de ontem" ‚Üí confirm ‚Üí delete
  - "Atualiza meu peso de hoje para 75kg" ‚Üí confirm ‚Üí update
  - "Registra que fiz exerc√≠cio hoje" ‚Üí confirm ‚Üí habit entry
- [ ] Finance queries:
  - "Quanto gastei este m√™s?" ‚Üí summary correto
  - "Quais contas vencem esta semana?" ‚Üí pending bills
  - "Registra gasto de R$50 com almo√ßo" ‚Üí confirm ‚Üí expense criada
  - "Marca conta de luz como paga" ‚Üí confirm ‚Üí bill updated
  - "Como est√£o minhas d√≠vidas?" ‚Üí debt progress
- [ ] Memory:
  - "O que voc√™ sabe sobre mim?" ‚Üí user memories
  - "Lembra que eu prefiro caf√© sem a√ß√∫car" ‚Üí confirm ‚Üí knowledge added
  - Busca em knowledge_items com filtros
- [ ] Multi-tool:
  - "Como estou financeiramente e na sa√∫de?" ‚Üí m√∫ltiplos agents/tools
- [ ] Edge cases:
  - Timeout de LLM ‚Üí error handling graceful
  - Tool n√£o encontrado ‚Üí error message
  - Confirma√ß√£o ap√≥s 5+ minutos ‚Üí behavior correto (LangGraph checkpoints persistem em PostgreSQL sem TTL por default, diferente do Redis 5min anterior)
  - Mensagem vazia ‚Üí rejection ou resposta default

**SSE Event Compatibility:**
- [ ] Verificar que todos os SSE events emitidos pelo Python t√™m o mesmo formato do TypeScript:
  - `tool_calls` (iteration, toolCalls array)
  - `tool_result` (toolName, result, success)
  - `confirmation_required` (confirmationId, toolName, toolArgs, message, expiresAt)
  - Final response `{ content, done: true }`
  - Error `{ content, done: true, error }`
  - `{ done: true, awaitingConfirmation: true }`
- [ ] Frontend funciona sem nenhuma mudan√ßa de c√≥digo

**Performance:**
- [ ] Load testing: 50 concurrent chat requests ao Python service
- [ ] Verificar lat√™ncia do proxy NestJS ‚Üí Python (deve ser <50ms overhead)
- [ ] Verificar que triage com Flash model < 500ms
- [ ] Validar `InMemoryRateLimiter` do LangChain sob carga (single-process). Se insuficiente em produ√ß√£o com m√∫ltiplos workers uvicorn, avaliar Redis-based rate limiter como melhoria futura

**Observabilidade:**
- [ ] Sentry configurado para Python service (error tracking)
- [ ] Structured logging (JSON) com request_id para correla√ß√£o com NestJS
- [ ] Health check inclui status do DB (Python n√£o depende de Redis)

**Testes:**
- [ ] Suite completa de paridade passa (50+ cen√°rios)
- [ ] Frontend funciona sem mudan√ßas
- [ ] Load test: sem erros em 50 concurrent requests
- [ ] Sentry captura erros do Python service

**Definition of Done:**
- [ ] Todos os cen√°rios produzem resultados funcionalmente equivalentes
- [ ] Frontend funciona identicamente com `USE_PYTHON_AI=true` e `false`
- [ ] Performance aceit√°vel sob carga
- [ ] Observabilidade configurada

---

## M4.10 ‚Äî NestJS Cleanup + Production Deploy üî¥

**Objetivo:** Deletar todo o c√≥digo TypeScript AI obsoleto (~13.400 linhas), simplificar NestJS para proxy, deploy em produ√ß√£o.

**Refer√™ncias:** `docs/ai-python-service-migration-plan.md` ¬ß5, ¬ß7, ¬ß12

**Depend√™ncias:** M4.9

> **Contexto:** Este √© o milestone de maior risco ‚Äî deleta ~13.400 linhas de c√≥digo AI em produ√ß√£o (~11.600 deletadas + ~2.700 simplificadas). A safety net √© o M4.9 (valida√ß√£o de paridade) e o deploy strategy (blue-green ou canary). Rollback √© poss√≠vel revertendo o commit + `USE_PYTHON_AI=false`.

**Tasks:**

**Deletar packages/ai/ (~7.677 linhas):**
- [ ] Deletar diret√≥rio `packages/ai/` inteiro
- [ ] Remover `@life-assistant/ai` do `pnpm-workspace.yaml`
- [ ] Remover depend√™ncias npm: `@anthropic-ai/sdk`, `@google/genai`, `zod-to-json-schema`
- [ ] Remover refer√™ncias em `tsconfig` base

**Deletar tool executors do NestJS:**
- [ ] Deletar `tracking-tool-executor.service.ts` (~587L)
- [ ] Deletar `finance-tool-executor.service.ts` (~1.047L)
- [ ] Deletar `memory-tool-executor.service.ts` (~297L)
- [ ] Remover providers dos respectivos modules

**Deletar servi√ßos AI do NestJS:**
- [ ] Deletar `confirmation-state.service.ts` (~475L)
- [ ] Deletar `context-builder.service.ts` (~337L)
- [ ] Deletar `contradiction-detector.adapter.ts` (~435L)

**Simplificar memory consolidation:**
- [ ] Remover l√≥gica LLM do `memory-consolidation.processor.ts` (~557L)
- [ ] Manter apenas: BullMQ trigger ‚Üí HTTP POST para Python `/workers/consolidation`
- [ ] Resultado: ~50 linhas (de ~557)

**Simplificar chat.service.ts:**
- [ ] Remover l√≥gica de tool loop TypeScript
- [ ] Remover imports de `@life-assistant/ai`
- [ ] Remover feature flag `USE_PYTHON_AI` (Python √© o √∫nico caminho)
- [ ] Resultado: ~200 linhas (de ~1.232) ‚Äî apenas: salvar msg do user + proxy HTTP/SSE para Python

**Simplificar chat.module.ts:**
- [ ] Remover providers de AI/tools/confirmation
- [ ] Manter apenas: ChatController, ChatService (proxy), ChatRepository, MessageRepository

**Atualizar monorepo:**
- [ ] Remover imports quebrados em todo o codebase
- [ ] Atualizar `CLAUDE.md` ‚Äî remover refer√™ncias a `packages/ai/`, adicionar `services/ai/`
- [ ] Atualizar `docs/specs/core/architecture.md` ‚Äî nova arquitetura de 3 servi√ßos

**Testes de regress√£o:**
- [ ] `pnpm typecheck` ‚Äî sem erros de tipo
- [ ] `pnpm lint` ‚Äî sem erros de lint
- [ ] `pnpm test` ‚Äî todos os testes unit√°rios passam
- [ ] `pnpm test:e2e` ‚Äî todos os testes E2E passam (Playwright)
- [ ] Testes de paridade de M4.9 ainda passam

**Deploy produ√ß√£o:**
- [ ] Railway: criar servi√ßo Python AI (Nixpacks, Python buildpack)
- [ ] Railway: configurar internal networking (`python-ai.railway.internal:8000`)
- [ ] Railway: configurar env vars (DATABASE_URL, GEMINI_API_KEY, SERVICE_SECRET)
- [ ] Deploy strategy: blue-green ou canary
- [ ] Monitoramento p√≥s-deploy: 24-48h de observa√ß√£o
- [ ] Verificar Sentry: sem novos erros no Python service
- [ ] Verificar logs: requests fluindo corretamente NestJS ‚Üí Python

**Definition of Done:**
- [ ] `packages/ai/` deletado (0 linhas)
- [ ] NestJS `chat.service.ts` √© ~200L de proxy (de ~1.232L)
- [ ] `pnpm typecheck && pnpm lint && pnpm test` passam
- [ ] `pnpm test:e2e` passa
- [ ] Produ√ß√£o est√°vel por 48h sem novos erros
- [ ] Total removido: **~11.600 linhas deletadas** + **~2.700 simplificadas** (~1.800 delta removido)

> **Riscos:**
> - Regress√µes em edge cases de confirma√ß√£o (SSE event ordering diferente)
> - Imports quebrados em arquivos n√£o cobertos pelos testes
> - Performance em produ√ß√£o diferente de local (lat√™ncia Railway internal networking)
> - Rollback plan: reverter commit + `USE_PYTHON_AI=false` no NestJS (requer que packages/ai/ ainda exista no git history)

---

## Resumo Quantitativo

| M√©trica | Valor |
|---|---|
| Milestones | 10 (M4.1 ‚Äî M4.10) |
| Linhas deletadas do NestJS | **~11.600** (deletadas) + **~2.700** (simplificadas, ~1.800 delta removido) |
| Linhas adicionadas no NestJS | ~160 (proxy SSE + config + feature flag) |
| Novo c√≥digo Python | **~5.000-7.000** (estimativa ‚Äî Python mais conciso que TypeScript equivalente) |
| SQLAlchemy models | ~120-200 linhas (mapeamento passivo + CI check) |
| Pacote deletado | `packages/ai/` (**7.677 linhas**, 49 arquivos) |
| Novo diret√≥rio | `services/ai/` (Python AI Service) |
| Servi√ßos NestJS intactos | Auth, REST controllers, domain services, repositories, BullMQ (scheduler) |
| Mudan√ßas no frontend | Nenhuma (SSE events mant√™m mesmo formato) |

### Estrutura do monorepo ap√≥s migra√ß√£o

```
life-assistant/
‚îú‚îÄ‚îÄ apps/
‚îÇ   ‚îú‚îÄ‚îÄ web/                    # Next.js (sem mudan√ßas)
‚îÇ   ‚îî‚îÄ‚îÄ api/                    # NestJS (simplificado ‚Äî sem AI code)
‚îÇ
‚îú‚îÄ‚îÄ services/
‚îÇ   ‚îî‚îÄ‚îÄ ai/                     # Python AI Service (NOVO)
‚îÇ       ‚îú‚îÄ‚îÄ app/
‚îÇ       ‚îÇ   ‚îú‚îÄ‚îÄ agents/         # LangGraph agents + graph
‚îÇ       ‚îÇ   ‚îú‚îÄ‚îÄ api/            # FastAPI routes + middleware
‚îÇ       ‚îÇ   ‚îú‚îÄ‚îÄ db/             # SQLAlchemy models + repositories
‚îÇ       ‚îÇ   ‚îú‚îÄ‚îÄ memory/         # Contradiction detection
‚îÇ       ‚îÇ   ‚îú‚îÄ‚îÄ prompts/        # System prompt + context builder
‚îÇ       ‚îÇ   ‚îú‚îÄ‚îÄ tools/          # 20 tool implementations
‚îÇ       ‚îÇ   ‚îî‚îÄ‚îÄ workers/        # Memory consolidation
‚îÇ       ‚îú‚îÄ‚îÄ tests/
‚îÇ       ‚îú‚îÄ‚îÄ pyproject.toml
‚îÇ       ‚îî‚îÄ‚îÄ Dockerfile
‚îÇ
‚îú‚îÄ‚îÄ packages/
‚îÇ   ‚îú‚îÄ‚îÄ database/               # Drizzle schemas + migrations (source of truth)
‚îÇ   ‚îú‚îÄ‚îÄ config/                 # Zod config (NestJS)
‚îÇ   ‚îî‚îÄ‚îÄ shared/                 # Shared enums/constants
‚îÇ   # packages/ai/ ‚Üí DELETADO em M4.10
‚îÇ
‚îú‚îÄ‚îÄ docs/
‚îú‚îÄ‚îÄ infra/
‚îî‚îÄ‚îÄ ...
```
