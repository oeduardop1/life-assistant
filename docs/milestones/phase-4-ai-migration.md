# Fase 4: MigraÃ§Ã£o da IA para Python (v4.x)

> **Objetivo:** Migrar toda a camada de inteligÃªncia artificial (packages/ai/ + tool executors + memory workers) de TypeScript/NestJS para um serviÃ§o Python independente com FastAPI + LangGraph, seguindo o padrÃ£o Strangler Fig.
> **ReferÃªncias:** `docs/ai-python-service-migration-plan.md`, `docs/adr-012-tool-use-vs-rag-analysis.md`, `docs/specs/core/architecture.md`

> **Contexto:** O ecossistema Python domina AI/ML (LangGraph, LangChain, LangSmith, scikit-learn, pandas). A implementaÃ§Ã£o atual em TypeScript (`packages/ai/` â€” 7.677 linhas, 49 arquivos) foi adequada para o MVP mas limita a evoluÃ§Ã£o para multi-agente, RAG futuro, e ferramentas avanÃ§adas de observabilidade de AI. A migraÃ§Ã£o cria um serviÃ§o Python dedicado (`services/ai/`) mantendo NestJS como API REST + auth + dashboard.
>
> **Filosofia:**
> - **Strangler Fig:** Sistema TypeScript e Python coexistem via feature flag (`USE_PYTHON_AI`). Rollback instantÃ¢neo em qualquer ponto.
> - **Milestones atÃ´micos:** Cada milestone produz um sistema funcional e testÃ¡vel. Nunca hÃ¡ estado quebrado entre milestones.
> - **LangGraph substitui, nÃ£o porta:** Muitos componentes TypeScript custom (~1.639 linhas) sÃ£o substituÃ­dos por primitivas LangGraph, nÃ£o portados 1:1.
> - **Python independente do Turbo:** O serviÃ§o Python **NÃƒO** faz parte do pnpm workspace nem do Turborepo pipeline. Python Ã© gerido 100% com ferramentas nativas (uv, ruff, mypy, pytest). O `pnpm dev` usa `concurrently` para iniciar Turbo + Python em paralelo. CI roda jobs Node e Python separados. DecisÃ£o baseada em [Turborepo multi-language docs](https://turborepo.dev/docs/guides/multi-language) e anÃ¡lise de trade-offs â€” o pattern de package.json wrapper Ã© oficialmente suportado pelo Turbo, mas gera artefatos artificiais (node_modules, lockfile entries) sem benefÃ­cio real de cache para Python.

### Insight: O que LangGraph substitui

A migraÃ§Ã£o **NÃƒO Ã© um port 1:1** do TypeScript. LangGraph substitui vÃ¡rios componentes custom:

| Componente TypeScript | Linhas | Equivalente LangGraph/LangChain | Resultado |
|---|---|---|---|
| `tool-loop.service.ts` | 310 | `create_react_agent()` (`langgraph.prebuilt`) | **Eliminado** |
| `LLMPort` interface | 245 | `ChatGoogleGenerativeAI` (`langchain-google-genai`) / `ChatAnthropic` (`langchain-anthropic`) | **Eliminado** |
| `retry.ts` + `rate-limiter.ts` | 382 | `max_retries` + `.with_retry()` + `InMemoryRateLimiter` (LangChain built-in) | **Eliminado** |
| `zod-to-gemini.ts` | 227 | `.bind_tools()` converte Pydantic â†’ formato do provider automaticamente | **Eliminado** |
| `confirmation-state.service.ts` (Redis TTL 5min) | 475 | `interrupt()` / `Command(resume=)` (`langgraph.types`) com PostgreSQL checkpoint (`AsyncPostgresSaver`) | **Redesenhado** |
| Tool definitions (Zod schemas) | ~1.000 | Pydantic models + `@tool` decorator | **Reescrito** |

> ~1.639 linhas de `packages/ai/` nÃ£o precisam ser portadas â€” sÃ£o substituÃ­das por primitivas LangGraph. O cÃ³digo Python serÃ¡ mais enxuto que o TypeScript equivalente.

### InventÃ¡rio do cÃ³digo afetado

**packages/ai/ (7.677 linhas, 49 arquivos) â€” serÃ¡ DELETADO:**

| Categoria | Linhas | Arquivos | Destino |
|---|---|---|---|
| Adapters (Claude + Gemini) | 1.932 | 4 | SubstituÃ­dos por `langchain-google-genai` / `langchain-anthropic` |
| Services (Factory, ToolLoop, Executor) | 1.503 | 7 | SubstituÃ­dos por LangGraph `create_react_agent()` |
| Tool definitions (22 tools + schemas) | 2.159 | 27 | Reescritos como Pydantic + `@tool` decorator |
| Utilities (retry, rate-limit, zod-to-gemini) | 1.484 | 8 | SubstituÃ­dos por primitivas LangChain |
| Ports/Interfaces | 245 | 1 | Eliminados (LangGraph abstrai) |
| Errors + Core | 354 | 2 | Python exception hierarchy |

**apps/api/ â€” cÃ³digo AI-related (~5.700 linhas) â€” serÃ¡ DELETADO ou SIMPLIFICADO:**

| Arquivo | Linhas | AÃ§Ã£o |
|---|---|---|
| `chat.service.ts` | 1.232 | Simplificado para ~200L (proxy SSE) |
| `finance-tool-executor.service.ts` | 1.047 | Deletado (migra para Python) |
| `tracking-tool-executor.service.ts` | 587 | Deletado (migra para Python) |
| `memory-consolidation.processor.ts` | 557 | Simplificado para ~50L (BullMQ trigger â†’ HTTP POST para Python) |
| `confirmation-state.service.ts` | 475 | Deletado (LangGraph interrupt) |
| `contradiction-detector.adapter.ts` | 435 | Deletado (migra para Python) |
| `context-builder.service.ts` | 337 | Deletado (migra para Python) |
| `memory-tool-executor.service.ts` | 297 | Deletado (migra para Python) |
| `consolidation-prompt.ts` | 337 | Deletado (migra para Python) |
| `contradiction-resolution.service.ts` | 311 | Deletado (migra para Python) |
| `contradiction-detector.port.ts` | 86 | Deletado (interface eliminada) |

**Total:** ~11.600 linhas deletadas + ~2.700 simplificadas (~1.800 delta removido) â†’ ~5.000-7.000 linhas Python novas

### Paralelismo entre milestones

- M4.5 (Finance Tools) e M4.6 (Memory Tools) podem rodar **em paralelo** (ambos dependem de M4.4 mas sÃ£o independentes entre si)
- M4.1 pode comeÃ§ar **imediatamente** sem afetar trabalho nas outras fases
- Feature flag permite **rollback instantÃ¢neo** em qualquer ponto da migraÃ§Ã£o

---

## M4.1 â€” Python Service: Scaffold + Infra + CI ðŸŸ¢

**Objetivo:** ServiÃ§o Python bootÃ¡vel com FastAPI, integrado no fluxo de dev local (`pnpm infra:up` + `pnpm dev`) e CI. Nenhuma lÃ³gica de AI â€” apenas infraestrutura.

**ReferÃªncias:** `docs/ai-python-service-migration-plan.md` Â§3, Â§10

**DependÃªncias:** Nenhuma (pode comeÃ§ar imediatamente)

> **DecisÃ£o arquitetural:** O serviÃ§o Python NÃƒO faz parte do pnpm workspace nem do Turborepo. Python Ã© gerido com ferramentas nativas (uv, ruff, mypy, pytest). `pnpm dev` usa `concurrently` para iniciar Turbo (JS/TS) + uvicorn (Python) em paralelo. Esta decisÃ£o segue o princÃ­pio de separaÃ§Ã£o de concerns â€” cada linguagem com seu toolchain nativo, sem artefatos artificiais.

**Tasks:**

**Scaffold do projeto Python (via CLI):**
- [x] Inicializar projeto: `uv init --app --python 3.12 services/ai`
  - Cria: `pyproject.toml`, `.python-version`, `.gitignore`, `README.md`, `main.py`
  - Flag `--no-workspace` se existir `pyproject.toml` na raiz do monorepo (evita auto-join)
- [x] Adicionar dependÃªncias runtime:
  ```bash
  cd services/ai
  uv add fastapi 'uvicorn[standard]' 'sqlalchemy[asyncio]' asyncpg langgraph langgraph-checkpoint-postgres langchain-google-genai langchain-anthropic pydantic pydantic-settings sse-starlette
  ```
- [x] Adicionar dependÃªncias dev:
  ```bash
  uv add --dev pytest pytest-asyncio ruff mypy httpx
  ```
- [x] Configurar tool settings no `pyproject.toml` (seÃ§Ãµes `[tool.ruff]`, `[tool.mypy]`, `[tool.pytest.ini_options]`)
- [x] Remover `main.py` gerado pelo scaffold e reorganizar para estrutura `app/`:
  ```
  services/ai/
  â”œâ”€â”€ app/
  â”‚   â”œâ”€â”€ __init__.py
  â”‚   â”œâ”€â”€ main.py          # FastAPI app + lifespan (startup/shutdown)
  â”‚   â”œâ”€â”€ config.py         # Pydantic Settings (BaseSettings)
  â”‚   â”œâ”€â”€ dependencies.py   # FastAPI Depends() â€” DB session, config
  â”‚   â””â”€â”€ api/
  â”‚       â”œâ”€â”€ routes/
  â”‚       â”‚   â””â”€â”€ health.py # GET /health (status + DB check)
  â”‚       â””â”€â”€ middleware/
  â”‚           â””â”€â”€ auth.py   # Service-to-service auth (Bearer token)
  â”œâ”€â”€ tests/
  â”œâ”€â”€ pyproject.toml
  â”œâ”€â”€ uv.lock
  â””â”€â”€ .python-version
  ```
- [x] Criar `app/main.py` com FastAPI lifespan:
  - Startup: `AsyncPostgresSaver.setup()` (cria tabelas de checkpoint: `checkpoints`, `checkpoint_blobs`, `checkpoint_writes`, `checkpoint_migrations`)
  - Shutdown: dispose engine
- [x] Criar `app/config.py` com Pydantic Settings:
  - `DATABASE_URL`, `GEMINI_API_KEY`, `SERVICE_SECRET`, `ANTHROPIC_API_KEY` (opcional)
  - Loads from root `.env` via `model_config = SettingsConfigDict(env_file="../../.env")`
- [x] Criar `app/dependencies.py` â€” FastAPI `Depends()` com generator `yield` para DB session
- [x] Criar `app/api/routes/health.py` â€” GET /health (status + versÃ£o + check de DB)
- [x] Criar `app/api/middleware/auth.py` â€” service-to-service auth via shared secret (Bearer token)
- [x] Estender `.gitignore` gerado pelo uv: adicionar `__pycache__/`, `.mypy_cache/`, `.pytest_cache/`, `.ruff_cache/`

> **Nota:** `sse-starlette` Ã© dependÃªncia explÃ­cita â€” FastAPI nÃ£o tem classe SSE built-in. Usar `EventSourceResponse` para streaming.
> **Nota:** `REDIS_URL` removido da config Python â€” nÃ£o necessÃ¡rio na fase inicial. ConfirmaÃ§Ã£o usa PostgreSQL (LangGraph checkpoints), nÃ£o Redis TTL. BullMQ scheduling permanece no NestJS.

**IntegraÃ§Ã£o com `pnpm dev` (via `concurrently`):**
- [x] Instalar concurrently: `pnpm add -Dw concurrently`
- [x] Atualizar `package.json` root:
  ```json
  {
    "scripts": {
      "dev": "concurrently -k -p [{name}] -n turbo,ai -c blue,yellow \"turbo run dev\" \"cd services/ai && uv run uvicorn app.main:app --reload --host 0.0.0.0 --port 8000\"",
      "dev:js": "turbo run dev",
      "dev:ai": "cd services/ai && uv run uvicorn app.main:app --reload --host 0.0.0.0 --port 8000"
    }
  }
  ```
- [x] Verificar que `Ctrl+C` mata todos os processos (flag `-k` do concurrently)
- [x] Verificar que output mostra prefixos `[turbo]` e `[ai]` no terminal

**IntegraÃ§Ã£o com `pnpm infra:up` (dev-start.sh):**
- [x] Adicionar porta 8000 ao `check_ports()` existente
- [x] Criar novo Step (entre Service Status e Database Schema):
  ```
  Step 4: Python AI Service Setup
    âœ“ Check Python 3.12+
    âœ“ Check uv package manager
    âœ“ Install dependencies (uv sync)
    âœ“ Python environment ready
  ```
- [x] Implementar `check_python()`:
  - Verificar `python3 --version` >= 3.12
  - Se nÃ£o encontrado: mensagem com instruÃ§Ãµes de instalaÃ§Ã£o
- [x] Implementar `check_uv()`:
  - Verificar `uv --version`
  - Se nÃ£o encontrado: sugerir `curl -LsSf https://astral.sh/uv/install.sh | sh`
- [x] Implementar `setup_python_env()`:
  - `cd services/ai && uv sync` (cria .venv + instala deps)
  - Idempotente: <2s em runs subsequentes
  - VerificaÃ§Ã£o: `uv run python -c "import fastapi; print('OK')"`
- [x] Atualizar summary final para mostrar Python AI Service URL (localhost:8000)
- [x] Renumerar steps: 1-Docker, 2-Supabase, 3-Status, **4-Python**, 5-Database

**Docker (produÃ§Ã£o + CI):**
- [x] Criar `services/ai/Dockerfile`:
  ```dockerfile
  FROM python:3.12-slim AS base
  WORKDIR /app
  RUN pip install uv

  FROM base AS deps
  COPY pyproject.toml uv.lock ./
  RUN uv sync --frozen --no-dev

  FROM base AS runner
  COPY --from=deps /app/.venv /app/.venv
  COPY app/ app/
  ENV PATH="/app/.venv/bin:$PATH"
  EXPOSE 8000
  CMD ["uvicorn", "app.main:app", "--host", "0.0.0.0", "--port", "8000"]
  ```
- [x] Criar `services/ai/.dockerignore` â€” `.venv/`, `__pycache__/`, `.git/`, `tests/`, `.mypy_cache/`
- [x] **NÃƒO** adicionar Python ao docker-compose.yml (Python roda nativo em dev, Docker sÃ³ para produÃ§Ã£o)

**VariÃ¡veis de ambiente:**
- [x] Adicionar ao `.env.example`:
  ```bash
  # Python AI Service
  PYTHON_AI_URL=http://localhost:8000
  SERVICE_SECRET=dev-secret-change-me
  USE_PYTHON_AI=false
  ```
- [x] Adicionar `PYTHON_AI_URL` ao `packages/config/`

**CI (GitHub Actions â€” job separado):**
- [x] Criar `services/ai/tests/conftest.py` â€” fixtures base (async test client via `httpx.AsyncClient`, test DB session)
- [x] Adicionar job `python` no workflow CI:
  ```yaml
  python:
    runs-on: ubuntu-latest
    defaults:
      run:
        working-directory: services/ai
    steps:
      - uses: actions/checkout@v4
      - uses: astral-sh/setup-uv@v5
        with:
          python-version: "3.12"
      - run: uv sync
      - run: uv run ruff check .
      - run: uv run ruff format --check .
      - run: uv run mypy app/
      - run: uv run pytest
  ```
- [x] Job Python roda em **paralelo** com job Node (nÃ£o sequencial)

**DocumentaÃ§Ã£o:**
- [x] Atualizar `CLAUDE.md`:
  - Requirements: adicionar `Python >=3.12, uv`
  - Commands: adicionar `pnpm dev:ai` e explicar `pnpm dev` (agora usa concurrently)
  - Estrutura do monorepo: adicionar `services/ai/`
- [x] Atualizar `DEVELOPMENT.md` (se existir) com setup Python

**Definition of Done:**
- [x] `pnpm infra:up` verifica Python, instala deps via `uv sync`
- [x] `pnpm dev` inicia web (:3000) + api (:4000) + python (:8000) em paralelo
- [x] `curl http://localhost:8000/health` retorna 200
- [x] Request sem Bearer token retorna 401
- [x] CI passa: job Node (turbo) + job Python (ruff, mypy, pytest) em paralelo
- [x] `Ctrl+C` no `pnpm dev` mata todos os processos
- [x] `services/ai/` NÃƒO aparece em `pnpm-workspace.yaml` nem `pnpm-lock.yaml`

### Notas

_ConcluÃ­do em 2026-02-22._

**Melhorias sobre o plano original:**
- Adicionada dependÃªncia `psycopg[binary]` â€” necessÃ¡ria para `langgraph-checkpoint-postgres` funcionar sem `libpq` nativo instalado no sistema
- Dockerfile usa `COPY --from=ghcr.io/astral-sh/uv:latest /uv /uvx /bin/` em vez de `RUN pip install uv` â€” mais eficiente (layer de cache, sem pip)
- CI usa `astral-sh/setup-uv@v7` (plano dizia `@v5`, Context7 confirmou v7 como latest)
- `AsyncPostgresSaver.from_conn_string()` retorna context manager (`async with`) â€” validado via Context7 docs + source code inspection. Plano nÃ£o especificava esse detalhe
- Entradas Python adicionadas no `.gitignore` root em vez de criar `.gitignore` separado em `services/ai/` (jÃ¡ coberto pelo root)
- `README.md` gerado pelo `uv init` removido (desnecessÃ¡rio)
- Auth middleware implementado como `BaseHTTPMiddleware` do Starlette com `PUBLIC_PATHS` incluindo `/health`, `/docs`, `/openapi.json`, `/redoc`
- Testes do `@life-assistant/config` e `apps/api/test/setup.ts` atualizados para incluir `SERVICE_SECRET` nos fixtures (campo obrigatÃ³rio adicionado ao `envSchema`)

**VerificaÃ§Ã£o local:**
- Python: ruff check (0), ruff format (15 files OK), mypy (0 issues, 11 files), pytest (5/5)
- JS/TS: typecheck (10/10), lint (5/6 â€” web failure preexistente), test (5/6 â€” web failures preexistentes)
- Health endpoint: `curl localhost:8000/health` â†’ 200 `{"status":"ok","version":"0.1.0","database":"connected"}`
- Auth: endpoint sem Bearer â†’ 401, `/health` sem auth â†’ 200
- Isolamento: `services/ai/` nÃ£o aparece em `pnpm-workspace.yaml` nem `pnpm-lock.yaml`
- Concurrently rodando com flags corretos (`-k -p [{name}] -n turbo,ai -c blue,yellow`)

---

## M4.2 â€” SQLAlchemy Data Layer + RLS ðŸŸ¢

**Objetivo:** Python consegue ler/escrever no PostgreSQL com Row Level Security, mapeando tabelas do Drizzle.

**ReferÃªncias:** `docs/ai-python-service-migration-plan.md` Â§8, `docs/specs/core/data-conventions.md`, `docs/specs/core/auth-security.md`

**DependÃªncias:** M4.1

> **Contexto:** Drizzle (NestJS) Ã© o source of truth para schema e migrations. SQLAlchemy models sÃ£o mapeamentos passivos â€” nÃ£o geram migrations. PostgreSQL garante integridade via constraints, foreign keys e RLS policies independente de qual ORM escreve.

**Tasks:**

**Engine + Session:**
- [x] Criar `app/db/engine.py`:
  - `create_async_engine("postgresql+asyncpg://...")` com pool config
  - `async_sessionmaker(engine, expire_on_commit=False)` â€” `expire_on_commit=False` obrigatÃ³rio para evitar lazy-loading I/O em async
- [x] Criar `app/db/session.py` â€” context managers RLS-aware que executam `SET LOCAL request.jwt.claim.sub = '{user_id}'` antes de cada operaÃ§Ã£o (matching NestJS `set_config('request.jwt.claim.sub', ...)` e RLS policies que usam `auth.uid()`)
  - Deve ser **obrigatÃ³rio** â€” impossÃ­vel fazer query sem user_id setado
  - Testes que tentam query sem middleware devem falhar com RLS

**Models (mapeamento passivo das tabelas Drizzle):**
- [x] Criar `app/db/models/base.py` â€” `DeclarativeBase` + mixins comuns (`TimestampMixin`, `SoftDeleteMixin`)
- [x] Criar `app/db/models/enums.py` â€” Enums Python (`StrEnum`) espelhando os PostgreSQL `CREATE TYPE` (22 enums usados pelas tabelas modeladas)
- [x] Criar `app/db/models/users.py` â€” `users`, `user_memories` (read-only para Python)
- [x] Criar `app/db/models/tracking.py` â€” `tracking_entries`, `custom_metric_definitions`, `habits`, `habit_completions`
- [x] Criar `app/db/models/finance.py` â€” `incomes`, `bills`, `variable_expenses`, `debts`, `debt_payments`, `investments`, `budgets`
- [x] Criar `app/db/models/memory.py` â€” `knowledge_items`, `memory_consolidations`
- [x] Criar `app/db/models/chat.py` â€” `conversations`, `messages`
- [x] Todos os `Numeric` fields com `asdecimal=False` na definiÃ§Ã£o do model (retorna `float` ao invÃ©s de `Decimal`):
  ```python
  amount = mapped_column(Numeric(precision=12, scale=2, asdecimal=False))  # â†’ float
  ```

> **NUNCA criar SQLAlchemy models para tabelas de checkpoint do LangGraph** (`checkpoints`, `checkpoint_blobs`, `checkpoint_writes`, `checkpoint_migrations`). Essas tabelas sÃ£o gerenciadas exclusivamente pelo `AsyncPostgresSaver.setup()` chamado no lifespan do FastAPI (M4.1).

**Repositories:**
- [x] Criar `app/db/repositories/tracking.py` â€” TrackingRepository (create, find, aggregate, update, delete)
- [x] Criar `app/db/repositories/finance.py` â€” FinanceRepository (summary, bills, expenses, incomes, investments, debts)
- [x] Criar `app/db/repositories/memory.py` â€” MemoryRepository (search knowledge, add knowledge, get user memories)
- [x] Criar `app/db/repositories/chat.py` â€” ChatRepository (save message, get history, get conversation)
- [x] Criar `app/db/repositories/user.py` â€” UserRepository (get user, get settings â€” read-only)

**Schema Drift CI Check:**
- [x] Criar script `services/ai/scripts/check_schema_drift.py`:
  - Conecta ao DB, lÃª `information_schema` real
  - Compara com SQLAlchemy models declarados
  - Falha se tabela/coluna/tipo existir no DB mas nÃ£o no model (ou vice-versa)
- [x] Integrar no CI: roda a cada PR que toca `packages/database/src/schema/` ou `services/ai/app/db/models/`

**Testes:**
- [x] Teste de integraÃ§Ã£o: RLS impede User A de ler dados do User B
- [x] Teste de integraÃ§Ã£o: DECIMAL fields retornam `float`, nÃ£o `Decimal`
- [x] Teste de integraÃ§Ã£o: CRUD completo em cada repository (tracking, finance, memory, chat)
- [x] Teste: session RLS rejeita session sem user_id

**Definition of Done:**
- [x] Python lÃª/escreve em todas as tabelas necessÃ¡rias
- [x] RLS funciona: user A nÃ£o vÃª dados de user B
- [x] DECIMAL â†’ float em todas as queries
- [x] CI detecta schema drift quando Drizzle muda e SQLAlchemy nÃ£o acompanha
- [x] Testes de integraÃ§Ã£o passam

> **Riscos:**
> - DECIMAL handling: Drizzle retorna **string**, SQLAlchemy retorna **`Decimal`** por default. SoluÃ§Ã£o: usar `Numeric(asdecimal=False)` em todos os money fields nos models SQLAlchemy. Testes de integraÃ§Ã£o que comparam outputs dos dois ORMs para as mesmas queries.
> - RLS com SQLAlchemy async pode ter edge cases com connection pooling (`expire_on_commit=False` Ã© obrigatÃ³rio). Testar com mÃºltiplos users concorrentes.
> - Concurrent writes: ambos os serviÃ§os escrevem na mesma tabela (ex: `tracking_entries`). Usar `ON CONFLICT` / upsert patterns. Idempotency keys para write operations via chat.

### Notas

_ConcluÃ­do em 2026-02-23._

**Melhorias sobre o plano original:**
- RLS implementado como context managers em `app/db/session.py` (`get_user_session`, `get_service_session`) em vez de middleware HTTP (`app/db/middleware.py` no plano original). Context managers sÃ£o mais seguros â€” garantem que `SET LOCAL` e a transaÃ§Ã£o estejam sempre no mesmo escopo, e permitem uso direto em workers/scripts sem depender do ciclo HTTP. `get_service_session()` adicional para worker jobs que bypassam RLS via `SET LOCAL role = 'service_role'`
- 22 enums implementados (dos 30 no DB) â€” apenas os referenciados pelas tabelas que Python modela. Enums nÃ£o utilizados (ex: `vault_item_type`, `notification_type`, `export_status`) ficam de fora atÃ© que Python precise dessas tabelas
- Colunas `metadata` nos modelos `TrackingEntry`, `Conversation` e `Message` renomeadas no Python (`entry_metadata`, `conversation_metadata`, `message_metadata`) com mapeamento explÃ­cito `mapped_column("metadata", JSON)` porque `metadata` Ã© atributo reservado do `DeclarativeBase` do SQLAlchemy. A coluna no banco continua `metadata`
- `app/main.py` refatorado para usar `get_async_engine()` e `get_session_factory()` do novo mÃ³dulo `app/db/engine`, com `session_factory` armazenado em `app.state`
- `app/dependencies.py` estendido com `get_db_session()` que injeta sessÃ£o RLS-scoped via FastAPI `Depends()`
- Schema drift check integrado no job `e2e` do CI (apÃ³s migrations, antes do build) â€” requer Supabase rodando, por isso roda no e2e e nÃ£o no job `python`
- Testes de integraÃ§Ã£o (RLS + repositories) usam flag `--run-db` e sÃ£o skipped automaticamente no CI sem Supabase. 16 testes unitÃ¡rios (models) passam sem DB

**VerificaÃ§Ã£o local:**
- Python: ruff check (0 errors), ruff format (34 files OK), mypy (0 issues, 26 files), pytest (16 passed, 14 skipped)
- JS/TS: typecheck (10/10 cached) â€” nenhuma regressÃ£o

---

## M4.3 â€” LangGraph Basic Chat + NestJS Proxy ðŸŸ¢

**Objetivo:** Primeira mensagem end-to-end pelo Python service: Frontend â†’ NestJS â†’ Python â†’ resposta. Chat funcional sem tools.

**ReferÃªncias:** `docs/ai-python-service-migration-plan.md` Â§2, Â§4, Â§9

**DependÃªncias:** M4.2

> **Contexto:** Este milestone estabelece o "pipe" completo. Depois que mensagens fluem end-to-end, os milestones seguintes adicionam tools incrementalmente. O frontend NÃƒO muda â€” NestJS proxeia SSE transparentemente.

**Tasks:**

**LangGraph Core:**
- [x] Criar `app/agents/state.py` â€” `AgentState` TypedDict:
  ```python
  class AgentState(TypedDict):
      messages: Annotated[list, add_messages]
      user_id: str
      conversation_id: str
      current_agent: str | None
  ```
- [x] Criar `app/agents/llm.py` â€” LLM factory baseado em `LLM_PROVIDER` env (Gemini/Anthropic)
- [x] Criar `app/agents/domains/general.py` â€” agente conversacional (sem tools, sÃ³ responde)
  - Usa LLM factory (model configurÃ¡vel via `LLM_MODEL` env, default `gemini-2.5-flash`)
- [x] Criar `app/agents/graph.py` â€” StateGraph bÃ¡sico:
  - START â†’ general_agent â†’ save_response â†’ END
  - `AsyncPostgresSaver` como checkpointer (persistÃªncia de threads)
  - Import: `from langgraph.checkpoint.postgres.aio import AsyncPostgresSaver`
  - `.setup()` chamado no lifespan do FastAPI (M4.1) â€” cria tabelas `checkpoints`, `checkpoint_blobs`, `checkpoint_writes`, `checkpoint_migrations`
- [x] Criar `app/agents/save_response.py` â€” node que salva mensagem do assistente no DB via SQLAlchemy

**Context Builder (versÃ£o simplificada):**
- [x] Criar `app/prompts/system.py` â€” system prompt base:
  - Nome do usuÃ¡rio, timezone, data atual
  - Personalidade conforme `docs/specs/core/ai-personality.md`
- [x] Criar `app/prompts/context_builder.py` (versÃ£o mÃ­nima):
  - User memories formatadas do `user_memories` table
  - Apenas campos essenciais: bio, goals, topOfMind
  - Context builder completo serÃ¡ expandido em M4.6

**SSE Streaming (via `sse-starlette`):**
- [x] Criar `app/api/routes/chat.py`:
  - POST `/chat/invoke` â€” recebe `{ user_id, conversation_id, message }`, retorna SSE stream
  - Usar `EventSourceResponse` de `sse-starlette` (FastAPI nÃ£o tem SSE built-in)
  - SSE events compatÃ­veis com formato atual do frontend:
    - `{ data: { content: "...", done: false } }` â€” text delta
    - `{ data: { content: "...", done: true } }` â€” resposta final
    - `{ data: { content: "", done: true, error: "..." } }` â€” erro (matching NestJS format)
- [x] Carregar histÃ³rico de mensagens do DB quando nÃ£o existe checkpoint (conversas originadas no TypeScript)

**NestJS Proxy:**
- [x] Consumir `pythonAiSchema` no API module via `AppConfigService` (getters: `pythonAiUrl`, `serviceSecret`, `usePythonAi`)
- [x] Criar mÃ©todo `proxyToPython()` no `chat.service.ts`:
  - POST para Python `/chat/invoke` com Bearer `SERVICE_SECRET`
  - Parseia SSE stream do Python via `ReadableStream` reader e emite para o frontend
- [x] Quando `USE_PYTHON_AI=true`: proxy para Python. Quando `false`: usa lÃ³gica TypeScript atual

**Testes:**
- [x] Teste E2E: enviar mensagem simples â†’ receber resposta via Python (SSE streaming)
- [x] Teste: save response node persiste mensagem no DB
- [x] Teste: context builder inclui user memories no system prompt
- [x] Teste: feature flag alterna corretamente entre TypeScript e Python
- [x] Teste: frontend recebe SSE events no formato esperado (sem mudanÃ§as no frontend)

**Definition of Done:**
- [x] Com `USE_PYTHON_AI=true`, chat funciona end-to-end pelo Python (sem tools)
- [x] Com `USE_PYTHON_AI=false`, sistema TypeScript continua funcionando normalmente
- [x] Frontend nÃ£o percebe diferenÃ§a (mesmos SSE events)
- [x] Mensagens sÃ£o salvas no DB pelo Python

> **DecisÃ£o tomada:** Feature flag via environment variable (`USE_PYTHON_AI`), jÃ¡ definida em `packages/config/src/schemas/python-ai.ts`.

**Notas (2026-02-23):**
ImplementaÃ§Ã£o completa do pipe Python end-to-end. **Python (16 arquivos criados, 2 modificados):** `app/agents/` (state.py, llm.py, graph.py, save_response.py, domains/general.py) â€” StateGraph com `general_agent â†’ save_response`, `AsyncPostgresSaver` checkpointer, LLM factory suportando Gemini + Anthropic via `LLM_PROVIDER` env. `app/prompts/` (system.py, context_builder.py) â€” system prompt completo com personalidade Â§4, guardrails Â§7 (CVV 188, Ligue 180), counselor mode Â§5.1, user memories (bio, occupation, family, goals, challenges, topOfMind, values, communication_style). `app/api/routes/chat.py` â€” POST `/chat/invoke` com `EventSourceResponse`, checkpoint-or-DB-fallback para conversas originadas no TypeScript (carrega histÃ³rico do DB se checkpoint nÃ£o existe), `convert_db_messages()` com IDs preservados para dedup do `add_messages` reducer, `await request.is_disconnected()` para disconnect detection. Error SSE retorna mensagem genÃ©rica "Erro ao gerar resposta" (nÃ£o vaza `str(e)` ao cliente). Modificados: `app/main.py` (build graph no lifespan + registra chat router), `app/dependencies.py` (get_checkpointer helper). Reusa cÃ³digo existente de M4.2: `get_user_session()` (RLS), `ChatRepository`, `UserRepository`, `get_settings()`. **NestJS (3 arquivos modificados):** `config.service.ts` (3 getters: pythonAiUrl, serviceSecret, usePythonAi), `chat.service.ts` (`AppConfigService` injetado como 1Âº param do constructor + feature flag check no topo de `processStreamResponse()` + `proxyToPython()` com native `fetch` + `ReadableStream` reader para SSE parsing + `reader.releaseLock()` no finally), `chat.service.spec.ts` (mock do `AppConfigService` com `usePythonAi: false`). **Testes:** 26 Python (pytest) â€” test_llm_factory (4), test_agents (4), test_context_builder (6), test_chat_endpoint (5), test_graph (2), conftest + existing (5). 853 NestJS (jest). Todos passando. `ruff check .` + `mypy app/` + `pnpm typecheck` + `pnpm lint` limpos.

---

## M4.4 â€” Tracking Tools + Habits + Confirmation Framework ðŸ”´

**Objetivo:** Primeiros tools funcionando no Python com confirmaÃ§Ã£o via `interrupt()`. Tracking Ã© o domÃ­nio mais simples â€” ideal para validar o framework.

**ReferÃªncias:** `docs/ai-python-service-migration-plan.md` Â§4.5, `docs/specs/domains/tracking.md`, `ADR-015`

**DependÃªncias:** M4.3

> **Contexto:** O framework de confirmaÃ§Ã£o com `interrupt()` / `Command(resume=)` do LangGraph (import de `langgraph.types`) substitui o sistema atual de Redis TTL (5 min) do `confirmation-state.service.ts`. A persistÃªncia passa a ser via PostgreSQL (`AsyncPostgresSaver`), sem TTL por default. Isso Ã© uma **melhoria**: confirmaÃ§Ãµes nÃ£o expiram, sobrevivem a crashes do processo, e o thread pode ser retomado a qualquer momento. Este milestone valida o padrÃ£o que serÃ¡ usado por todos os write tools.
>
> **MudanÃ§a de infra:** Confirmation state migra de Redis (ioredis SETEX 5min) â†’ PostgreSQL (LangGraph checkpoint tables). Python **nÃ£o precisa de Redis** para confirmaÃ§Ãµes.

**Tasks:**

**Confirmation Framework:**
- [ ] Criar `app/tools/common/confirmation.py`:
  - Wrapper de `interrupt()` que padroniza o formato de confirmaÃ§Ã£o
  - Emite SSE event `confirmation_required` com `{ confirmationId, toolName, toolArgs, message, expiresAt }`
- [ ] Adicionar endpoint POST `/chat/resume` em `app/api/routes/chat.py`:
  - Recebe `{ thread_id, action: "confirm" | "reject" }`
  - Executa `Command(resume={"action": "confirm"})` ou `Command(resume={"action": "reject"})`
  - Retorna SSE stream com resultado
- [ ] **NestJS:** Proxy do endpoint `/confirm` para Python `/chat/resume`
- [ ] SSE event `confirmation_required` compatÃ­vel com frontend atual:
  ```json
  {
    "type": "confirmation_required",
    "data": {
      "confirmationId": "uuid",
      "toolName": "record_metric",
      "toolArgs": { "type": "water", "value": 2000 },
      "message": "Registrar Ã¡gua: 2000ml em 2026-02-22",
      "expiresAt": "ISO string"
    }
  }
  ```
- [ ] SSE event `tool_result` apÃ³s execuÃ§Ã£o:
  ```json
  { "type": "tool_result", "data": { "toolName": "record_metric", "result": "...", "success": true } }
  ```

**Tracking Tools (4 tools):**
- [ ] Criar `app/tools/tracking/record_metric.py` â€” registra mÃ©trica (WRITE, confirmation)
  - Params: type, value, entry_date, unit (opcional), area (opcional)
  - Usa TrackingRepository para INSERT
  - Default units/areas por tipo de mÃ©trica
- [ ] Criar `app/tools/tracking/get_history.py` â€” histÃ³rico de mÃ©tricas (READ)
  - Params: metric_type, days (opcional, default 30)
  - Retorna entries ordenadas por data
- [ ] Criar `app/tools/tracking/update_metric.py` â€” atualiza mÃ©trica existente (WRITE, confirmation)
  - Params: entry_id, value, entry_date (opcionais)
  - Verifica que entry pertence ao user
- [ ] Criar `app/tools/tracking/delete_metric.py` â€” deleta mÃ©trica (WRITE, confirmation)
  - Params: entry_id
  - Suporte a delete em batch (mÃºltiplos IDs)

**Habit Tools (2 tools â€” definidos mas atualmente INATIVOS no ChatService):**
- [ ] Criar `app/tools/tracking/record_habit.py` â€” registra hÃ¡bito (WRITE, confirmation)
  - Params: habit_name, completed, entry_date
  - Match por nome fuzzy do hÃ¡bito
- [ ] Criar `app/tools/tracking/get_habits.py` â€” lista hÃ¡bitos (READ)
  - Retorna hÃ¡bitos com status de hoje

> **Nota:** `analyze_context` estÃ¡ mapeado para o executor `'memory'` no cÃ³digo (chat.service.ts:121), nÃ£o tracking. Esse tool Ã© implementado em M4.6 (Memory Tools).

**Tracking Agent:**
- [ ] Criar `app/agents/domains/tracking.py`:
  - Usa `create_react_agent()` com os 6 tools acima (4 tracking + 2 habits) (ver nota sobre deprecation em M4.7)
  - System prompt com regras de tracking (timezone, unidades default, regras de confirmaÃ§Ã£o)
- [ ] Atualizar graph principal: START â†’ general_agent â†’ save_response (tracking agent serÃ¡ integrado ao routing em M4.7)
  - Por enquanto, tracking agent Ã© invocado diretamente quando tools de tracking sÃ£o necessÃ¡rios

**Testes:**
- [ ] Teste: record_metric com confirmaÃ§Ã£o (confirm + reject)
- [ ] Teste: get_tracking_history retorna dados corretos
- [ ] Teste: update_metric verifica ownership
- [ ] Teste: delete_metric em batch
- [ ] Teste: record_habit com fuzzy match de nome
- [ ] Teste de integraÃ§Ã£o: dados escritos pelo Python visÃ­veis no dashboard NestJS (via Drizzle)
- [ ] Teste: SSE events de confirmaÃ§Ã£o compatÃ­veis com frontend
- [ ] Teste: flow completo "Registra 2L de Ã¡gua hoje" end-to-end

**Definition of Done:**
- [ ] "Registra 2L de Ã¡gua hoje" funciona end-to-end pelo Python (card de confirmaÃ§Ã£o no frontend)
- [ ] ConfirmaÃ§Ã£o e rejeiÃ§Ã£o funcionam corretamente
- [ ] Dados escritos pelo Python aparecem no dashboard
- [ ] Todos os 6 tools passam em testes isolados + integraÃ§Ã£o

---

## M4.5 â€” Finance Tools ðŸ”´

**Objetivo:** Todos os 11 tools financeiros migrados para Python. Maior executor em linhas de cÃ³digo (~1.047L no TypeScript).

**ReferÃªncias:** `docs/specs/domains/finance.md`, `apps/api/src/modules/finance/application/services/finance-tool-executor.service.ts`

**DependÃªncias:** M4.4

> **Contexto:** O `finance-tool-executor.service.ts` Ã© o maior executor (1.047 linhas) com lÃ³gica complexa de agregaÃ§Ã£o, cÃ¡lculos mensais, projeÃ§Ãµes e breakdown por categoria. Requer atenÃ§Ã£o especial ao handling de DECIMAL (string no Drizzle, float no Python).

**Tasks:**

**Finance Tools â€” READ (9 tools):**
- [ ] Criar `app/tools/finance/get_finance_summary.py` â€” resumo financeiro mensal
  - Params: month, year (opcionais, default: mÃªs atual)
  - Retorna: income total, expenses total, bills total, balance, breakdown por categoria
- [ ] Criar `app/tools/finance/get_pending_bills.py` â€” contas pendentes
  - Params: nenhum obrigatÃ³rio
  - Retorna: bills com status pending/overdue, valor total pendente
- [ ] Criar `app/tools/finance/get_bills.py` â€” todas as contas com status
  - Params: month, year, status (opcionais)
  - Retorna: lista de bills com paid/pending/overdue
- [ ] Criar `app/tools/finance/get_expenses.py` â€” despesas variÃ¡veis
  - Params: month, year, category (opcionais)
  - Retorna: lista de expenses com categoria e valor
- [ ] Criar `app/tools/finance/get_incomes.py` â€” receitas
  - Params: month, year (opcionais)
  - Retorna: lista de incomes
- [ ] Criar `app/tools/finance/get_investments.py` â€” investimentos
  - Params: nenhum obrigatÃ³rio
  - Retorna: lista de investments com tipo e valor
- [ ] Criar `app/tools/finance/get_debt_progress.py` â€” progresso de dÃ­vidas
  - Params: debt_id (opcional â€” todas se omitido)
  - Retorna: total pago, percentual quitado, parcelas restantes
- [ ] Criar `app/tools/finance/get_debt_payment_history.py` â€” histÃ³rico de pagamentos de dÃ­vida
  - Params: debt_id
  - Retorna: lista de pagamentos com data e valor
- [ ] Criar `app/tools/finance/get_upcoming_installments.py` â€” prÃ³ximas parcelas
  - Params: days_ahead (opcional, default 30)
  - Retorna: installments com data de vencimento e valor

**Finance Tools â€” WRITE (2 tools):**
- [ ] Criar `app/tools/finance/mark_bill_paid.py` â€” marcar conta como paga (WRITE, confirmation)
  - Params: bill_id, paid_date (opcional, default: hoje)
  - Verifica que bill pertence ao user e estÃ¡ pendente
- [ ] Criar `app/tools/finance/create_expense.py` â€” criar despesa variÃ¡vel (WRITE, confirmation)
  - Params: description, amount, category, date (opcional)
  - Mapeamento de categorias PTâ†’EN preservado (alimentacaoâ†’food, transporteâ†’transport, etc.)

**Finance Agent:**
- [ ] Criar `app/agents/domains/finance.py`:
  - Usa `create_react_agent()` com os 11 tools (ver nota sobre deprecation em M4.7)
  - System prompt com regras de finance (categorias PTâ†’EN, formataÃ§Ã£o monetÃ¡ria BRL, regras de confirmaÃ§Ã£o)

**LÃ³gica de agregaÃ§Ã£o:**
- [ ] Implementar cÃ¡lculos mensais: income - expenses - bills = balance
- [ ] Implementar breakdown por categoria com percentuais
- [ ] Implementar projeÃ§Ãµes baseadas em histÃ³rico
- [ ] Garantir que todos os cÃ¡lculos usam `float` (nÃ£o `Decimal` nem `string`)

**Testes:**
- [ ] Teste: cada tool isoladamente com dados de seed
- [ ] Teste: get_finance_summary com mÃºltiplas categorias e breakdown correto
- [ ] Teste: mark_bill_paid com confirmaÃ§Ã£o
- [ ] Teste: create_expense com mapeamento de categoria PTâ†’EN
- [ ] Teste cross-ORM: mesma query financeira via Drizzle e SQLAlchemy retorna mesmos valores
- [ ] Teste: queries complexas ("quanto gastei com alimentaÃ§Ã£o este mÃªs?", "quais contas vencem esta semana?")

**Definition of Done:**
- [ ] Todos os 11 finance tools funcionam no Python
- [ ] Valores financeiros sÃ£o precisos (cross-ORM verification)
- [ ] ConfirmaÃ§Ã£o funciona para mark_bill_paid e create_expense
- [ ] Categorias PTâ†’EN mapeadas corretamente

---

## M4.6 â€” Memory Tools + Context Builder Completo ðŸ”´

**Objetivo:** Tools de memÃ³ria migrados e context builder completo (system prompt com todas as instruÃ§Ãµes de tools).

**ReferÃªncias:** `docs/specs/domains/memory.md`, `docs/specs/core/ai-personality.md` Â§4-8, `ADR-012`

**DependÃªncias:** M4.4

> **Nota:** Este milestone pode rodar **em paralelo** com M4.5 (Finance Tools).

**Tasks:**

**Memory Tools (3 tools):**
- [ ] Criar `app/tools/memory/search_knowledge.py` â€” busca em knowledge_items (READ)
  - Params: query, type (opcional), area (opcional), sub_area (opcional)
  - Busca por keyword/filtros em knowledge_items
- [ ] Criar `app/tools/memory/add_knowledge.py` â€” adicionar fato/preferÃªncia/insight (WRITE, confirmation)
  - Params: content, type (fact/preference/insight), area, sub_area (opcionais)
  - Detecta duplicatas antes de inserir
- [ ] Criar `app/tools/memory/analyze_context.py` â€” anÃ¡lise de contexto memÃ³ria (READ)
  - Params: query
  - Retorna knowledge_items relevantes para contexto da conversa

**Memory Agent:**
- [ ] Criar `app/agents/domains/memory.py`:
  - Usa `create_react_agent()` com os 3 tools (ver nota sobre deprecation em M4.7)
  - System prompt com regras de memÃ³ria (tipos de knowledge, Ã¡reas, quando adicionar vs buscar)

**Context Builder Completo:**
- [ ] Expandir `app/prompts/context_builder.py` (iniciado em M4.3):
  - User memories completas: bio, occupation, family, goals, challenges, topOfMind, values, learnedPatterns
  - Tool instructions completas (~88 linhas):
    - Memory tools: quando usar search_knowledge vs add_knowledge
    - Tracking tools: confirmaÃ§Ã£o obrigatÃ³ria, nunca inventar IDs, timezone do user
    - Finance tools: mapeamento de categorias, formataÃ§Ã£o monetÃ¡ria
    - Habits tools: match por nome, regras de registro
  - Regras explÃ­citas: "sempre confirme antes de registrar", "nunca invente IDs para update/delete"
  - Counselor mode: instruÃ§Ãµes especiais para conversas tipo "counselor"
- [ ] Integrar context builder no graph principal (substituir versÃ£o simplificada de M4.3)

**Testes:**
- [ ] Teste: search_knowledge com filtros por type/area
- [ ] Teste: add_knowledge com detecÃ§Ã£o de duplicata
- [ ] Teste: context builder produz system prompt equivalente ao TypeScript
- [ ] Teste: counselor mode altera instruÃ§Ãµes corretamente
- [ ] Teste: tool instructions estÃ£o presentes e completas no prompt

**Definition of Done:**
- [ ] Memory tools funcionam no Python
- [ ] Context builder produz system prompt completo e equivalente ao TypeScript
- [ ] "O que vocÃª sabe sobre mim?" retorna informaÃ§Ãµes corretas das user_memories

---

## M4.7 â€” Multi-Agent: Triage + Domain Routing ðŸ”´

**Objetivo:** Arquitetura multi-agente com triage inteligente roteando mensagens para agentes especializados.

**ReferÃªncias:** `docs/ai-python-service-migration-plan.md` Â§4

**DependÃªncias:** M4.4, M4.5, M4.6

> **Contexto:** AtÃ© este ponto, o graph usa um Ãºnico agente com todos os tools. Este milestone implementa a arquitetura final: triage node classifica a intenÃ§Ã£o e roteia para domain agents especializados. Isso permite usar modelo rÃ¡pido (Flash) para triagem e modelo capaz (Pro) para execuÃ§Ã£o, reduzindo custo e latÃªncia.

**Tasks:**

**Triage Node:**
- [ ] Criar `app/agents/triage.py`:
  - Usa modelo rÃ¡pido: `ChatGoogleGenerativeAI(model="gemini-2.0-flash")`
  - Triage prompt com exemplos de roteamento:
    - "Registra 2L de Ã¡gua" â†’ tracking_agent
    - "Quanto gastei este mÃªs?" â†’ finance_agent
    - "O que vocÃª sabe sobre mim?" â†’ memory_agent
    - "Estou me sentindo ansioso" â†’ wellbeing_agent
    - "Bom dia!" â†’ general_agent
  - Retorna `{ current_agent: "tracking_agent" | "finance_agent" | "memory_agent" | "wellbeing_agent" | "general_agent" }`

**Wellbeing Agent (novo):**
- [ ] Criar `app/agents/domains/wellbeing.py`:
  - Sem tools (modo counselor puro)
  - System prompt com instruÃ§Ãµes de counselor mode: reflexÃ£o profunda, perguntas exploratÃ³rias, menos emojis

**Graph Atualizado:**
- [ ] Atualizar `app/agents/graph.py`:
  - START â†’ triage â†’ conditional_edges â†’ [tracking_agent, finance_agent, memory_agent, wellbeing_agent, general_agent] â†’ save_response â†’ END
  - `route_to_agent()` baseado em `state["current_agent"]`
  - Fallback para `general_agent` quando triage retorna intenÃ§Ã£o desconhecida

**Agent Registry:**
- [ ] Cada domain agent Ã© criado com `create_react_agent()` (ou `create_agent` se disponÃ­vel â€” ver nota) e seus tools especÃ­ficos:
  - `tracking_agent`: 6 tools (M4.4)
  - `finance_agent`: 11 tools (M4.5)
  - `memory_agent`: 3 tools (M4.6)
  - `wellbeing_agent`: 0 tools (counselor mode)
  - `general_agent`: 0 tools (conversacional)

> **Nota sobre `create_react_agent` deprecation:** Em LangGraph v1.0, `create_react_agent` do `langgraph.prebuilt` estÃ¡ em processo de migraÃ§Ã£o para `create_agent` de `langchain.agents`. No momento da implementaÃ§Ã£o, verificar via Context7 qual Ã© a API estÃ¡vel recomendada. Se `create_agent` jÃ¡ estiver estÃ¡vel, usar essa. Caso contrÃ¡rio, `create_react_agent` continua funcional.

**Testes:**
- [ ] Teste: 20+ mensagens classificadas corretamente pelo triage (cobrindo todos os 5 agents)
- [ ] Teste: mensagens ambÃ­guas caem no general_agent
- [ ] Teste: mensagens multi-domÃ­nio ("como estou financeiramente e na saÃºde?") â€” definir estratÃ©gia (rota para o primeiro, ou executa sequencialmente)
- [ ] Teste: wellbeing agent responde com tom de counselor
- [ ] Teste: triage com modelo Flash Ã© significativamente mais rÃ¡pido que Pro

**Definition of Done:**
- [ ] Mensagens sÃ£o roteadas para o agente correto
- [ ] Cada agente executa seus tools especializados
- [ ] Triage usa modelo rÃ¡pido, agents usam modelo capaz
- [ ] Fallback funciona para intenÃ§Ãµes ambÃ­guas

---

## M4.8 â€” Workers: Memory Consolidation + Contradiction Detection ðŸ”´

**Objetivo:** Migrar jobs assÃ­ncronos (memory consolidation, contradiction detection) para Python, mantendo BullMQ como scheduler.

**ReferÃªncias:** `docs/ai-python-service-migration-plan.md` Â§11 Fase 3, `docs/specs/domains/memory.md`

**DependÃªncias:** M4.6

> **Contexto:** `memory-consolidation.processor.ts` (557L) e `contradiction-detector.adapter.ts` (435L) usam LLM para extrair fatos de conversas e detectar contradiÃ§Ãµes. A estratÃ©gia recomendada Ã© manter BullMQ no NestJS como scheduler e chamar Python via HTTP para a lÃ³gica de AI. Isso minimiza mudanÃ§as na infraestrutura de jobs.

**Tasks:**

**Memory Consolidation:**
- [ ] Criar `app/workers/consolidation.py`:
  - Recebe: `{ user_id, timezone, date }`
  - Busca mensagens desde Ãºltima consolidaÃ§Ã£o (via ChatRepository)
  - Usa LLM para extrair fatos, preferÃªncias, insights das mensagens
  - Atualiza `user_memories`: bio, occupation, family, goals, challenges, topOfMind, values, learnedPatterns
  - Cria novos `knowledge_items` (com contradiction detection)
  - Atualiza `knowledge_items` existentes quando informaÃ§Ã£o evolui
  - Registra consolidation log em `memory_consolidations`
- [ ] Criar endpoint POST `/workers/consolidation` em `app/api/routes/workers.py`:
  - Auth via SERVICE_SECRET
  - Recebe job data, executa consolidation, retorna resultado
  - Retorna: `{ usersProcessed, usersConsolidated, usersSkipped, errors, completedAt }`

**Contradiction Detection:**
- [ ] Criar `app/memory/contradiction.py`:
  - Single item: "novo fato torna fato existente obsoleto?"
  - Batch items: check novo fato contra 3+ fatos existentes em uma chamada LLM
  - Parse JSON response do LLM com fallback para output truncado
  - Retorna: `{ is_contradiction, confidence, explanation }`
- [ ] Integrar com consolidation: antes de salvar knowledge_item, detectar contradiÃ§Ãµes

**NestJS Bridge:**
- [ ] Atualizar `memory-consolidation.processor.ts`:
  - Quando `USE_PYTHON_AI=true`: POST para Python `/workers/consolidation` via HTTP
  - Quando `false`: executa lÃ³gica TypeScript atual
  - BullMQ scheduler permanece no NestJS (sem mudanÃ§as no cron/trigger)

**Testes:**
- [ ] Teste: consolidation extrai fatos corretos de conversas
- [ ] Teste: contradictions detectadas (ex: "gosta de cafÃ©" â†’ "parou de tomar cafÃ©")
- [ ] Teste: user_memories atualizadas corretamente apÃ³s consolidation
- [ ] Teste: knowledge_items criados sem duplicatas
- [ ] Teste: endpoint /workers/consolidation retorna resultado esperado
- [ ] Teste: batch contradiction detection com mÃºltiplos fatos

**Definition of Done:**
- [ ] Consolidation job roda via BullMQ â†’ HTTP â†’ Python â†’ resultado
- [ ] Fatos extraÃ­dos corretamente de conversas
- [ ] Contradictions detectadas com confianÃ§a adequada
- [ ] Resultado equivalente ao sistema TypeScript

> **DecisÃ£o tomada:** NestJS BullMQ mantÃ©m o scheduling e chama Python via HTTP (opÃ§Ã£o A â€” menor mudanÃ§a). Existe um pacote oficial `bullmq` para Python (v2.19.5) com classe `Worker`, mas estÃ¡ classificado como **Alpha** e nÃ£o suporta todas as features do Node.js â€” por isso a decisÃ£o de manter o scheduler no NestJS. Se no futuro Python precisar de jobs prÃ³prios, considerar APScheduler ou Celery.
>
> **PadrÃ£o de comunicaÃ§Ã£o:** NestJS BullMQ (cron trigger + retry + job history) â†’ HTTP POST â†’ Python (AI/LLM execution logic) â†’ JSON response. BullMQ retry config permanece no NestJS â€” Python nÃ£o precisa implementar retry de job.

---

## M4.9 â€” Feature Parity + Parallel Validation ðŸ”´

**Objetivo:** Validar que o sistema Python produz resultados funcionalmente equivalentes ao TypeScript em todos os cenÃ¡rios antes de deletar cÃ³digo.

**ReferÃªncias:** Todos os milestones anteriores (M4.1-M4.8)

**DependÃªncias:** M4.7, M4.8

> **Contexto:** Este milestone Ã© uma "safety net" antes da limpeza. Roda ambos os sistemas em paralelo e compara resultados. Qualquer discrepÃ¢ncia Ã© corrigida antes de prosseguir para M4.10.

**Tasks:**

**Suite de Paridade (50+ cenÃ¡rios):**
- [ ] Mensagens simples:
  - "Bom dia" â†’ general agent responde
  - "Como vocÃª estÃ¡?" â†’ general agent
  - Conversa tipo counselor â†’ wellbeing agent
- [ ] Tracking com confirmaÃ§Ã£o:
  - "Registra 2L de Ã¡gua hoje" â†’ confirm â†’ verificar DB
  - "Registra 2L de Ã¡gua hoje" â†’ reject â†’ nada salvo
  - "Quanto peso eu registrei esta semana?" â†’ read â†’ dados corretos
  - "Apaga o registro de Ã¡gua de ontem" â†’ confirm â†’ delete
  - "Atualiza meu peso de hoje para 75kg" â†’ confirm â†’ update
  - "Registra que fiz exercÃ­cio hoje" â†’ confirm â†’ habit entry
- [ ] Finance queries:
  - "Quanto gastei este mÃªs?" â†’ summary correto
  - "Quais contas vencem esta semana?" â†’ pending bills
  - "Registra gasto de R$50 com almoÃ§o" â†’ confirm â†’ expense criada
  - "Marca conta de luz como paga" â†’ confirm â†’ bill updated
  - "Como estÃ£o minhas dÃ­vidas?" â†’ debt progress
- [ ] Memory:
  - "O que vocÃª sabe sobre mim?" â†’ user memories
  - "Lembra que eu prefiro cafÃ© sem aÃ§Ãºcar" â†’ confirm â†’ knowledge added
  - Busca em knowledge_items com filtros
- [ ] Multi-tool:
  - "Como estou financeiramente e na saÃºde?" â†’ mÃºltiplos agents/tools
- [ ] Edge cases:
  - Timeout de LLM â†’ error handling graceful
  - Tool nÃ£o encontrado â†’ error message
  - ConfirmaÃ§Ã£o apÃ³s 5+ minutos â†’ behavior correto (LangGraph checkpoints persistem em PostgreSQL sem TTL por default, diferente do Redis 5min anterior)
  - Mensagem vazia â†’ rejection ou resposta default

**SSE Event Compatibility:**
- [ ] Verificar que todos os SSE events emitidos pelo Python tÃªm o mesmo formato do TypeScript:
  - `tool_calls` (iteration, toolCalls array)
  - `tool_result` (toolName, result, success)
  - `confirmation_required` (confirmationId, toolName, toolArgs, message, expiresAt)
  - Final response `{ content, done: true }`
  - Error `{ content, done: true, error }`
  - `{ done: true, awaitingConfirmation: true }`
- [ ] Frontend funciona sem nenhuma mudanÃ§a de cÃ³digo

**Performance:**
- [ ] Load testing: 50 concurrent chat requests ao Python service
- [ ] Verificar latÃªncia do proxy NestJS â†’ Python (deve ser <50ms overhead)
- [ ] Verificar que triage com Flash model < 500ms
- [ ] Validar `InMemoryRateLimiter` do LangChain sob carga (single-process). Se insuficiente em produÃ§Ã£o com mÃºltiplos workers uvicorn, avaliar Redis-based rate limiter como melhoria futura

**Observabilidade:**
- [ ] Sentry configurado para Python service (error tracking)
- [ ] Structured logging (JSON) com request_id para correlaÃ§Ã£o com NestJS
- [ ] Health check inclui status do DB (Python nÃ£o depende de Redis)

**Testes:**
- [ ] Suite completa de paridade passa (50+ cenÃ¡rios)
- [ ] Frontend funciona sem mudanÃ§as
- [ ] Load test: sem erros em 50 concurrent requests
- [ ] Sentry captura erros do Python service

**Definition of Done:**
- [ ] Todos os cenÃ¡rios produzem resultados funcionalmente equivalentes
- [ ] Frontend funciona identicamente com `USE_PYTHON_AI=true` e `false`
- [ ] Performance aceitÃ¡vel sob carga
- [ ] Observabilidade configurada

---

## M4.10 â€” NestJS Cleanup + Production Deploy ðŸ”´

**Objetivo:** Deletar todo o cÃ³digo TypeScript AI obsoleto (~13.400 linhas), simplificar NestJS para proxy, deploy em produÃ§Ã£o.

**ReferÃªncias:** `docs/ai-python-service-migration-plan.md` Â§5, Â§7, Â§12

**DependÃªncias:** M4.9

> **Contexto:** Este Ã© o milestone de maior risco â€” deleta ~13.400 linhas de cÃ³digo AI em produÃ§Ã£o (~11.600 deletadas + ~2.700 simplificadas). A safety net Ã© o M4.9 (validaÃ§Ã£o de paridade) e o deploy strategy (blue-green ou canary). Rollback Ã© possÃ­vel revertendo o commit + `USE_PYTHON_AI=false`.

**Tasks:**

**Deletar packages/ai/ (~7.677 linhas):**
- [ ] Deletar diretÃ³rio `packages/ai/` inteiro
- [ ] Remover `@life-assistant/ai` do `pnpm-workspace.yaml`
- [ ] Remover dependÃªncias npm: `@anthropic-ai/sdk`, `@google/genai`, `zod-to-json-schema`
- [ ] Remover referÃªncias em `tsconfig` base

**Deletar tool executors do NestJS:**
- [ ] Deletar `tracking-tool-executor.service.ts` (~587L)
- [ ] Deletar `finance-tool-executor.service.ts` (~1.047L)
- [ ] Deletar `memory-tool-executor.service.ts` (~297L)
- [ ] Remover providers dos respectivos modules

**Deletar serviÃ§os AI do NestJS:**
- [ ] Deletar `confirmation-state.service.ts` (~475L)
- [ ] Deletar `context-builder.service.ts` (~337L)
- [ ] Deletar `contradiction-detector.adapter.ts` (~435L)

**Simplificar memory consolidation:**
- [ ] Remover lÃ³gica LLM do `memory-consolidation.processor.ts` (~557L)
- [ ] Manter apenas: BullMQ trigger â†’ HTTP POST para Python `/workers/consolidation`
- [ ] Resultado: ~50 linhas (de ~557)

**Simplificar chat.service.ts:**
- [ ] Remover lÃ³gica de tool loop TypeScript
- [ ] Remover imports de `@life-assistant/ai`
- [ ] Remover feature flag `USE_PYTHON_AI` (Python Ã© o Ãºnico caminho)
- [ ] Resultado: ~200 linhas (de ~1.232) â€” apenas: salvar msg do user + proxy HTTP/SSE para Python

**Simplificar chat.module.ts:**
- [ ] Remover providers de AI/tools/confirmation
- [ ] Manter apenas: ChatController, ChatService (proxy), ChatRepository, MessageRepository

**Atualizar monorepo:**
- [ ] Remover imports quebrados em todo o codebase
- [ ] Atualizar `CLAUDE.md` â€” remover referÃªncias a `packages/ai/`, adicionar `services/ai/`
- [ ] Atualizar `docs/specs/core/architecture.md` â€” nova arquitetura de 3 serviÃ§os

**Testes de regressÃ£o:**
- [ ] `pnpm typecheck` â€” sem erros de tipo
- [ ] `pnpm lint` â€” sem erros de lint
- [ ] `pnpm test` â€” todos os testes unitÃ¡rios passam
- [ ] `pnpm test:e2e` â€” todos os testes E2E passam (Playwright)
- [ ] Testes de paridade de M4.9 ainda passam

**Deploy produÃ§Ã£o:**
- [ ] Railway: criar serviÃ§o Python AI (Nixpacks, Python buildpack)
- [ ] Railway: configurar internal networking (`python-ai.railway.internal:8000`)
- [ ] Railway: configurar env vars (DATABASE_URL, GEMINI_API_KEY, SERVICE_SECRET)
- [ ] Deploy strategy: blue-green ou canary
- [ ] Monitoramento pÃ³s-deploy: 24-48h de observaÃ§Ã£o
- [ ] Verificar Sentry: sem novos erros no Python service
- [ ] Verificar logs: requests fluindo corretamente NestJS â†’ Python

**Definition of Done:**
- [ ] `packages/ai/` deletado (0 linhas)
- [ ] NestJS `chat.service.ts` Ã© ~200L de proxy (de ~1.232L)
- [ ] `pnpm typecheck && pnpm lint && pnpm test` passam
- [ ] `pnpm test:e2e` passa
- [ ] ProduÃ§Ã£o estÃ¡vel por 48h sem novos erros
- [ ] Total removido: **~11.600 linhas deletadas** + **~2.700 simplificadas** (~1.800 delta removido)

> **Riscos:**
> - RegressÃµes em edge cases de confirmaÃ§Ã£o (SSE event ordering diferente)
> - Imports quebrados em arquivos nÃ£o cobertos pelos testes
> - Performance em produÃ§Ã£o diferente de local (latÃªncia Railway internal networking)
> - Rollback plan: reverter commit + `USE_PYTHON_AI=false` no NestJS (requer que packages/ai/ ainda exista no git history)

---

## Resumo Quantitativo

| MÃ©trica | Valor |
|---|---|
| Milestones | 10 (M4.1 â€” M4.10) |
| Linhas deletadas do NestJS | **~11.600** (deletadas) + **~2.700** (simplificadas, ~1.800 delta removido) |
| Linhas adicionadas no NestJS | ~160 (proxy SSE + config + feature flag) |
| Novo cÃ³digo Python | **~5.000-7.000** (estimativa â€” Python mais conciso que TypeScript equivalente) |
| SQLAlchemy models | ~120-200 linhas (mapeamento passivo + CI check) |
| Pacote deletado | `packages/ai/` (**7.677 linhas**, 49 arquivos) |
| Novo diretÃ³rio | `services/ai/` (Python AI Service) |
| ServiÃ§os NestJS intactos | Auth, REST controllers, domain services, repositories, BullMQ (scheduler) |
| MudanÃ§as no frontend | Nenhuma (SSE events mantÃªm mesmo formato) |

### Estrutura do monorepo apÃ³s migraÃ§Ã£o

```
life-assistant/
â”œâ”€â”€ apps/
â”‚   â”œâ”€â”€ web/                    # Next.js (sem mudanÃ§as)
â”‚   â””â”€â”€ api/                    # NestJS (simplificado â€” sem AI code)
â”‚
â”œâ”€â”€ services/
â”‚   â””â”€â”€ ai/                     # Python AI Service (NOVO)
â”‚       â”œâ”€â”€ app/
â”‚       â”‚   â”œâ”€â”€ agents/         # LangGraph agents + graph
â”‚       â”‚   â”œâ”€â”€ api/            # FastAPI routes + middleware
â”‚       â”‚   â”œâ”€â”€ db/             # SQLAlchemy models + repositories
â”‚       â”‚   â”œâ”€â”€ memory/         # Contradiction detection
â”‚       â”‚   â”œâ”€â”€ prompts/        # System prompt + context builder
â”‚       â”‚   â”œâ”€â”€ tools/          # 20 tool implementations
â”‚       â”‚   â””â”€â”€ workers/        # Memory consolidation
â”‚       â”œâ”€â”€ tests/
â”‚       â”œâ”€â”€ pyproject.toml
â”‚       â””â”€â”€ Dockerfile
â”‚
â”œâ”€â”€ packages/
â”‚   â”œâ”€â”€ database/               # Drizzle schemas + migrations (source of truth)
â”‚   â”œâ”€â”€ config/                 # Zod config (NestJS)
â”‚   â””â”€â”€ shared/                 # Shared enums/constants
â”‚   # packages/ai/ â†’ DELETADO em M4.10
â”‚
â”œâ”€â”€ docs/
â”œâ”€â”€ infra/
â””â”€â”€ ...
```
