# Fase 4: MigraÃ§Ã£o da IA para Python (v4.x)

> **Objetivo:** Migrar toda a camada de inteligÃªncia artificial (packages/ai/ + tool executors + memory workers) de TypeScript/NestJS para um serviÃ§o Python independente com FastAPI + LangGraph, seguindo o padrÃ£o Strangler Fig.
> **ReferÃªncias:** `docs/ai-python-service-migration-plan.md`, `docs/adr-012-tool-use-vs-rag-analysis.md`, `docs/specs/core/architecture.md`

> **Contexto:** O ecossistema Python domina AI/ML (LangGraph, LangChain, LangSmith, scikit-learn, pandas). A implementaÃ§Ã£o atual em TypeScript (`packages/ai/` â€” 7.677 linhas, 49 arquivos) foi adequada para o MVP mas limita a evoluÃ§Ã£o para multi-agente, RAG futuro, e ferramentas avanÃ§adas de observabilidade de AI. A migraÃ§Ã£o cria um serviÃ§o Python dedicado (`services/ai/`) mantendo NestJS como API REST + auth + dashboard.
>
> **Filosofia:**
> - **Strangler Fig:** Sistema TypeScript e Python coexistem via feature flag (`USE_PYTHON_AI`). Rollback instantÃ¢neo em qualquer ponto.
> - **Milestones atÃ´micos:** Cada milestone produz um sistema funcional e testÃ¡vel. Nunca hÃ¡ estado quebrado entre milestones.
> - **LangGraph substitui, nÃ£o porta:** Muitos componentes TypeScript custom (~1.639 linhas) sÃ£o substituÃ­dos por primitivas LangGraph, nÃ£o portados 1:1.
> - **Python independente do Turbo:** O serviÃ§o Python **NÃƒO** faz parte do pnpm workspace nem do Turborepo pipeline. Python Ã© gerido 100% com ferramentas nativas (uv, ruff, mypy, pytest). O `pnpm dev` usa `concurrently` para iniciar Turbo + Python em paralelo. CI roda jobs Node e Python separados. DecisÃ£o baseada em [Turborepo multi-language docs](https://turborepo.dev/docs/guides/multi-language) e anÃ¡lise de trade-offs â€” o pattern de package.json wrapper Ã© oficialmente suportado pelo Turbo, mas gera artefatos artificiais (node_modules, lockfile entries) sem benefÃ­cio real de cache para Python.

### Insight: O que LangGraph substitui

A migraÃ§Ã£o **NÃƒO Ã© um port 1:1** do TypeScript. LangGraph substitui vÃ¡rios componentes custom:

| Componente TypeScript | Linhas | Equivalente LangGraph/LangChain | Resultado |
|---|---|---|---|
| `tool-loop.service.ts` | 310 | `create_react_agent()` (`langgraph.prebuilt`) | **Eliminado** |
| `LLMPort` interface | 245 | `ChatGoogleGenerativeAI` (`langchain-google-genai`) / `ChatAnthropic` (`langchain-anthropic`) | **Eliminado** |
| `retry.ts` + `rate-limiter.ts` | 382 | `max_retries` + `.with_retry()` + `InMemoryRateLimiter` (LangChain built-in) | **Eliminado** |
| `zod-to-gemini.ts` | 227 | `.bind_tools()` converte Pydantic â†’ formato do provider automaticamente | **Eliminado** |
| `confirmation-state.service.ts` (Redis TTL 5min) | 475 | `interrupt()` / `Command(resume=)` (`langgraph.types`) com PostgreSQL checkpoint (`AsyncPostgresSaver`) | **Redesenhado** |
| Tool definitions (Zod schemas) | ~1.000 | Pydantic models + `@tool` decorator | **Reescrito** |

> ~1.639 linhas de `packages/ai/` nÃ£o precisam ser portadas â€” sÃ£o substituÃ­das por primitivas LangGraph. O cÃ³digo Python serÃ¡ mais enxuto que o TypeScript equivalente.

### InventÃ¡rio do cÃ³digo afetado

**packages/ai/ (7.677 linhas, 49 arquivos) â€” serÃ¡ DELETADO:**

| Categoria | Linhas | Arquivos | Destino |
|---|---|---|---|
| Adapters (Claude + Gemini) | 1.932 | 4 | SubstituÃ­dos por `langchain-google-genai` / `langchain-anthropic` |
| Services (Factory, ToolLoop, Executor) | 1.503 | 7 | SubstituÃ­dos por LangGraph `create_react_agent()` |
| Tool definitions (22 tools + schemas) | 2.159 | 27 | Reescritos como Pydantic + `@tool` decorator |
| Utilities (retry, rate-limit, zod-to-gemini) | 1.484 | 8 | SubstituÃ­dos por primitivas LangChain |
| Ports/Interfaces | 245 | 1 | Eliminados (LangGraph abstrai) |
| Errors + Core | 354 | 2 | Python exception hierarchy |

**apps/api/ â€” cÃ³digo AI-related (~5.700 linhas) â€” serÃ¡ DELETADO ou SIMPLIFICADO:**

| Arquivo | Linhas | AÃ§Ã£o |
|---|---|---|
| `chat.service.ts` | 1.232 | Simplificado para ~200L (proxy SSE) |
| `finance-tool-executor.service.ts` | 1.047 | Deletado (migra para Python) |
| `tracking-tool-executor.service.ts` | 587 | Deletado (migra para Python) |
| `memory-consolidation.processor.ts` | 557 | Simplificado para ~50L (BullMQ trigger â†’ HTTP POST para Python) |
| `confirmation-state.service.ts` | 475 | Deletado (LangGraph interrupt) |
| `contradiction-detector.adapter.ts` | 435 | Deletado (migra para Python) |
| `context-builder.service.ts` | 337 | Deletado (migra para Python) |
| `memory-tool-executor.service.ts` | 297 | Deletado (migra para Python) |
| `consolidation-prompt.ts` | 337 | Deletado (migra para Python) |
| `contradiction-resolution.service.ts` | 311 | Deletado (migra para Python) |
| `contradiction-detector.port.ts` | 86 | Deletado (interface eliminada) |

**Total:** ~11.600 linhas deletadas + ~2.700 simplificadas (~1.800 delta removido) â†’ ~5.000-7.000 linhas Python novas

### Paralelismo entre milestones

- M4.5 (Finance Tools) e M4.6 (Memory Tools) podem rodar **em paralelo** (ambos dependem de M4.4 mas sÃ£o independentes entre si)
- M4.1 pode comeÃ§ar **imediatamente** sem afetar trabalho nas outras fases
- Feature flag permite **rollback instantÃ¢neo** em qualquer ponto da migraÃ§Ã£o

---

## M4.1 â€” Python Service: Scaffold + Infra + CI ðŸŸ¢

**Objetivo:** ServiÃ§o Python bootÃ¡vel com FastAPI, integrado no fluxo de dev local (`pnpm infra:up` + `pnpm dev`) e CI. Nenhuma lÃ³gica de AI â€” apenas infraestrutura.

**ReferÃªncias:** `docs/ai-python-service-migration-plan.md` Â§3, Â§10

**DependÃªncias:** Nenhuma (pode comeÃ§ar imediatamente)

> **DecisÃ£o arquitetural:** O serviÃ§o Python NÃƒO faz parte do pnpm workspace nem do Turborepo. Python Ã© gerido com ferramentas nativas (uv, ruff, mypy, pytest). `pnpm dev` usa `concurrently` para iniciar Turbo (JS/TS) + uvicorn (Python) em paralelo. Esta decisÃ£o segue o princÃ­pio de separaÃ§Ã£o de concerns â€” cada linguagem com seu toolchain nativo, sem artefatos artificiais.

**Tasks:**

**Scaffold do projeto Python (via CLI):**
- [x] Inicializar projeto: `uv init --app --python 3.12 services/ai`
  - Cria: `pyproject.toml`, `.python-version`, `.gitignore`, `README.md`, `main.py`
  - Flag `--no-workspace` se existir `pyproject.toml` na raiz do monorepo (evita auto-join)
- [x] Adicionar dependÃªncias runtime:
  ```bash
  cd services/ai
  uv add fastapi 'uvicorn[standard]' 'sqlalchemy[asyncio]' asyncpg langgraph langgraph-checkpoint-postgres langchain-google-genai langchain-anthropic pydantic pydantic-settings sse-starlette
  ```
- [x] Adicionar dependÃªncias dev:
  ```bash
  uv add --dev pytest pytest-asyncio ruff mypy httpx
  ```
- [x] Configurar tool settings no `pyproject.toml` (seÃ§Ãµes `[tool.ruff]`, `[tool.mypy]`, `[tool.pytest.ini_options]`)
- [x] Remover `main.py` gerado pelo scaffold e reorganizar para estrutura `app/`:
  ```
  services/ai/
  â”œâ”€â”€ app/
  â”‚   â”œâ”€â”€ __init__.py
  â”‚   â”œâ”€â”€ main.py          # FastAPI app + lifespan (startup/shutdown)
  â”‚   â”œâ”€â”€ config.py         # Pydantic Settings (BaseSettings)
  â”‚   â”œâ”€â”€ dependencies.py   # FastAPI Depends() â€” DB session, config
  â”‚   â””â”€â”€ api/
  â”‚       â”œâ”€â”€ routes/
  â”‚       â”‚   â””â”€â”€ health.py # GET /health (status + DB check)
  â”‚       â””â”€â”€ middleware/
  â”‚           â””â”€â”€ auth.py   # Service-to-service auth (Bearer token)
  â”œâ”€â”€ tests/
  â”œâ”€â”€ pyproject.toml
  â”œâ”€â”€ uv.lock
  â””â”€â”€ .python-version
  ```
- [x] Criar `app/main.py` com FastAPI lifespan:
  - Startup: `AsyncPostgresSaver.setup()` (cria tabelas de checkpoint: `checkpoints`, `checkpoint_blobs`, `checkpoint_writes`, `checkpoint_migrations`)
  - Shutdown: dispose engine
- [x] Criar `app/config.py` com Pydantic Settings:
  - `DATABASE_URL`, `GEMINI_API_KEY`, `SERVICE_SECRET`, `ANTHROPIC_API_KEY` (opcional)
  - Loads from root `.env` via `model_config = SettingsConfigDict(env_file="../../.env")`
- [x] Criar `app/dependencies.py` â€” FastAPI `Depends()` com generator `yield` para DB session
- [x] Criar `app/api/routes/health.py` â€” GET /health (status + versÃ£o + check de DB)
- [x] Criar `app/api/middleware/auth.py` â€” service-to-service auth via shared secret (Bearer token)
- [x] Estender `.gitignore` gerado pelo uv: adicionar `__pycache__/`, `.mypy_cache/`, `.pytest_cache/`, `.ruff_cache/`

> **Nota:** `sse-starlette` Ã© dependÃªncia explÃ­cita â€” FastAPI nÃ£o tem classe SSE built-in. Usar `EventSourceResponse` para streaming.
> **Nota:** `REDIS_URL` removido da config Python â€” nÃ£o necessÃ¡rio na fase inicial. ConfirmaÃ§Ã£o usa PostgreSQL (LangGraph checkpoints), nÃ£o Redis TTL. BullMQ scheduling permanece no NestJS.

**IntegraÃ§Ã£o com `pnpm dev` (via `concurrently`):**
- [x] Instalar concurrently: `pnpm add -Dw concurrently`
- [x] Atualizar `package.json` root:
  ```json
  {
    "scripts": {
      "dev": "concurrently -k -p [{name}] -n turbo,ai -c blue,yellow \"turbo run dev\" \"cd services/ai && uv run uvicorn app.main:app --reload --host 0.0.0.0 --port 8000\"",
      "dev:js": "turbo run dev",
      "dev:ai": "cd services/ai && uv run uvicorn app.main:app --reload --host 0.0.0.0 --port 8000"
    }
  }
  ```
- [x] Verificar que `Ctrl+C` mata todos os processos (flag `-k` do concurrently)
- [x] Verificar que output mostra prefixos `[turbo]` e `[ai]` no terminal

**IntegraÃ§Ã£o com `pnpm infra:up` (dev-start.sh):**
- [x] Adicionar porta 8000 ao `check_ports()` existente
- [x] Criar novo Step (entre Service Status e Database Schema):
  ```
  Step 4: Python AI Service Setup
    âœ“ Check Python 3.12+
    âœ“ Check uv package manager
    âœ“ Install dependencies (uv sync)
    âœ“ Python environment ready
  ```
- [x] Implementar `check_python()`:
  - Verificar `python3 --version` >= 3.12
  - Se nÃ£o encontrado: mensagem com instruÃ§Ãµes de instalaÃ§Ã£o
- [x] Implementar `check_uv()`:
  - Verificar `uv --version`
  - Se nÃ£o encontrado: sugerir `curl -LsSf https://astral.sh/uv/install.sh | sh`
- [x] Implementar `setup_python_env()`:
  - `cd services/ai && uv sync` (cria .venv + instala deps)
  - Idempotente: <2s em runs subsequentes
  - VerificaÃ§Ã£o: `uv run python -c "import fastapi; print('OK')"`
- [x] Atualizar summary final para mostrar Python AI Service URL (localhost:8000)
- [x] Renumerar steps: 1-Docker, 2-Supabase, 3-Status, **4-Python**, 5-Database

**Docker (produÃ§Ã£o + CI):**
- [x] Criar `services/ai/Dockerfile`:
  ```dockerfile
  FROM python:3.12-slim AS base
  WORKDIR /app
  RUN pip install uv

  FROM base AS deps
  COPY pyproject.toml uv.lock ./
  RUN uv sync --frozen --no-dev

  FROM base AS runner
  COPY --from=deps /app/.venv /app/.venv
  COPY app/ app/
  ENV PATH="/app/.venv/bin:$PATH"
  EXPOSE 8000
  CMD ["uvicorn", "app.main:app", "--host", "0.0.0.0", "--port", "8000"]
  ```
- [x] Criar `services/ai/.dockerignore` â€” `.venv/`, `__pycache__/`, `.git/`, `tests/`, `.mypy_cache/`
- [x] **NÃƒO** adicionar Python ao docker-compose.yml (Python roda nativo em dev, Docker sÃ³ para produÃ§Ã£o)

**VariÃ¡veis de ambiente:**
- [x] Adicionar ao `.env.example`:
  ```bash
  # Python AI Service
  PYTHON_AI_URL=http://localhost:8000
  SERVICE_SECRET=dev-secret-change-me
  USE_PYTHON_AI=false
  ```
- [x] Adicionar `PYTHON_AI_URL` ao `packages/config/`

**CI (GitHub Actions â€” job separado):**
- [x] Criar `services/ai/tests/conftest.py` â€” fixtures base (async test client via `httpx.AsyncClient`, test DB session)
- [x] Adicionar job `python` no workflow CI:
  ```yaml
  python:
    runs-on: ubuntu-latest
    defaults:
      run:
        working-directory: services/ai
    steps:
      - uses: actions/checkout@v4
      - uses: astral-sh/setup-uv@v5
        with:
          python-version: "3.12"
      - run: uv sync
      - run: uv run ruff check .
      - run: uv run ruff format --check .
      - run: uv run mypy app/
      - run: uv run pytest
  ```
- [x] Job Python roda em **paralelo** com job Node (nÃ£o sequencial)

**DocumentaÃ§Ã£o:**
- [x] Atualizar `CLAUDE.md`:
  - Requirements: adicionar `Python >=3.12, uv`
  - Commands: adicionar `pnpm dev:ai` e explicar `pnpm dev` (agora usa concurrently)
  - Estrutura do monorepo: adicionar `services/ai/`
- [x] Atualizar `DEVELOPMENT.md` (se existir) com setup Python

**Definition of Done:**
- [x] `pnpm infra:up` verifica Python, instala deps via `uv sync`
- [x] `pnpm dev` inicia web (:3000) + api (:4000) + python (:8000) em paralelo
- [x] `curl http://localhost:8000/health` retorna 200
- [x] Request sem Bearer token retorna 401
- [x] CI passa: job Node (turbo) + job Python (ruff, mypy, pytest) em paralelo
- [x] `Ctrl+C` no `pnpm dev` mata todos os processos
- [x] `services/ai/` NÃƒO aparece em `pnpm-workspace.yaml` nem `pnpm-lock.yaml`

### Notas

_ConcluÃ­do em 2026-02-22._

**Melhorias sobre o plano original:**
- Adicionada dependÃªncia `psycopg[binary]` â€” necessÃ¡ria para `langgraph-checkpoint-postgres` funcionar sem `libpq` nativo instalado no sistema
- Dockerfile usa `COPY --from=ghcr.io/astral-sh/uv:latest /uv /uvx /bin/` em vez de `RUN pip install uv` â€” mais eficiente (layer de cache, sem pip)
- CI usa `astral-sh/setup-uv@v7` (plano dizia `@v5`, Context7 confirmou v7 como latest)
- `AsyncPostgresSaver.from_conn_string()` retorna context manager (`async with`) â€” validado via Context7 docs + source code inspection. Plano nÃ£o especificava esse detalhe
- Entradas Python adicionadas no `.gitignore` root em vez de criar `.gitignore` separado em `services/ai/` (jÃ¡ coberto pelo root)
- `README.md` gerado pelo `uv init` removido (desnecessÃ¡rio)
- Auth middleware implementado como `BaseHTTPMiddleware` do Starlette com `PUBLIC_PATHS` incluindo `/health`, `/docs`, `/openapi.json`, `/redoc`
- Testes do `@life-assistant/config` e `apps/api/test/setup.ts` atualizados para incluir `SERVICE_SECRET` nos fixtures (campo obrigatÃ³rio adicionado ao `envSchema`)

**VerificaÃ§Ã£o local:**
- Python: ruff check (0), ruff format (15 files OK), mypy (0 issues, 11 files), pytest (5/5)
- JS/TS: typecheck (10/10), lint (5/6 â€” web failure preexistente), test (5/6 â€” web failures preexistentes)
- Health endpoint: `curl localhost:8000/health` â†’ 200 `{"status":"ok","version":"0.1.0","database":"connected"}`
- Auth: endpoint sem Bearer â†’ 401, `/health` sem auth â†’ 200
- Isolamento: `services/ai/` nÃ£o aparece em `pnpm-workspace.yaml` nem `pnpm-lock.yaml`
- Concurrently rodando com flags corretos (`-k -p [{name}] -n turbo,ai -c blue,yellow`)

---

## M4.2 â€” SQLAlchemy Data Layer + RLS ðŸŸ¢

**Objetivo:** Python consegue ler/escrever no PostgreSQL com Row Level Security, mapeando tabelas do Drizzle.

**ReferÃªncias:** `docs/ai-python-service-migration-plan.md` Â§8, `docs/specs/core/data-conventions.md`, `docs/specs/core/auth-security.md`

**DependÃªncias:** M4.1

> **Contexto:** Drizzle (NestJS) Ã© o source of truth para schema e migrations. SQLAlchemy models sÃ£o mapeamentos passivos â€” nÃ£o geram migrations. PostgreSQL garante integridade via constraints, foreign keys e RLS policies independente de qual ORM escreve.

**Tasks:**

**Engine + Session:**
- [x] Criar `app/db/engine.py`:
  - `create_async_engine("postgresql+asyncpg://...")` com pool config
  - `async_sessionmaker(engine, expire_on_commit=False)` â€” `expire_on_commit=False` obrigatÃ³rio para evitar lazy-loading I/O em async
- [x] Criar `app/db/session.py` â€” context managers RLS-aware que executam `SET LOCAL request.jwt.claim.sub = '{user_id}'` antes de cada operaÃ§Ã£o (matching NestJS `set_config('request.jwt.claim.sub', ...)` e RLS policies que usam `auth.uid()`)
  - Deve ser **obrigatÃ³rio** â€” impossÃ­vel fazer query sem user_id setado
  - Testes que tentam query sem middleware devem falhar com RLS

**Models (mapeamento passivo das tabelas Drizzle):**
- [x] Criar `app/db/models/base.py` â€” `DeclarativeBase` + mixins comuns (`TimestampMixin`, `SoftDeleteMixin`)
- [x] Criar `app/db/models/enums.py` â€” Enums Python (`StrEnum`) espelhando os PostgreSQL `CREATE TYPE` (22 enums usados pelas tabelas modeladas)
- [x] Criar `app/db/models/users.py` â€” `users`, `user_memories` (read-only para Python)
- [x] Criar `app/db/models/tracking.py` â€” `tracking_entries`, `custom_metric_definitions`, `habits`, `habit_completions`
- [x] Criar `app/db/models/finance.py` â€” `incomes`, `bills`, `variable_expenses`, `debts`, `debt_payments`, `investments`, `budgets`
- [x] Criar `app/db/models/memory.py` â€” `knowledge_items`, `memory_consolidations`
- [x] Criar `app/db/models/chat.py` â€” `conversations`, `messages`
- [x] Todos os `Numeric` fields com `asdecimal=False` na definiÃ§Ã£o do model (retorna `float` ao invÃ©s de `Decimal`):
  ```python
  amount = mapped_column(Numeric(precision=12, scale=2, asdecimal=False))  # â†’ float
  ```

> **NUNCA criar SQLAlchemy models para tabelas de checkpoint do LangGraph** (`checkpoints`, `checkpoint_blobs`, `checkpoint_writes`, `checkpoint_migrations`). Essas tabelas sÃ£o gerenciadas exclusivamente pelo `AsyncPostgresSaver.setup()` chamado no lifespan do FastAPI (M4.1).

**Repositories:**
- [x] Criar `app/db/repositories/tracking.py` â€” TrackingRepository (create, find, aggregate, update, delete)
- [x] Criar `app/db/repositories/finance.py` â€” FinanceRepository (summary, bills, expenses, incomes, investments, debts)
- [x] Criar `app/db/repositories/memory.py` â€” MemoryRepository (search knowledge, add knowledge, get user memories)
- [x] Criar `app/db/repositories/chat.py` â€” ChatRepository (save message, get history, get conversation)
- [x] Criar `app/db/repositories/user.py` â€” UserRepository (get user, get settings â€” read-only)

**Schema Drift CI Check:**
- [x] Criar script `services/ai/scripts/check_schema_drift.py`:
  - Conecta ao DB, lÃª `information_schema` real
  - Compara com SQLAlchemy models declarados
  - Falha se tabela/coluna/tipo existir no DB mas nÃ£o no model (ou vice-versa)
- [x] Integrar no CI: roda a cada PR que toca `packages/database/src/schema/` ou `services/ai/app/db/models/`

**Testes:**
- [x] Teste de integraÃ§Ã£o: RLS impede User A de ler dados do User B
- [x] Teste de integraÃ§Ã£o: DECIMAL fields retornam `float`, nÃ£o `Decimal`
- [x] Teste de integraÃ§Ã£o: CRUD completo em cada repository (tracking, finance, memory, chat)
- [x] Teste: session RLS rejeita session sem user_id

**Definition of Done:**
- [x] Python lÃª/escreve em todas as tabelas necessÃ¡rias
- [x] RLS funciona: user A nÃ£o vÃª dados de user B
- [x] DECIMAL â†’ float em todas as queries
- [x] CI detecta schema drift quando Drizzle muda e SQLAlchemy nÃ£o acompanha
- [x] Testes de integraÃ§Ã£o passam

> **Riscos:**
> - DECIMAL handling: Drizzle retorna **string**, SQLAlchemy retorna **`Decimal`** por default. SoluÃ§Ã£o: usar `Numeric(asdecimal=False)` em todos os money fields nos models SQLAlchemy. Testes de integraÃ§Ã£o que comparam outputs dos dois ORMs para as mesmas queries.
> - RLS com SQLAlchemy async pode ter edge cases com connection pooling (`expire_on_commit=False` Ã© obrigatÃ³rio). Testar com mÃºltiplos users concorrentes.
> - Concurrent writes: ambos os serviÃ§os escrevem na mesma tabela (ex: `tracking_entries`). Usar `ON CONFLICT` / upsert patterns. Idempotency keys para write operations via chat.

### Notas

_ConcluÃ­do em 2026-02-23._

**Melhorias sobre o plano original:**
- RLS implementado como context managers em `app/db/session.py` (`get_user_session`, `get_service_session`) em vez de middleware HTTP (`app/db/middleware.py` no plano original). Context managers sÃ£o mais seguros â€” garantem que `SET LOCAL` e a transaÃ§Ã£o estejam sempre no mesmo escopo, e permitem uso direto em workers/scripts sem depender do ciclo HTTP. `get_service_session()` adicional para worker jobs que bypassam RLS via `SET LOCAL role = 'service_role'`
- 22 enums implementados (dos 30 no DB) â€” apenas os referenciados pelas tabelas que Python modela. Enums nÃ£o utilizados (ex: `vault_item_type`, `notification_type`, `export_status`) ficam de fora atÃ© que Python precise dessas tabelas
- Colunas `metadata` nos modelos `TrackingEntry`, `Conversation` e `Message` renomeadas no Python (`entry_metadata`, `conversation_metadata`, `message_metadata`) com mapeamento explÃ­cito `mapped_column("metadata", JSON)` porque `metadata` Ã© atributo reservado do `DeclarativeBase` do SQLAlchemy. A coluna no banco continua `metadata`
- `app/main.py` refatorado para usar `get_async_engine()` e `get_session_factory()` do novo mÃ³dulo `app/db/engine`, com `session_factory` armazenado em `app.state`
- `app/dependencies.py` estendido com `get_db_session()` que injeta sessÃ£o RLS-scoped via FastAPI `Depends()`
- Schema drift check integrado no job `e2e` do CI (apÃ³s migrations, antes do build) â€” requer Supabase rodando, por isso roda no e2e e nÃ£o no job `python`
- Testes de integraÃ§Ã£o (RLS + repositories) usam flag `--run-db` e sÃ£o skipped automaticamente no CI sem Supabase. 16 testes unitÃ¡rios (models) passam sem DB

**VerificaÃ§Ã£o local:**
- Python: ruff check (0 errors), ruff format (34 files OK), mypy (0 issues, 26 files), pytest (16 passed, 14 skipped)
- JS/TS: typecheck (10/10 cached) â€” nenhuma regressÃ£o

---

## M4.3 â€” LangGraph Basic Chat + NestJS Proxy ðŸŸ¢

**Objetivo:** Primeira mensagem end-to-end pelo Python service: Frontend â†’ NestJS â†’ Python â†’ resposta. Chat funcional sem tools.

**ReferÃªncias:** `docs/ai-python-service-migration-plan.md` Â§2, Â§4, Â§9

**DependÃªncias:** M4.2

> **Contexto:** Este milestone estabelece o "pipe" completo. Depois que mensagens fluem end-to-end, os milestones seguintes adicionam tools incrementalmente. O frontend NÃƒO muda â€” NestJS proxeia SSE transparentemente.

**Tasks:**

**LangGraph Core:**
- [x] Criar `app/agents/state.py` â€” `AgentState` TypedDict:
  ```python
  class AgentState(TypedDict):
      messages: Annotated[list, add_messages]
      user_id: str
      conversation_id: str
      current_agent: str | None
  ```
- [x] Criar `app/agents/llm.py` â€” LLM factory baseado em `LLM_PROVIDER` env (Gemini/Anthropic)
- [x] Criar `app/agents/domains/general.py` â€” agente conversacional (sem tools, sÃ³ responde)
  - Usa LLM factory (model configurÃ¡vel via `LLM_MODEL` env, default `gemini-2.5-flash`)
- [x] Criar `app/agents/graph.py` â€” StateGraph bÃ¡sico:
  - START â†’ general_agent â†’ save_response â†’ END
  - `AsyncPostgresSaver` como checkpointer (persistÃªncia de threads)
  - Import: `from langgraph.checkpoint.postgres.aio import AsyncPostgresSaver`
  - `.setup()` chamado no lifespan do FastAPI (M4.1) â€” cria tabelas `checkpoints`, `checkpoint_blobs`, `checkpoint_writes`, `checkpoint_migrations`
- [x] Criar `app/agents/save_response.py` â€” node que salva mensagem do assistente no DB via SQLAlchemy

**Context Builder (versÃ£o simplificada):**
- [x] Criar `app/prompts/system.py` â€” system prompt base:
  - Nome do usuÃ¡rio, timezone, data atual
  - Personalidade conforme `docs/specs/core/ai-personality.md`
- [x] Criar `app/prompts/context_builder.py` (versÃ£o mÃ­nima):
  - User memories formatadas do `user_memories` table
  - Apenas campos essenciais: bio, goals, topOfMind
  - Context builder completo serÃ¡ expandido em M4.6

**SSE Streaming (via `sse-starlette`):**
- [x] Criar `app/api/routes/chat.py`:
  - POST `/chat/invoke` â€” recebe `{ user_id, conversation_id, message }`, retorna SSE stream
  - Usar `EventSourceResponse` de `sse-starlette` (FastAPI nÃ£o tem SSE built-in)
  - SSE events compatÃ­veis com formato atual do frontend:
    - `{ data: { content: "...", done: false } }` â€” text delta
    - `{ data: { content: "...", done: true } }` â€” resposta final
    - `{ data: { content: "", done: true, error: "..." } }` â€” erro (matching NestJS format)
- [x] Carregar histÃ³rico de mensagens do DB quando nÃ£o existe checkpoint (conversas originadas no TypeScript)

**NestJS Proxy:**
- [x] Consumir `pythonAiSchema` no API module via `AppConfigService` (getters: `pythonAiUrl`, `serviceSecret`, `usePythonAi`)
- [x] Criar mÃ©todo `proxyToPython()` no `chat.service.ts`:
  - POST para Python `/chat/invoke` com Bearer `SERVICE_SECRET`
  - Parseia SSE stream do Python via `ReadableStream` reader e emite para o frontend
- [x] Quando `USE_PYTHON_AI=true`: proxy para Python. Quando `false`: usa lÃ³gica TypeScript atual

**Testes:**
- [x] Teste E2E: enviar mensagem simples â†’ receber resposta via Python (SSE streaming)
- [x] Teste: save response node persiste mensagem no DB
- [x] Teste: context builder inclui user memories no system prompt
- [x] Teste: feature flag alterna corretamente entre TypeScript e Python
- [x] Teste: frontend recebe SSE events no formato esperado (sem mudanÃ§as no frontend)

**Definition of Done:**
- [x] Com `USE_PYTHON_AI=true`, chat funciona end-to-end pelo Python (sem tools)
- [x] Com `USE_PYTHON_AI=false`, sistema TypeScript continua funcionando normalmente
- [x] Frontend nÃ£o percebe diferenÃ§a (mesmos SSE events)
- [x] Mensagens sÃ£o salvas no DB pelo Python

> **DecisÃ£o tomada:** Feature flag via environment variable (`USE_PYTHON_AI`), jÃ¡ definida em `packages/config/src/schemas/python-ai.ts`.

**Notas (2026-02-23):**
ImplementaÃ§Ã£o completa do pipe Python end-to-end. **Python (16 arquivos criados, 2 modificados):** `app/agents/` (state.py, llm.py, graph.py, save_response.py, domains/general.py) â€” StateGraph com `general_agent â†’ save_response`, `AsyncPostgresSaver` checkpointer, LLM factory suportando Gemini + Anthropic via `LLM_PROVIDER` env. `app/prompts/` (system.py, context_builder.py) â€” system prompt completo com personalidade Â§4, guardrails Â§7 (CVV 188, Ligue 180), counselor mode Â§5.1, user memories (bio, occupation, family, goals, challenges, topOfMind, values, communication_style). `app/api/routes/chat.py` â€” POST `/chat/invoke` com `EventSourceResponse`, checkpoint-or-DB-fallback para conversas originadas no TypeScript (carrega histÃ³rico do DB se checkpoint nÃ£o existe), `convert_db_messages()` com IDs preservados para dedup do `add_messages` reducer, `await request.is_disconnected()` para disconnect detection. Error SSE retorna mensagem genÃ©rica "Erro ao gerar resposta" (nÃ£o vaza `str(e)` ao cliente). Modificados: `app/main.py` (build graph no lifespan + registra chat router), `app/dependencies.py` (get_checkpointer helper). Reusa cÃ³digo existente de M4.2: `get_user_session()` (RLS), `ChatRepository`, `UserRepository`, `get_settings()`. **NestJS (3 arquivos modificados):** `config.service.ts` (3 getters: pythonAiUrl, serviceSecret, usePythonAi), `chat.service.ts` (`AppConfigService` injetado como 1Âº param do constructor + feature flag check no topo de `processStreamResponse()` + `proxyToPython()` com native `fetch` + `ReadableStream` reader para SSE parsing + `reader.releaseLock()` no finally), `chat.service.spec.ts` (mock do `AppConfigService` com `usePythonAi: false`). **Testes:** 26 Python (pytest) â€” test_llm_factory (4), test_agents (4), test_context_builder (6), test_chat_endpoint (5), test_graph (2), conftest + existing (5). 853 NestJS (jest). Todos passando. `ruff check .` + `mypy app/` + `pnpm typecheck` + `pnpm lint` limpos.

---

## M4.4 â€” Tracking Tools + Habits + Confirmation Framework ðŸŸ¢

**Objetivo:** Primeiros tools funcionando no Python com confirmaÃ§Ã£o via `interrupt()`. Tracking Ã© o domÃ­nio mais simples â€” ideal para validar o framework.

**ReferÃªncias:** `docs/ai-python-service-migration-plan.md` Â§4.5, `docs/specs/domains/tracking.md`, `ADR-015`

**DependÃªncias:** M4.3

> **Contexto:** O framework de confirmaÃ§Ã£o com `interrupt()` / `Command(resume=)` do LangGraph (import de `langgraph.types`) substitui o sistema atual de Redis TTL (5 min) do `confirmation-state.service.ts`. A persistÃªncia passa a ser via PostgreSQL (`AsyncPostgresSaver`), sem TTL por default. Isso Ã© uma **melhoria**: confirmaÃ§Ãµes nÃ£o expiram, sobrevivem a crashes do processo, e o thread pode ser retomado a qualquer momento. Este milestone valida o padrÃ£o que serÃ¡ usado por todos os write tools.
>
> **MudanÃ§a de infra:** Confirmation state migra de Redis (ioredis SETEX 5min) â†’ PostgreSQL (LangGraph checkpoint tables). Python **nÃ£o precisa de Redis** para confirmaÃ§Ãµes.

**Tasks:**

**Confirmation Framework:**
- [x] Criar `app/tools/common/confirmation.py`:
  - Wrapper de `interrupt()` que padroniza o formato de confirmaÃ§Ã£o
  - `generate_confirmation_message()` â€” mensagens em PT (ex: "Registrar peso: 75 kg em 2026-02-23?")
  - `generate_batch_confirmation_message()` â€” batch (ex: "Remover 3 registros?")
  - Constraint de idempotÃªncia documentada: cÃ³digo antes de `interrupt()` re-executa no resume â€” sem side effects antes do interrupt
  - `expiresAt` = now + 24h (soft limit â€” checkpoints PostgreSQL nÃ£o expiram, frontend usa para UX)
- [x] Criar `app/tools/common/confirmable_tool_node.py` â€” `ConfirmableToolNode`:
  - Substitui `ToolNode` do `create_react_agent` para agents com WRITE tools
  - Separa READ tools (executa imediatamente) de WRITE tools (batch em Ãºnico `interrupt()`)
  - 3 aÃ§Ãµes no resume: `confirm` (executa), `reject` (cancela), `edit` (corrige args e executa)
  - Emite SSE events `tool_calls` (antes) e `tool_result` (apÃ³s cada tool)
- [x] Adicionar endpoint POST `/chat/resume` em `app/api/routes/chat.py`:
  - Recebe `{ thread_id, action: "confirm" | "reject" | "edit", edited_args?: dict }`
  - Executa `Command(resume={"action": ..., "args": ...})`
  - Retorna SSE stream com resultado (reutiliza lÃ³gica de streaming)
- [x] Atualizar streaming em `app/api/routes/chat.py`:
  - `stream_mode="messages"` â†’ `stream_mode=["messages", "updates"]` para detectar `__interrupt__`
  - Chunks "updates" com `__interrupt__` â†’ SSE `confirmation_required` + `{ done: true, awaitingConfirmation: true }`
  - Chunks "updates" com tool data â†’ SSE `tool_calls` e `tool_result`
- [x] Implementar detecÃ§Ã£o de confirmaÃ§Ã£o por mensagem em `/chat/invoke`:
  - Verificar interrupt pendente via `graph.get_state(config)` antes de processar
  - Classificar intent via LLM: confirm / reject / correction / unrelated
  - Confirm â†’ `Command(resume={"action": "confirm"})`; Reject â†’ `Command(resume={"action": "reject"})`
  - Correction â†’ `Command(resume={"action": "edit", "args": corrected_args})`
  - Unrelated â†’ rejeitar pendente + processar como nova mensagem
- [x] **NestJS:** Proxy de confirmaÃ§Ã£o para Python:
  - `confirm/:confirmationId` â†’ Python `/chat/resume` action "confirm"
  - `reject/:confirmationId` â†’ Python `/chat/resume` action "reject"
  - Proxy SSE response de volta ao frontend
- [x] SSE event `confirmation_required` compatÃ­vel com frontend atual:
  ```json
  {
    "type": "confirmation_required",
    "data": {
      "confirmationId": "uuid",
      "toolName": "record_metric",
      "toolArgs": { "type": "water", "value": 2000 },
      "message": "Registrar Ã¡gua: 2000ml em 2026-02-22",
      "expiresAt": "ISO string"
    }
  }
  ```
- [x] SSE event `tool_result` apÃ³s execuÃ§Ã£o:
  ```json
  { "type": "tool_result", "data": { "toolName": "record_metric", "result": "...", "success": true } }
  ```

**Tracking Tools (4 tools):**
- [x] Criar `app/tools/tracking/record_metric.py` â€” registra mÃ©trica (WRITE, confirmation)
  - Params: metric_type, value, date (opcional, default hoje), unit (opcional, auto-fill), notes (opcional)
  - ValidaÃ§Ã£o de ranges por tipo (weight 0.1â€“500, water 1â€“20000, mood 1â€“10, sleep 0.1â€“24, etc.)
  - Mapeamento automÃ¡tico metric_type â†’ area/sub_area (ex: weightâ†’health/physical, moodâ†’health/mental)
  - Usa TrackingRepository para INSERT, retorna JSON com entryId
- [x] Criar `app/tools/tracking/get_history.py` â€” histÃ³rico de mÃ©tricas (READ)
  - Params: metric_type, days (opcional, default 30)
  - Retorna entries com UUIDs (para update/delete), stats (count, avg, min, max, sum, trend), variaÃ§Ã£o %
  - Inclui `_note` instruindo o LLM a usar IDs exatos para update/delete
- [x] Criar `app/tools/tracking/update_metric.py` â€” atualiza mÃ©trica existente (WRITE, confirmation)
  - Params: entry_id (UUID exato), value, unit (opcional), reason (opcional â€” audit trail)
  - Ownership verificada via RLS (SET LOCAL request.jwt.claim.sub)
- [x] Criar `app/tools/tracking/delete_metric.py` â€” deleta mÃ©trica (WRITE, confirmation)
  - Params: entry_id (UUID exato), reason (opcional)
  - Delete individual (batch removido â€” LLM alucinava IDs em batch, mesma decisÃ£o do TypeScript M2.1)

**Habit Tools (2 tools):**
- [x] Criar `app/tools/tracking/record_habit.py` â€” registra hÃ¡bito (WRITE, confirmation)
  - Params: habit_name, date (opcional, default hoje), notes (opcional)
  - Fuzzy match por nome: exact case-insensitive â†’ contains bidirecional
  - DetecÃ§Ã£o de duplicata (jÃ¡ completado na data), cÃ¡lculo de streak apÃ³s registro
- [x] Criar `app/tools/tracking/get_habits.py` â€” lista hÃ¡bitos (READ)
  - Params: include_streaks (bool, default true), include_today_status (bool, default true)
  - Retorna hÃ¡bitos com streak atual, longest streak, status de hoje

> **Nota:** `analyze_context` estÃ¡ mapeado para o executor `'memory'` no cÃ³digo (chat.service.ts:121), nÃ£o tracking. Esse tool Ã© implementado em M4.6 (Memory Tools).

**Tracking Agent:**
- [x] Criar `app/agents/domains/tracking.py`:
  - Exporta `TRACKING_TOOLS` (6 tools) e `TRACKING_WRITE_TOOLS` (4 nomes) para uso pelo graph builder
  - Graph construÃ­do via `build_domain_agent_graph()` factory reutilizÃ¡vel (agent_factory.py)
  - System prompt vem do context_builder.py (centralizado, nÃ£o embarcado no agente)
- [x] Atualizar graph principal: `build_domain_agent_graph(llm, TRACKING_TOOLS, TRACKING_WRITE_TOOLS, checkpointer)`
  - Grafo: agent â†’ should_continue â†’ tools (ConfirmableToolNode) â†’ agent (loop) ou save_response â†’ END
  - Loop guard em agent_node previne Gemini de re-chamar WRITE tool apÃ³s sucesso (forÃ§a resposta textual)

**Confirmation Flow Hardening (bugs encontrados durante E2E testing):**
- [x] Salvar mensagem de confirmaÃ§Ã£o no DB ao detectar `__interrupt__` no stream (espelha NestJS L1189-1201)
  - Mensagem persiste apÃ³s page refresh. Metadata inclui `pendingConfirmation` (confirmationId, toolName, toolArgs)
- [x] Reject usa `graph.ainvoke()` em vez de `graph.astream()` â€” resposta curta enviada como evento SSE Ãºnico
  - Corrige bug onde resposta de rejeiÃ§Ã£o nÃ£o aparecia no frontend (perdia-se no pipeline streaming multi-camada)
- [x] Loop guard para re-chamada de WRITE tools â€” Gemini chamava `record_metric` em loop apÃ³s sucesso
  - Detecta ToolMessage de WRITE tool seguida de nova chamada ao mesmo tool; forÃ§a AIMessage textual
- [x] Guard de content blocks vazios do Gemini â€” `[{"type":"text","text":""}]` Ã© truthy mas sem conteÃºdo
  - `tokens_streamed` sÃ³ Ã© setado como `True` quando token extraÃ­do Ã© non-empty
- [x] `skip_save_response` para intent "unrelated" â€” rejeiÃ§Ã£o silenciosa nÃ£o salva "OperaÃ§Ã£o cancelada" como mensagem separada
  - Nova mensagem do fluxo normal inclui menÃ§Ã£o ao cancelamento em resposta Ãºnica combinada
- [x] JSON format para ToolMessage de rejeiÃ§Ã£o â€” `json.dumps({"success": False, "message": "..."})` em vez de plain text
  - Gemini interpretava plain text como resultado de tool a ser re-processado
- [x] Frontend: safety net `useEffect` em `use-chat.ts` â€” quando `done:true` chega sem streaming content, chama `finishStreaming()` diretamente
  - Cobre edge case onde backend termina sem ter feito stream de tokens (ex: resposta via ainvoke)

**Testes:**
- [x] Teste: pipeline SSE de interrupt â€” salva confirmaÃ§Ã£o no DB (`test_invoke_interrupt_saves_confirmation_to_db`), reject via ainvoke envia content (`test_invoke_reject_uses_ainvoke_and_sends_content`). Nota: testa pipeline de streaming, nÃ£o o tool record_metric com ConfirmableToolNode end-to-end (coberto por E2E manual)
- [x] Teste: get_tracking_history retorna dados corretos (`test_get_history_returns_formatted_entries`)
- [x] Teste: update_metric retorna erro quando entry nÃ£o existe (`test_update_metric_not_found`). Nota: ownership real Ã© garantida por RLS (`SET LOCAL`) mas nÃ£o hÃ¡ teste de integraÃ§Ã£o com 2 users â€” requer DB real
- [x] Teste: record_habit com fuzzy match de nome (`test_record_habit_fuzzy_matching`, `test_record_habit_already_completed`)
- [x] Teste: SSE events de confirmaÃ§Ã£o compatÃ­veis com frontend (`test_invoke_interrupt_saves_confirmation_to_db`, `test_resume_confirm_returns_sse`)
- [x] Teste: flow completo "Registra 2L de Ã¡gua hoje" end-to-end (verificaÃ§Ã£o manual â€” 4 cenÃ¡rios: confirm, reject, unrelated, e rejectâ†’re-registerâ†’confirm)
- [x] Teste: loop guard previne re-chamada de WRITE tool (`test_loop_guard_breaks_write_tool_re_call`)
- [x] Teste: empty Gemini blocks nÃ£o escondem loop guard (`test_invoke_empty_gemini_blocks_do_not_shadow_loop_guard`)
- [x] Teste: DB failure no interrupt nÃ£o quebra stream (`test_invoke_interrupt_db_failure_still_streams`)

**Definition of Done:**
- [x] "Registra 2L de Ã¡gua hoje" funciona end-to-end pelo Python (card de confirmaÃ§Ã£o no frontend)
- [x] ConfirmaÃ§Ã£o, rejeiÃ§Ã£o, mensagem nÃ£o-relacionada e re-registro funcionam corretamente
- [x] Dados escritos pelo Python aparecem no dashboard (persistem apÃ³s page refresh)
- [x] Todos os 6 tools passam em testes isolados (82 passed, 14 skipped)

### Notas

_ConcluÃ­do em 2026-02-23._

**Desvios do plano original:**
- `delete_metric` batch removido do tool (repositÃ³rio mantÃ©m `delete_batch()` para uso futuro). DecisÃ£o alinhada com TypeScript M2.1 â€” LLM alucinava IDs quando recebia operaÃ§Ã£o batch. Chamadas paralelas de `delete_metric` individual com UUIDs reais do `get_history` Ã© mais confiÃ¡vel
- `update_metric` nÃ£o suporta alteraÃ§Ã£o de `entry_date` (plano previa). Params reais: `entry_id`, `value`, `unit?`, `reason?`. `reason` adiciona audit trail de correÃ§Ãµes
- `record_habit` sem param `completed` (plano previa). Sempre registra como concluÃ­do â€” "registrar hÃ¡bito" no chat implica completude. Param `notes` adicionado
- Tracking agent implementado como bridge (`tracking.py` exporta tools/write_tools) + factory reutilizÃ¡vel (`agent_factory.py`) em vez de graph customizado por domÃ­nio. Factory serÃ¡ reusada por M4.5 (Finance) e M4.6 (Memory) sem duplicaÃ§Ã£o

**Melhorias sobre o plano original:**
- `record_metric` inclui validaÃ§Ã£o de ranges por tipo (weight 0.1â€“500 kg, water 1â€“20000 ml, mood 1â€“10, etc.) â€” nÃ£o previsto no plano
- `get_history` retorna estatÃ­sticas completas (count, avg, min, max, sum, trend, variaÃ§Ã£o %) + `_note` instruindo LLM a usar IDs exatos â€” nÃ£o previsto no plano
- `get_habits` retorna streaks (atual e recorde) e status de hoje com params configurÃ¡veis â€” excede spec original
- `build_domain_agent_graph()` factory em `agent_factory.py` â€” pattern reutilizÃ¡vel com agent â†’ ConfirmableToolNode â†’ agent loop + save_response, compilado com checkpointer. Elimina duplicaÃ§Ã£o para M4.5/M4.6
- Loop guard no agent_node â€” detecta quando Gemini re-chama WRITE tool apÃ³s ToolMessage de sucesso e forÃ§a resposta textual. Essencial para estabilidade com Gemini
- 7 bugs de confirmation flow descobertos e corrigidos durante E2E testing (vide seÃ§Ã£o "Confirmation Flow Hardening")
- Frontend `use-chat.ts` safety net â€” `useEffect` que detecta `done:true` sem conteÃºdo streamed e chama `finishStreaming()` direto

**VerificaÃ§Ã£o local:**
- Python: ruff check (0 errors), mypy (0 issues, 51 files), pytest (82 passed, 14 skipped)
- TypeScript: typecheck compilado sem erros
- E2E manual: 4 cenÃ¡rios testados (confirm, reject, unrelated intent, rejectâ†’re-registerâ†’confirm) â€” todos funcionando

---

## M4.5 â€” Finance Tools ðŸŸ¢

**Objetivo:** Todos os 11 tools financeiros migrados para Python. Maior executor em linhas de cÃ³digo (~1.047L no TypeScript).

**ReferÃªncias:** `docs/specs/domains/finance.md`, `apps/api/src/modules/finance/application/services/finance-tool-executor.service.ts`

**DependÃªncias:** M4.4

> **Contexto:** O `finance-tool-executor.service.ts` Ã© o maior executor (1.047 linhas) com lÃ³gica complexa de agregaÃ§Ã£o, cÃ¡lculos mensais, projeÃ§Ãµes e breakdown por categoria. Requer atenÃ§Ã£o especial ao handling de DECIMAL (string no Drizzle, float no Python).

**Tasks:**

**Finance Tools â€” Shared Helpers:**
- [x] Criar `app/tools/finance/_helpers.py` â€” TZ utils + ensure_recurring
  - FunÃ§Ãµes: get_current_month_tz, get_today_tz, get_days_until_due_day, resolve_month_year, get_previous_month, months_diff
  - `ensure_recurring_for_month()` â€” geraÃ§Ã£o lazy de itens recorrentes (bills, incomes, expenses)
- [x] Adicionar mÃ©todos ao `app/db/repositories/finance.py`:
  - get_debt_by_id, get_debt_payments_for_debts (batch), sum_payments_by_month_year

**Finance Tools â€” READ (9 tools):**
- [x] Criar `app/tools/finance/get_finance_summary.py` â€” resumo financeiro mensal
  - Params: period (Literal["current_month", "last_month", "year"], default: "current_month")
  - Retorna: KPIs (income, budgeted, spent, balance), breakdown por entidade, ensure_recurring para 3 tabelas
- [x] Criar `app/tools/finance/get_pending_bills.py` â€” contas pendentes
  - Params: month, year (opcionais, default: mÃªs atual via TZ)
  - Retorna: bills com status pending, daysUntilDue, reclassifica overdue, ensure_recurring
- [x] Criar `app/tools/finance/get_bills.py` â€” todas as contas com status
  - Params: month, year, status (opcionais, status default: "all")
  - Retorna: lista de bills com paid/pending/overdue, daysUntilDue, ensure_recurring
- [x] Criar `app/tools/finance/get_expenses.py` â€” despesas variÃ¡veis
  - Params: month, year (opcionais)
  - Retorna: lista de expenses com variance, percentUsed, ensure_recurring
- [x] Criar `app/tools/finance/get_incomes.py` â€” receitas
  - Params: month, year (opcionais)
  - Retorna: lista de incomes com variance, receivedCount/pendingCount, ensure_recurring
- [x] Criar `app/tools/finance/get_investments.py` â€” investimentos
  - Params: nenhum
  - Retorna: lista com progress, remainingToGoal, monthsToGoal
- [x] Criar `app/tools/finance/get_debt_progress.py` â€” progresso de dÃ­vidas
  - Params: debt_id (opcional), month_year (opcional, YYYY-MM)
  - Retorna: total pago, percentual, parcelas restantes, projeÃ§Ã£o de quitaÃ§Ã£o, regras de visibilidade Â§3.6
- [x] Criar `app/tools/finance/get_debt_payment_history.py` â€” histÃ³rico de pagamentos de dÃ­vida
  - Params: debt_id (obrigatÃ³rio), limit (opcional, default 50)
  - Retorna: lista de pagamentos com paidEarly flag, contexto da dÃ­vida
- [x] Criar `app/tools/finance/get_upcoming_installments.py` â€” prÃ³ximas parcelas
  - Params: month_year (opcional, YYYY-MM, default: mÃªs atual)
  - Retorna: installments com status (paid/paid_early/overdue/pending), regras de visibilidade Â§3.6

**Finance Tools â€” WRITE (2 tools):**
- [x] Criar `app/tools/finance/mark_bill_paid.py` â€” marcar conta como paga (WRITE, confirmation)
  - Params: bill_id, paid_date (opcional, default: hoje)
  - Verifica que bill pertence ao user e estÃ¡ pendente
- [x] Criar `app/tools/finance/create_expense.py` â€” criar despesa variÃ¡vel (WRITE, confirmation)
  - Params: description, amount, category, date (opcional)
  - Mapeamento de categorias PTâ†’EN preservado (alimentacaoâ†’food, transporteâ†’transport, etc.)

**Finance Agent Bridge + Graph:**
- [x] Criar `app/agents/domains/finance.py` â€” bridge (re-export FINANCE_TOOLS, FINANCE_WRITE_TOOLS)
- [x] Atualizar `app/agents/graph.py` â€” merge finance + tracking tools no grafo Ãºnico

**LÃ³gica de agregaÃ§Ã£o:**
- [x] Implementar cÃ¡lculos mensais: income - expenses - bills = balance
- [x] Implementar breakdown por categoria com percentuais
- [x] Implementar projeÃ§Ãµes baseadas em histÃ³rico
- [x] Garantir que todos os cÃ¡lculos usam `float` (nÃ£o `Decimal` nem `string`)

**Testes:**
- [x] Teste: cada READ tool isoladamente com mocks (41 testes)
- [x] Teste: get_finance_summary com KPI aggregation e breakdown correto
- [x] Teste: helpers TZ (20 testes) + ensure_recurring (4 testes)
- [x] Teste: mark_bill_paid com confirmaÃ§Ã£o (5 testes: success, not_found, already_paid, overdue_success, invalid_uuid)
- [x] Teste: create_expense com mapeamento de categoria PTâ†’EN (5 testes: success, category_mapping 7x, defaults, invalid_category, budgeted_fallback)
- [x] Teste cross-ORM: coberto por M4.2 integration tests (DECIMALâ†’float) + E2E manual verification
- [x] Teste: queries complexas â€” verificadas via E2E manual (Playwright)

**Definition of Done:**
- [x] Todos os 11 finance tools funcionam no Python
- [x] Valores financeiros sÃ£o precisos (cross-ORM verification)
- [x] ConfirmaÃ§Ã£o funciona para mark_bill_paid e create_expense
- [x] Categorias PTâ†’EN mapeadas corretamente

**Notas (2026-02-23) â€” READ tools session:**
- 9 READ tools implementados: get_finance_summary, get_pending_bills, get_bills, get_expenses, get_incomes, get_investments, get_debt_progress, get_debt_payment_history, get_upcoming_installments
- `_helpers.py`: TZ utils (6 funÃ§Ãµes) + `ensure_recurring_for_month()` genÃ©rico para 3 entidades (Bill, Income, VariableExpense) via `_ENTITY_CONFIG` dict
- `__init__.py`: exports FINANCE_TOOLS (list de 9) e FINANCE_WRITE_TOOLS (set vazio, preparado para WRITE tools)
- Repository: +3 mÃ©todos (get_debt_by_id, get_debt_payments_for_debts batch com guard lista vazia, sum_payments_by_month_year com func.coalesce)
- Graph atualizado: ALL_TOOLS = TRACKING_TOOLS + FINANCE_TOOLS (15 tools total)
- `pyproject.toml`: adicionado `"app/tools/finance/*.py" = ["TCH002"]` per-file-ignores (RunnableConfig necessÃ¡rio em runtime, mesmo padrÃ£o de tracking)
- 41 testes unitÃ¡rios (mocked), 112 total suite passando (ruff + mypy + pytest limpos)
- CorreÃ§Ãµes do milestone: params alinhados com NestJS (period em vez de month/year para summary, month_year YYYY-MM para debts, limit para payment_history)
- E2E manual via Playwright: 9/9 tools testados com dados reais do seed, todos os valores conferem com o banco de dados
- VerificaÃ§Ã£o de tool calls via LangGraph checkpoints: confirmado que a IA chama tools corretamente (paralelo quando possÃ­vel, sequencial para resolver IDs como debt_id)
- WRITE tools (mark_bill_paid, create_expense) serÃ£o implementados na prÃ³xima sessÃ£o

**Notas (2026-02-23) â€” WRITE tools session:**
- 2 WRITE tools implementados: mark_bill_paid, create_expense
- `mark_bill_paid`: validates UUID, checks bill exists (via new `get_bill_by_id` repo method), verifies status is pending/overdue, defaults paid_date to today in user TZ
- `create_expense`: 7 PTâ†’EN category mappings (alimentacaoâ†’food, etc.), defaults expected_amount to actual_amount or 0, generates UUID client-side
- Confirmation templates fixed: old templates used mismatched PT arg names ({nome}, {data}, {valor}, {categoria}) that never matched Python tool params â€” always fell back to generic. New templates use actual Python param names or static messages
- `_OPTIONAL_DEFAULTS` extended for mark_bill_paid and create_expense
- `FINANCE_WRITE_TOOLS = {"mark_bill_paid", "create_expense"}` â€” graph.py already merges with TRACKING_WRITE_TOOLS via set union
- 12 new unit tests (5 mark_bill_paid + 5 create_expense + 2 graph integration), confirmation tests updated
- All checks pass: ruff (0), mypy (0 issues, 65 files), pytest (134 passed, 14 skipped)
- M4.5 complete: 11 finance tools (9 READ + 2 WRITE) fully migrated from TypeScript

---

## M4.6 â€” Memory Tools + Context Builder Completo ðŸŸ¢

**Objetivo:** Tools de memÃ³ria migrados e context builder completo (system prompt com todas as instruÃ§Ãµes de tools).

**ReferÃªncias:** `docs/specs/domains/memory.md`, `docs/specs/core/ai-personality.md` Â§4-8, `ADR-012`

**DependÃªncias:** M4.4

> **Nota:** Este milestone pode rodar **em paralelo** com M4.5 (Finance Tools).

**Tasks:**

**MemoryRepository Enhancements:**
- [x] Enhance `MemoryRepository.search_knowledge()` with keyword search (ILIKE on title+content) and sub_area filter

**Memory Tools (3 tools):**
- [x] Criar `app/tools/memory/search_knowledge.py` â€” busca em knowledge_items (READ)
  - Params: query (keyword ILIKE), type (opcional), area (opcional), sub_area (opcional), limit
  - Busca por keyword/filtros em knowledge_items
- [x] Criar `app/tools/memory/add_knowledge.py` â€” adicionar fato/preferÃªncia/insight (WRITE, confirmation)
  - Params: content, type (fact/preference/memory/insight/person), area, sub_area, confidence
  - LLM-based contradiction detection (matching TS ContradictionDetectorAdapter)
  - Supersede contradicted items
- [x] Criar `app/tools/memory/_contradiction_detector.py` â€” LLM-based semantic contradiction detection
  - Uses `create_llm(settings, temperature=0)` for deterministic comparison
  - PT-BR prompt with contradiction examples
  - Safe default: returns empty on LLM error
- [x] Criar `app/tools/memory/analyze_context.py` â€” anÃ¡lise de contexto memÃ³ria (READ)
  - Params: current_topic (str), related_areas (list[str]), look_for_contradictions (bool)
  - Retorna knowledge_items relevantes, padrÃµes aprendidos, conexÃµes potenciais

**Memory Agent Registration:**
- [x] Criar `app/agents/domains/memory.py` â€” re-export MEMORY_TOOLS/MEMORY_WRITE_TOOLS
- [x] Registrar memory tools em `graph.py` (ALL_TOOLS + ALL_WRITE_TOOLS)

**Confirmation Template Fix:**
- [x] Fix `confirmation.py` template: `{conteudo}` â†’ `{content}` (match add_knowledge param)

**Context Builder Completo:**
- [x] Expandir `app/prompts/system.py` â€” full TS parity (~120 linhas tool instructions):
  - Memory tools: search_knowledge, add_knowledge, analyze_context com exemplos
  - Tracking tools: record_metric (ADR-015 flow), update_metric (UUID rules), delete_metric (batch)
  - Habits tools: record_habit (name matching, confirmation), get_habits
  - Finance tools: categories, READ/WRITE tools, mandatory flow, critical rules
  - Inferential reasoning: FLUXO OBRIGATÃ“RIO, contradiction detection, connection examples
  - Expanded rules (11 rules matching TS)
  - Counselor extension: add "Tom" subsection
- [x] Expandir `app/prompts/context_builder.py`:
  - Add learnedPatterns (confidence >= 0.7, max 5)
  - Add feedback_preferences
  - Use markdown headers (## Sobre o UsuÃ¡rio, ## Valores, etc.)
  - Skip empty sections, match TS formatForPrompt()

**Testes:**
- [x] Teste: search_knowledge sem filtros, com type, com area, com keyword ILIKE
- [x] Teste: add_knowledge basic, title generation, contradiction detection, no contradiction
- [x] Teste: contradiction detector LLM error retorna safe default
- [x] Teste: analyze_context multi-area, patterns, hint flag
- [x] Teste: context builder tool instructions presentes (memory, tracking, finance, habits)
- [x] Teste: context builder learned patterns, counselor Tom section, all 11 rules
- [x] Teste: context builder memory formatting com markdown headers

**Definition of Done:**
- [x] Memory tools funcionam no Python (3 tools registrados em graph.py)
- [x] Contradiction detection via LLM funciona com safe fallback
- [x] Context builder produz system prompt completo e equivalente ao TypeScript
- [x] "O que vocÃª sabe sobre mim?" retorna informaÃ§Ãµes corretas das user_memories

**Notas (2026-02-24):**
- 3 memory tools: search_knowledge (READ), add_knowledge (WRITE+confirmation), analyze_context (READ)
- LLM-based contradiction detector using `create_llm(settings, temperature=0)` â€” same pattern as intent classifier
- Context builder expanded from ~60 to ~280 lines, full TS parity with all tool instructions
- Memory formatting uses markdown ## headers matching TS formatForPrompt()
- Counselor extension now includes "Tom" subsection (pausado, reflexivo, minimize emojis)
- 30 new tests (18 memory tools + 12 context builder expansion), all passing
- `confirmation.py` template fixed: `{conteudo}` â†’ `{content}` to match tool param name

---

## M4.7 â€” Multi-Agent: Triage + Domain Routing ðŸŸ¢

**Objetivo:** Arquitetura multi-agente com triage inteligente roteando mensagens para agentes especializados.

**ReferÃªncias:** `docs/ai-python-service-migration-plan.md` Â§4

**DependÃªncias:** M4.4, M4.5, M4.6

> **Contexto:** AtÃ© este ponto, o graph usa um Ãºnico agente com todos os tools. Este milestone implementa a arquitetura final: triage node classifica a intenÃ§Ã£o e roteia para domain agents especializados. Isso permite usar modelo rÃ¡pido (Flash) para triagem e modelo capaz (Pro) para execuÃ§Ã£o, reduzindo custo e latÃªncia.

**Tasks:**

**Triage Node:**
- [x] Criar `app/agents/triage.py`:
  - Usa modelo rÃ¡pido: `ChatGoogleGenerativeAI(model=settings.TRIAGE_LLM_MODEL)` (default: `gemini-flash-latest`)
  - `TriageDecision` Pydantic model com `with_structured_output()` para classificaÃ§Ã£o determinÃ­stica
  - Triage prompt com exemplos de roteamento:
    - "Registra 2L de Ã¡gua" â†’ tracking
    - "Quanto gastei este mÃªs?" â†’ finance
    - "O que vocÃª sabe sobre mim?" â†’ memory
    - "Estou me sentindo ansioso" â†’ wellbeing
    - "Bom dia!" â†’ general
  - Retorna `{ current_agent: "tracking" | "finance" | "memory" | "wellbeing" | "general" }`
  - Factory pattern: `make_triage_node(triage_llm)` captura LLM em closure
  - Fallback para `"general"` em caso de erro do LLM (try/except com log warning)

**Triage LLM Config:**
- [x] Adicionar `TRIAGE_LLM_MODEL: str = "gemini-flash-latest"` em `app/config.py`
- [x] Adicionar `create_triage_llm(settings)` em `app/agents/llm.py` (temperature=0)

**System Prompt Split:**
- [x] Refatorar `app/prompts/system.py`:
  - Separar `BASE_SYSTEM_PROMPT` monolÃ­tico em:
    - `CORE_SYSTEM_PROMPT`: persona, regras gerais, seguranÃ§a, memÃ³ria do usuÃ¡rio, contexto
    - `SHARED_MEMORY_INSTRUCTIONS`: instruÃ§Ãµes de search_knowledge + analyze_context (compartilhado por todos os domÃ­nios)
    - `TRACKING_PROMPT_EXTENSION`: instruÃ§Ãµes de record_metric, get_history, update/delete_metric, record_habit, get_habits
    - `FINANCE_PROMPT_EXTENSION`: instruÃ§Ãµes de todas as ferramentas financeiras
    - `MEMORY_WRITE_EXTENSION`: instruÃ§Ãµes de add_knowledge (WRITE)
    - `WELLBEING_PROMPT_EXTENSION`: modo counselor (atual `COUNSELOR_EXTENSION`)
  - Cada domain extension = SHARED_MEMORY_INSTRUCTIONS + extensÃ£o especÃ­fica do domÃ­nio
- [x] Atualizar `app/prompts/context_builder.py`:
  - Remover append de `COUNSELOR_EXTENSION` (extensÃµes agora sÃ£o aplicadas pelo agent_node)
  - `build_context()` retorna apenas o prompt core com contexto do usuÃ¡rio

**Memory Tools Compartilhados:**
- [x] Exportar `MEMORY_READ_TOOLS = [search_knowledge, analyze_context]` em `app/tools/memory/__init__.py`
- [x] Todos os domain agents recebem memory READ tools (search_knowledge + analyze_context):
  - tracking: 6 + 2 = 8 tools (4 WRITE)
  - finance: 11 + 2 = 13 tools (2 WRITE)
  - memory: 3 tools (1 WRITE)
  - wellbeing: 0 + 2 = 2 tools (0 WRITE)
  - general: 0 + 2 = 2 tools (0 WRITE)

**Wellbeing Agent (novo):**
- [x] Criar `app/agents/domains/wellbeing.py`:
  - Export de listas vazias (WELLBEING_TOOLS, WELLBEING_WRITE_TOOLS) seguindo padrÃ£o de tracking.py, finance.py, memory.py
  - Tools reais vÃªm do registry (memory READ compartilhado)
  - Modo counselor puro: reflexÃ£o profunda, perguntas exploratÃ³rias, menos emojis

**Domain Registry:**
- [x] Criar `app/agents/registry.py`:
  - `DomainConfig` dataclass: tools, write_tools, prompt_extension
  - `build_domain_registry()` retorna mapeamento dos 5 domÃ­nios
  - Imports lazy para evitar dependÃªncias circulares

**Graph Atualizado (Dynamic Dispatch):**
- [x] Adicionar `build_multi_agent_graph()` em `app/tools/common/agent_factory.py`:
  - Topologia: START â†’ triage â†’ agent â†’ should_continue â†’ {tools, save_response}
  - `agent_node` dinÃ¢mico: bind tools + prompt extension baseado em `state["current_agent"]`
  - Pre-bind LLMs por domÃ­nio no build time (um `llm.bind_tools()` por domÃ­nio)
  - `ConfirmableToolNode` registrado com ALL tools (deduplicados) â€” LLM sÃ³ chama tools que tem bound
  - Loop guard mantido sem alteraÃ§Ãµes
- [x] Atualizar `app/agents/graph.py`:
  - Substituir `build_chat_graph()` por novo entry point usando `build_multi_agent_graph`
  - Manter `build_domain_agent_graph` no factory para backward compat
- [x] Atualizar `app/main.py`:
  - Criar triage LLM e domain LLM no startup
  - Chamar novo graph builder

> **Nota sobre arquitetura "Dynamic Dispatch":** Verificado via Context7 (Fev 2026): Em vez de subgraphs ou `create_react_agent`, usa um Ãºnico graph com triage node no inÃ­cio e agent node com dispatch dinÃ¢mico. Vantagem: ZERO mudanÃ§as no streaming (`chat.py`), no resume/interrupt, e no `ConfirmableToolNode`. Node names "agent" e "tools" permanecem iguais, SSE filtering funciona sem alteraÃ§Ã£o. Pattern validado: `llm.with_structured_output(Pydantic)` Ã© o padrÃ£o recomendado pelo LangGraph para routing.

**EstratÃ©gia Multi-DomÃ­nio:**
- [x] Mensagens multi-domÃ­nio ("como estou financeiramente e na saÃºde?"): triage roteia para o domÃ­nio **primÃ¡rio** (mais relevante). OrquestraÃ§Ã£o multi-agente sequencial diferida para pÃ³s-M4.10.

**Testes:**
- [x] test_triage.py: 20+ mensagens classificadas corretamente pelo triage (cobrindo todos os 5 agents)
- [x] test_triage.py: mensagens ambÃ­guas caem no general
- [x] test_triage.py: fallback para general em caso de erro do LLM
- [x] test_triage.py: mensagens multi-domÃ­nio roteiam para domÃ­nio primÃ¡rio
- [x] test_multi_agent_graph.py: roteamento correto para cada domÃ­nio
- [x] test_multi_agent_graph.py: isolamento de tools (tracking nÃ£o chama finance tools)
- [x] test_multi_agent_graph.py: wellbeing agent usa prompt de counselor
- [x] test_multi_agent_graph.py: fallback no graph quando triage falha
- [x] test_multi_agent_graph.py: resume de interrupt nÃ£o re-executa triage
- [x] test_registry.py: registry contÃ©m todos os 5 domÃ­nios com counts corretos
- [x] test_registry.py: todos os domÃ­nios tÃªm memory READ tools
- [x] test_llm_factory.py: create_triage_llm funciona corretamente
- [x] Atualizar test_graph.py para novo builder
- [x] Atualizar test_context_builder.py para prompt split

**Definition of Done:**
- [x] Mensagens sÃ£o roteadas para o agente correto
- [x] Cada agente executa seus tools especializados + memory READ tools compartilhados
- [x] Triage usa modelo rÃ¡pido (Flash), agents usam modelo capaz
- [x] Fallback funciona para intenÃ§Ãµes ambÃ­guas e erros do triage
- [x] System prompt dividido em core + extensÃµes por domÃ­nio
- [x] ZERO mudanÃ§as em chat.py, confirmable_tool_node.py, save_response.py
- [x] Todos os testes passando (ruff + mypy + pytest)

**Notas (2026-02-24):**
- Arquitetura "Dynamic Dispatch" com ~200 LOC novos (vs ~500-700 LOC para subgraphs/swarm)
- Triage usa `gemini-flash-latest` com `with_structured_output(TriageDecision)` â€” temperatura 0, determinÃ­stico
- Default original `gemini-2.0-flash` dava 404 (deprecated pela Google); corrigido para `gemini-flash-latest`
- Prompt monolÃ­tico (252 linhas) dividido em CORE + 6 extensÃµes composÃ¡veis
- ZERO alteraÃ§Ãµes em chat.py, confirmable_tool_node.py, save_response.py, state.py, e todos os 20 tool files
- `build_domain_agent_graph` mantido no factory para backward compat
- 214 testes passed, 14 skipped (DB), ruff + mypy clean
- **ValidaÃ§Ã£o manual E2E** (Playwright): 6 cenÃ¡rios testados â€” general (cumprimento), finance READ (gastos do mÃªs com dados reais do banco), tracking READ (Ã¡gua da semana), tracking WRITE (registrar Ã¡gua + confirmaÃ§Ã£o + verificaÃ§Ã£o no DB), memory (perfil completo do usuÃ¡rio), wellbeing (resposta empÃ¡tica de conselheira). Todos os domÃ­nios rotearam corretamente com confidence >= 0.98. Tools chamadas corretas e isoladas por domÃ­nio. Memory READ compartilhada usada em 4 dos 6 testes.

---

## M4.8 â€” Workers: Memory Consolidation + Contradiction Detection ðŸŸ¢

**Objetivo:** Migrar memory consolidation e contradiction detection para Python com scheduling nativo via APScheduler (arquitetura hÃ­brida: jobs AI em Python, jobs CRUD em NestJS BullMQ).

**ReferÃªncias:** `docs/ai-python-service-migration-plan.md` Â§11 Fase 3, `docs/specs/domains/memory.md`

**DependÃªncias:** M4.6

> **Contexto:** `memory-consolidation.processor.ts` (557L), `consolidation-prompt.ts` (337L) e `contradiction-detector.adapter.ts` (435L) usam LLM para extrair fatos de conversas e detectar contradiÃ§Ãµes. Esses sÃ£o jobs de AI que pertencem ao runtime Python, onde toda a lÃ³gica LLM jÃ¡ reside.
>
> **DecisÃ£o arquitetural (atualizada em 2026-02-24):** Adotar **arquitetura hÃ­brida** em vez de HTTP bridge:
> - **Jobs AI** (memory consolidation, follow-ups futuros): scheduling + execuÃ§Ã£o em **Python via APScheduler**
> - **Jobs CRUD** (cleanup-onboarding, hard-deletes, calendar sync futuros): permanecem em **NestJS BullMQ**
>
> Essa decisÃ£o se baseia em pesquisa tÃ©cnica detalhada:
> - **BullMQ Python** (v2.19.5) Ã© classificado Alpha no PyPI, **nÃ£o suporta cron/repeat jobs** ([Issue #2772](https://github.com/taskforcesh/bullmq/issues/2772)), e tem bugs crÃ­ticos (Redis disconnect infinite loop [#3103](https://github.com/taskforcesh/bullmq/issues/3103), graceful shutdown quebrado). Descartado.
> - **HTTP bridge** (NestJS BullMQ â†’ POST â†’ Python) adiciona ponto de falha desnecessÃ¡rio, duplicaÃ§Ã£o de codebases, e complexidade operacional â€” sem benefÃ­cio real dado que o sistema nÃ£o estÃ¡ em produÃ§Ã£o.
> - **APScheduler 3.x** Ã© production-ready, async-native (`AsyncIOScheduler`), integra com FastAPI via lifespan, persiste schedules em PostgreSQL via SQLAlchemy + asyncpg (infra que o Python service jÃ¡ usa), e suporta CronTrigger com timezone.
>
> **PrincÃ­pio:** Cada runtime agenda e executa o que Ã© do seu domÃ­nio. Sem HTTP bridge para jobs agendados.

**Tasks:**

**APScheduler Setup:**
- [x] Adicionar dependÃªncia: `uv add apscheduler==3.11.2`
- [x] Adicionar configuraÃ§Ãµes de scheduler ao `app/config.py` Settings:
  - `CONSOLIDATION_ENABLED`, `CONSOLIDATION_CRON_HOUR`, `CONSOLIDATION_CRON_MINUTE`
- [x] Criar `app/workers/scheduler.py`:
  - Configurar `AsyncIOScheduler` com MemoryJobStore (in-memory, re-registra no startup)
  - Integrar no FastAPI lifespan (`app/main.py`): `scheduler.start()` no startup, `scheduler.shutdown()` no teardown
  - No startup: query distinct user timezones ativos, registrar `CronTrigger` por timezone
  - Usar `replace_existing=True` em `add_job()` para idempotÃªncia no startup

**Memory Consolidation:**
- [x] Criar `app/workers/consolidation.py`:
  - FunÃ§Ã£o `async run_consolidation(timezone: str)` â€” entry point do scheduler
  - Usar `get_service_session()` para bypass de RLS (operaÃ§Ã£o cross-user)
  - Per-user: messages since lastConsolidatedAt, dedup, LLM call, apply updates, log
  - Retorna: `ConsolidationResult(users_processed, users_consolidated, users_skipped, errors, completed_at)`
  - Error handling per-user: falha em um usuÃ¡rio nÃ£o impede processamento dos demais
- [x] Portar `consolidation-prompt.ts` (337L) para Python (`consolidation_prompt.py`):
  - Prompt builder em portuguÃªs (mesma estrutura do TypeScript)
  - Parser de response com validaÃ§Ã£o Pydantic (equivalente ao Zod schema atual)
  - NormalizaÃ§Ã£o de tipos invÃ¡lidos do LLM (ex: `challenge` â†’ `insight`)
  - Fallback para JSON truncado/malformado
- [x] Criar `app/workers/utils.py`:
  - `refresh_schedules(scheduler, session_factory)` â€” re-query timezones e upsert schedules
  - `run_consolidation_for_user(user_id)` â€” trigger manual (dev/testing)
  - `retry_with_backoff()` â€” exponencial 1sâ†’2sâ†’4s (3 tentativas)

**Contradiction Detection:**
- [x] Expandir `app/tools/memory/_contradiction_detector.py`:
  - Melhorar parse de JSON com fallback para output truncado (`_try_extract_json_array()`)
  - Manter threshold de confianÃ§a 0.7
- [x] Integrar com consolidation: antes de salvar knowledge_item, chamar contradiction detection
- [x] Reutilizar `ContradictionResult` dataclass existente

**NestJS Deactivation:**
- [x] Atualizar `memory-consolidation.scheduler.ts`:
  - Quando `USE_PYTHON_AI=true`: **nÃ£o registrar** schedulers BullMQ para memory-consolidation (skip no `onModuleInit`)
  - Quando `false`: comportamento atual (fallback TypeScript)
  - Log indicando qual sistema estÃ¡ ativo: `"Memory consolidation: Python APScheduler"` ou `"Memory consolidation: NestJS BullMQ"`
- [x] Manter `cleanup-onboarding` inalterado (nÃ£o usa LLM, fica no NestJS BullMQ)
- [x] CÃ³digo TypeScript do memory-consolidation NÃƒO Ã© deletado aqui (cleanup em M4.10)

**Admin/Dev Endpoints:**
- [x] Criar endpoint POST `/workers/consolidation/trigger` em `app/api/routes/workers.py`:
  - Auth via SERVICE_SECRET
  - Recebe: `{ user_id?: string, timezone?: string }`
  - Trigger manual para dev/testing (equivalente ao admin endpoint NestJS)
  - Retorna: `ConsolidationResult`

**Testes:**
- [x] Teste: APScheduler registra schedules por timezone no startup
- [x] Teste: consolidation extrai fatos corretos de conversas
- [x] Teste: contradictions detectadas (ex: "gosta de cafÃ©" â†’ "parou de tomar cafÃ©")
- [x] Teste: user_memories atualizadas corretamente apÃ³s consolidation
- [x] Teste: knowledge_items criados sem duplicatas
- [x] Teste: batch contradiction detection com mÃºltiplos fatos
- [x] Teste: retry funciona apÃ³s falha de LLM (3 tentativas com backoff)
- [x] Teste: schedules re-registrados apÃ³s restart do serviÃ§o (idempotÃªncia)
- [x] Teste: NestJS nÃ£o registra memory-consolidation schedulers quando `USE_PYTHON_AI=true`
- [x] Teste: skip user se 0 mensagens desde lastConsolidatedAt (deduplicaÃ§Ã£o)
- [x] Teste: falha parcial â€” um user falha, outros continuam processando
- [x] Teste: consolidation log criado corretamente em memory_consolidations
- [x] Teste: endpoint admin trigger retorna resposta correta

**Definition of Done:**
- [x] APScheduler roda consolidation diariamente Ã s 3:00 AM por timezone
- [x] Fatos extraÃ­dos corretamente de conversas (equivalente ao TypeScript)
- [x] Contradictions detectadas com confianÃ§a adequada (threshold 0.7)
- [x] Schedules re-registrados no startup (idempotentes via `replace_existing=True`)
- [x] NestJS memory-consolidation desativado quando `USE_PYTHON_AI=true`
- [x] Resultado equivalente ao sistema TypeScript

> **DecisÃ£o tomada (2026-02-24):** Arquitetura hÃ­brida â€” jobs AI em Python (APScheduler), jobs CRUD em NestJS (BullMQ). Pesquisa tÃ©cnica completa documentada na sessÃ£o de anÃ¡lise.
>
> **DecisÃ£o atualizada (2026-02-24):** Usar **APScheduler 3.11.2 (estÃ¡vel)** com `AsyncIOScheduler` + `MemoryJobStore` (in-memory). Schedules re-registrados no startup via `add_job(replace_existing=True)` â€” mesmo padrÃ£o do NestJS `upsertJobScheduler`. APScheduler 4.x descartado (ainda alpha, 4.0.0a6). PersistÃªncia em PostgreSQL desnecessÃ¡ria para single-process com re-registro automÃ¡tico.
>
> **Stack de scheduling Python:** APScheduler 3.11.2 + `AsyncIOScheduler` + `MemoryJobStore` + `CronTrigger(timezone=)`. Roda in-process no FastAPI via lifespan â€” sem processo separado (diferente de Celery Beat).
>
> **Alternativas avaliadas e descartadas:**
> - APScheduler 4.x (alpha 4.0.0a6 â€” API instÃ¡vel, sem release estÃ¡vel)
> - BullMQ Python (Alpha, sem cron jobs, bugs crÃ­ticos)
> - HTTP bridge NestJSâ†’Python (complexidade operacional desnecessÃ¡ria para sistema nÃ£o em produÃ§Ã£o)
> - Celery (nÃ£o async-native, impedance mismatch com FastAPI + asyncpg)
> - Taskiq (pre-1.0, comunidade pequena)
> - arq (maintenance-only mode)
>
> **PadrÃ£o de scheduling:**
> ```
> Jobs AI:   FastAPI lifespan â†’ APScheduler AsyncIOScheduler (CronTrigger, MemoryJobStore) â†’ async Python function
> Jobs CRUD: NestJS BullMQ (cron trigger, Redis) â†’ NestJS processor
> ```

**Notas (2026-02-24):**
- ImplementaÃ§Ã£o completa: APScheduler + consolidation worker + prompt parser + contradiction detection + admin endpoint + NestJS guard
- Novos arquivos Python: `workers/__init__.py`, `scheduler.py`, `consolidation.py`, `consolidation_prompt.py`, `utils.py`, `api/routes/workers.py`
- Modificados: `config.py` (3 settings), `main.py` (scheduler lifespan + workers route), `db/repositories/user.py` (2 mÃ©todos), `tools/memory/_contradiction_detector.py` (JSON fallback)
- NestJS: `memory-consolidation.scheduler.ts` guarded com `USE_PYTHON_AI` flag via `AppConfigService`
- Testes completos (18 Python + 1 NestJS): `tests/test_workers.py` (7 testes: scheduler, retry, endpoint trigger), `tests/test_consolidation.py` (11 testes: extraction, contradictions, memory updates, deduplication, partial failure, logging, priority resolution), `memory-consolidation.scheduler.spec.ts` (+1 teste: skip BullMQ when usePythonAi=true)
- `ruff check .` + `mypy app/` + `pytest` (232 passed) + `vitest` (854 passed) all pass

---

## M4.9 â€” Production Readiness: Observability + Validation ðŸ”´

**Objetivo:** Preparar o serviÃ§o Python para produÃ§Ã£o: configurar observabilidade (Sentry, logging estruturado), corrigir gaps de validaÃ§Ã£o, e validar paridade funcional com o sistema TypeScript via testes E2E com `USE_PYTHON_AI=true`.

**ReferÃªncias:** Todos os milestones anteriores (M4.1-M4.8), `docs/specs/core/observability.md`

**DependÃªncias:** M4.7, M4.8

> **Contexto:** Este milestone fecha os gaps de infra/observabilidade identificados na comparaÃ§Ã£o NestJSâ†”Python. A funcionalidade de AI/chat (20 tools, confirmation flow, memory consolidation, multi-agent triage) jÃ¡ estÃ¡ em paridade funcional ou melhor no Python. Os gaps sÃ£o de **infraestrutura de produÃ§Ã£o**: Sentry (zero error tracking no Python), structured logging (sem JSON, sem request_id), e input validation (aceita mensagem vazia). AlÃ©m disso, valida paridade funcional via testes E2E Playwright rodando com `USE_PYTHON_AI=true`.
>
> **Nota sobre "parallel validation":** NÃƒO Ã© shadow traffic (rodar ambos os sistemas e comparar). Ã‰ testar com a flag `USE_PYTHON_AI` alternada â€” os mesmos testes E2E devem passar com `true` e `false`.

**Tasks:**

**Sentry para Python Service (gap: ZERO error tracking hoje):**
> No NestJS: `@sentry/nestjs@10.32.1` com `nestIntegration()`, auto-capture de exceÃ§Ãµes, `tracesSampleRate: 0.1` em prod, `sendDefaultPii: false`, disabled em test. No Python: **nada** â€” erros vÃ£o para stdout e sÃ£o invisÃ­veis.
- [ ] Instalar SDK: `cd services/ai && uv add 'sentry-sdk[fastapi]'`
- [ ] Criar `app/observability.py` com `init_sentry(settings)`:
  - `FastApiIntegration()` â€” auto-capture de exceÃ§Ãµes em endpoints
  - `SqlalchemyIntegration()` â€” capture de erros de DB
  - `traces_sample_rate`: 0.1 em prod, 1.0 em dev (match NestJS)
  - `send_default_pii=False` (match NestJS)
  - `environment` from settings (`development` | `production`)
  - `release` from `APP_VERSION`
  - `enabled`: False quando `ENVIRONMENT=test`
  - Inicializar apenas se `SENTRY_DSN` estiver configurado (match NestJS: optional)
- [ ] Chamar `init_sentry()` no topo de `app/main.py` (antes de criar FastAPI app â€” Sentry precisa instrumentar antes)
- [ ] Adicionar `SENTRY_DSN` ao `app/config.py` (Settings): `SENTRY_DSN: str = ""` (optional, empty = disabled)
- [ ] Adicionar `ENVIRONMENT` ao `app/config.py`: `ENVIRONMENT: str = "development"`
- [ ] Testar: provocar erro intencional â†’ verificar que aparece no Sentry dashboard
- [ ] Verificar: erros de LLM (timeout, rate limit) capturados automaticamente
- [ ] Verificar: erros de DB (connection, RLS) capturados automaticamente

**Structured Logging + Request-ID Correlation (gap: plain text logs sem correlaÃ§Ã£o):**
> No NestJS: `AppLoggerService` (176L) com JSON structured output `{level, message, timestamp, requestId, userId, statusCode, durationMs}` + `RequestIdMiddleware` (45L) propaga `x-request-id` + `LoggingInterceptor` (74L) loga cada request/response. No Python: `logging.getLogger()` default com output `INFO: message` â€” sem JSON, sem requestId, impossÃ­vel correlacionar com logs do NestJS.
- [ ] Criar `app/api/middleware/request_id.py`:
  - Ler `x-request-id` header do request (propagado pelo NestJS proxy)
  - Se ausente, gerar `uuid4()`
  - Armazenar em contexto (ContextVar) para acesso global
  - Retornar no response header `x-request-id`
- [ ] Configurar JSON logging formatter em `app/observability.py`:
  - Format: `{"level", "message", "timestamp", "request_id", "user_id", "duration_ms"}`
  - Usar `python-json-logger` ou formatter custom (avaliar se dependÃªncia extra vale)
  - Configurar `uvicorn.access` e `uvicorn.error` loggers para JSON
- [ ] Adicionar middleware de logging (equivalente ao `LoggingInterceptor` do NestJS):
  - Log de entrada: `POST /chat/invoke {request_id, user_id}`
  - Log de saÃ­da: `POST /chat/invoke 200 {request_id, duration_ms}`
- [ ] Propagar `request_id` para Sentry (via `sentry_sdk.set_tag("request_id", ...)`)
- [ ] Testar: fazer request via NestJS proxy â†’ verificar que requestId aparece nos logs Python e Sentry

**Input Validation (gap: aceita mensagem vazia):**
> No NestJS: `class-validator` com `@IsNotEmpty()` no DTO global validation pipe. No Python: Pydantic `message: str` sem `min_length` â€” `""` passa.
- [ ] Adicionar `min_length=1` no Pydantic model de `/chat/invoke`: `message: str = Field(min_length=1)`
- [ ] Adicionar validaÃ§Ã£o no `/chat/resume`: `action` deve ser `"confirm" | "reject" | "edit"` (Literal type)
- [ ] Testar: POST com `message: ""` â†’ retorna 422 Validation Error

**Suite de Paridade â€” Testes E2E Playwright (`USE_PYTHON_AI=true`):**
> Mesmos testes E2E existentes, executados com flag alternada. O objetivo Ã© garantir que o frontend funciona identicamente. CenÃ¡rios testados via Playwright (browser real) contra a API com proxy Python ativo.
- [ ] Mensagens simples:
  - "Bom dia" â†’ triage classifica como general â†’ resposta coerente
  - "Como vocÃª estÃ¡?" â†’ general agent
  - Conversa tipo counselor â†’ triage classifica como wellbeing
- [ ] Tracking com confirmaÃ§Ã£o (6 cenÃ¡rios):
  - "Registra 2L de Ã¡gua hoje" â†’ confirm â†’ verificar registro no DB
  - "Registra 2L de Ã¡gua hoje" â†’ reject â†’ nada salvo
  - "Quanto peso eu registrei esta semana?" â†’ READ tool â†’ dados corretos
  - "Apaga o registro de Ã¡gua de ontem" â†’ confirm â†’ delete no DB
  - "Atualiza meu peso de hoje para 75kg" â†’ confirm â†’ update no DB
  - "Registra que fiz exercÃ­cio hoje" â†’ confirm â†’ habit completion
- [ ] Finance queries (5 cenÃ¡rios):
  - "Quanto gastei este mÃªs?" â†’ `get_finance_summary` â†’ summary correto
  - "Quais contas vencem esta semana?" â†’ `get_pending_bills` â†’ lista
  - "Registra gasto de R$50 com almoÃ§o" â†’ confirm â†’ expense criada
  - "Marca conta de luz como paga" â†’ confirm â†’ bill status updated
  - "Como estÃ£o minhas dÃ­vidas?" â†’ `get_debt_progress` â†’ dados corretos
- [ ] Memory (3 cenÃ¡rios):
  - "O que vocÃª sabe sobre mim?" â†’ `search_knowledge` / `analyze_context` â†’ user memories
  - "Lembra que eu prefiro cafÃ© sem aÃ§Ãºcar" â†’ confirm â†’ knowledge item criado
  - Busca em knowledge_items com filtros (type, area)
- [ ] Edge cases:
  - Timeout de LLM â†’ SSE error event graceful (nÃ£o crash)
  - ConfirmaÃ§Ã£o apÃ³s 5+ minutos â†’ funciona (LangGraph checkpoints em PostgreSQL sem TTL, melhoria vs Redis 5min do TypeScript)
  - Mensagem vazia â†’ 422 rejeitado (apÃ³s fix de input validation)
  - Duas mensagens rÃ¡pidas em sequÃªncia â†’ sem race condition

> **Nota sobre cenÃ¡rio multi-domain:** "Como estou financeiramente e na saÃºde?" Ã© roteado pelo triage para UM domÃ­nio (limitaÃ§Ã£o arquitetural do single-domain dispatch em M4.7). O agente responde sobre o domÃ­nio primÃ¡rio e pode complementar via memory tools (compartilhadas). Isso Ã© comportamento esperado, nÃ£o bug de paridade â€” o sistema TypeScript anterior tambÃ©m usava single agent sem routing inteligente.

**SSE Event Compatibility:**
> Verificado na anÃ¡lise de cÃ³digo: Python emite os mesmos eventos que o TypeScript. O NestJS proxy (`parsePythonSSEStream()`) jÃ¡ adapta diferenÃ§as menores. DiferenÃ§as conhecidas e aceitas:
> - `tool_calls`: Python nÃ£o inclui campo `iteration` (NestJS proxy nÃ£o usa esse campo)
> - `awaitingConfirmation`: Python inclui `content` com mensagem de confirmaÃ§Ã£o (NestJS proxy repassa)
- [ ] Verificar via testes E2E que todos os SSE events sÃ£o renderizados corretamente no frontend:
  - `tool_calls` â†’ UI mostra indicador de tool execution
  - `tool_result` â†’ UI mostra resultado
  - `confirmation_required` â†’ UI mostra dialog de confirmaÃ§Ã£o
  - Final response `{ content, done: true }` â†’ UI mostra resposta
  - Error `{ content, done: true, error: true }` â†’ UI mostra erro
  - `{ done: true, awaitingConfirmation: true }` â†’ UI aguarda resposta do usuÃ¡rio
- [ ] Confirmar que frontend NÃƒO precisa de mudanÃ§as de cÃ³digo

**Memory Consolidation Parity:**
> Migrado em M4.8 (APScheduler no Python substitui BullMQ no NestJS). NestJS jÃ¡ tem guard `if usePythonAi â†’ skip BullMQ scheduler`. Validar que o worker Python produz resultados equivalentes.
- [ ] Trigger manual (`POST /workers/consolidation/trigger`) â†’ consolidation executa e retorna mÃ©tricas
- [ ] Verificar que `user_memories` Ã© atualizado corretamente (bio, goals, challenges, patterns)
- [ ] Verificar que `knowledge_items` sÃ£o criados com contradiction detection
- [ ] Verificar que `memory_consolidations` audit log Ã© criado
- [ ] Verificar que scheduler APScheduler registra jobs por timezone no startup

**Performance:**
- [ ] Load testing com k6 ou locust: 50 concurrent chat requests ao Python service
  - MÃ©tricas: p50, p95, p99 latency + error rate
- [ ] Verificar latÃªncia do proxy NestJS â†’ Python (deve ser <50ms overhead em localhost)
- [ ] Verificar que triage com Flash model < 500ms (p95)
- [ ] Validar `InMemoryRateLimiter` do LangChain sob carga (single-process). Se insuficiente em produÃ§Ã£o com mÃºltiplos workers uvicorn, documentar como melhoria futura (Redis-based rate limiter)

**Testes:**
- [ ] Testes E2E Playwright passam com `USE_PYTHON_AI=true` (mesmos cenÃ¡rios que passam com `false`)
- [ ] Frontend funciona sem mudanÃ§as de cÃ³digo
- [ ] Load test: sem erros em 50 concurrent requests (p99 < 30s para chat com tool calls)
- [ ] Sentry captura erros do Python service (verificar no dashboard)
- [ ] Logs Python em JSON com request_id correlacionÃ¡vel com NestJS
- [ ] Memory consolidation manual trigger funciona corretamente

**Definition of Done:**
- [ ] Sentry configurado e capturando erros do Python (FastAPI + SQLAlchemy integrations)
- [ ] Logs estruturados (JSON) com request_id propagado do NestJS
- [ ] Input validation: mensagem vazia rejeitada (422)
- [ ] Testes E2E passam identicamente com `USE_PYTHON_AI=true` e `false`
- [ ] Performance aceitÃ¡vel sob carga (50 concurrent, p95 < 15s)
- [ ] Memory consolidation worker validado (trigger manual + audit log)
- [ ] Observability spec (`docs/specs/core/observability.md`) atualizada com Python service

---

## M4.10 â€” NestJS Cleanup + Production Deploy ðŸ”´

**Objetivo:** Deletar todo o cÃ³digo TypeScript AI obsoleto (~13.400 linhas), simplificar NestJS para proxy, deploy em produÃ§Ã£o.

**ReferÃªncias:** `docs/ai-python-service-migration-plan.md` Â§5, Â§7, Â§12

**DependÃªncias:** M4.9

> **Contexto:** Este Ã© o milestone de maior risco â€” deleta ~12.650 linhas de cÃ³digo AI (~11.600 + ~1.048 do memory consolidation, que foi migrado para Python APScheduler em M4.8) e simplifica ~1.650 linhas. A safety net Ã© o M4.9 (validaÃ§Ã£o de paridade) e o deploy strategy (blue-green ou canary). Rollback Ã© possÃ­vel revertendo o commit + `USE_PYTHON_AI=false`.

**Tasks:**

**Deletar packages/ai/ (~7.677 linhas):**
- [ ] Deletar diretÃ³rio `packages/ai/` inteiro
- [ ] Remover `@life-assistant/ai` do `pnpm-workspace.yaml`
- [ ] Remover dependÃªncias npm: `@anthropic-ai/sdk`, `@google/genai`, `zod-to-json-schema`
- [ ] Remover referÃªncias em `tsconfig` base

**Deletar tool executors do NestJS:**
- [ ] Deletar `tracking-tool-executor.service.ts` (~587L)
- [ ] Deletar `finance-tool-executor.service.ts` (~1.047L)
- [ ] Deletar `memory-tool-executor.service.ts` (~297L)
- [ ] Remover providers dos respectivos modules

**Deletar serviÃ§os AI do NestJS:**
- [ ] Deletar `confirmation-state.service.ts` (~475L)
- [ ] Deletar `context-builder.service.ts` (~337L)
- [ ] Deletar `contradiction-detector.adapter.ts` (~435L)

**Deletar memory consolidation do NestJS (migrado para Python APScheduler em M4.8):**
- [ ] Deletar `memory-consolidation.processor.ts` (~557L)
- [ ] Deletar `memory-consolidation.scheduler.ts` (~151L)
- [ ] Deletar `consolidation-prompt.ts` (~337L)
- [ ] Remover queue `MEMORY_CONSOLIDATION` de `queues.ts` e `jobs.module.ts`
- [ ] Remover `MemoryConsolidationScheduler` e `MemoryConsolidationProcessor` dos providers em `jobs.module.ts`
- [ ] Remover dependÃªncia de `MemoryModule` em `JobsModule` (se nÃ£o usada pelo cleanup-onboarding)
- [ ] Manter `cleanup-onboarding` intacto (BullMQ, nÃ£o usa LLM)
- [ ] Resultado: ~1.048 linhas deletadas (de ~1.048)

**Simplificar chat.service.ts:**
- [ ] Remover lÃ³gica de tool loop TypeScript
- [ ] Remover imports de `@life-assistant/ai`
- [ ] Remover feature flag `USE_PYTHON_AI` (Python Ã© o Ãºnico caminho)
- [ ] Resultado: ~200 linhas (de ~1.232) â€” apenas: salvar msg do user + proxy HTTP/SSE para Python

**Simplificar chat.module.ts:**
- [ ] Remover providers de AI/tools/confirmation
- [ ] Manter apenas: ChatController, ChatService (proxy), ChatRepository, MessageRepository

**Atualizar monorepo:**
- [ ] Remover imports quebrados em todo o codebase
- [ ] Atualizar `CLAUDE.md` â€” remover referÃªncias a `packages/ai/`, adicionar `services/ai/`
- [ ] Atualizar `docs/specs/core/architecture.md` â€” nova arquitetura de 3 serviÃ§os

**Testes de regressÃ£o:**
- [ ] `pnpm typecheck` â€” sem erros de tipo
- [ ] `pnpm lint` â€” sem erros de lint
- [ ] `pnpm test` â€” todos os testes unitÃ¡rios passam
- [ ] `pnpm test:e2e` â€” todos os testes E2E passam (Playwright)
- [ ] Testes de paridade de M4.9 ainda passam

**Deploy produÃ§Ã£o:**
- [ ] Railway: criar serviÃ§o Python AI (Nixpacks, Python buildpack)
- [ ] Railway: configurar internal networking (`python-ai.railway.internal:8000`)
- [ ] Railway: configurar env vars (DATABASE_URL, GEMINI_API_KEY, SERVICE_SECRET, SENTRY_DSN, ENVIRONMENT=production)
- [ ] Deploy strategy: blue-green ou canary
- [ ] Monitoramento pÃ³s-deploy: 24-48h de observaÃ§Ã£o
- [ ] Verificar Sentry: sem novos erros no Python service
- [ ] Verificar logs: requests fluindo corretamente NestJS â†’ Python

**Definition of Done:**
- [ ] `packages/ai/` deletado (0 linhas)
- [ ] NestJS `chat.service.ts` Ã© ~200L de proxy (de ~1.232L)
- [ ] `pnpm typecheck && pnpm lint && pnpm test` passam
- [ ] `pnpm test:e2e` passa
- [ ] ProduÃ§Ã£o estÃ¡vel por 48h sem novos erros
- [ ] Total removido: **~12.650 linhas deletadas** + **~1.650 simplificadas**

> **Riscos:**
> - RegressÃµes em edge cases de confirmaÃ§Ã£o (SSE event ordering diferente)
> - Imports quebrados em arquivos nÃ£o cobertos pelos testes
> - Performance em produÃ§Ã£o diferente de local (latÃªncia Railway internal networking)
> - Rollback plan: reverter commit + `USE_PYTHON_AI=false` no NestJS (requer que packages/ai/ ainda exista no git history)
> - Memory consolidation: rollback requer reativar BullMQ schedulers no NestJS (cÃ³digo ainda existe atÃ© ser deletado neste milestone)

---

## Resumo Quantitativo

| MÃ©trica | Valor |
|---|---|
| Milestones | 10 (M4.1 â€” M4.10) |
| Linhas deletadas do NestJS | **~12.650** (deletadas, inclui memory consolidation ~1.048L migrado para Python) |
| Linhas simplificadas no NestJS | **~1.650** (chat.service.ts, chat.module.ts, jobs.module.ts) |
| Linhas adicionadas no NestJS | ~160 (proxy SSE + config + feature flag) |
| Novo cÃ³digo Python | **~5.500-7.500** (estimativa â€” inclui APScheduler setup + consolidation) |
| SQLAlchemy models | ~120-200 linhas (mapeamento passivo + CI check) |
| Pacote deletado | `packages/ai/` (**7.677 linhas**, 49 arquivos) |
| Novo diretÃ³rio | `services/ai/` (Python AI Service) |
| ServiÃ§os NestJS intactos | Auth, REST controllers, domain services, repositories, BullMQ (cleanup + CRUD jobs) |
| Scheduling AI | APScheduler no Python (memory consolidation, follow-ups futuros) |
| Scheduling CRUD | BullMQ no NestJS (cleanup-onboarding, calendar sync futuro) |
| MudanÃ§as no frontend | Nenhuma (SSE events mantÃªm mesmo formato) |

### Estrutura do monorepo apÃ³s migraÃ§Ã£o

```
life-assistant/
â”œâ”€â”€ apps/
â”‚   â”œâ”€â”€ web/                    # Next.js (sem mudanÃ§as)
â”‚   â””â”€â”€ api/                    # NestJS (simplificado â€” sem AI code)
â”‚
â”œâ”€â”€ services/
â”‚   â””â”€â”€ ai/                     # Python AI Service (NOVO)
â”‚       â”œâ”€â”€ app/
â”‚       â”‚   â”œâ”€â”€ agents/         # LangGraph agents + graph
â”‚       â”‚   â”œâ”€â”€ api/            # FastAPI routes + middleware (incl. request_id)
â”‚       â”‚   â”œâ”€â”€ db/             # SQLAlchemy models + repositories
â”‚       â”‚   â”œâ”€â”€ observability.py # Sentry init + JSON logging (M4.9)
â”‚       â”‚   â”œâ”€â”€ prompts/        # System prompt + context builder
â”‚       â”‚   â”œâ”€â”€ tools/          # 20 tool implementations
â”‚       â”‚   â””â”€â”€ workers/        # APScheduler + Memory consolidation (cron jobs AI)
â”‚       â”œâ”€â”€ tests/
â”‚       â”œâ”€â”€ pyproject.toml
â”‚       â””â”€â”€ Dockerfile
â”‚
â”œâ”€â”€ packages/
â”‚   â”œâ”€â”€ database/               # Drizzle schemas + migrations (source of truth)
â”‚   â”œâ”€â”€ config/                 # Zod config (NestJS)
â”‚   â””â”€â”€ shared/                 # Shared enums/constants
â”‚   # packages/ai/ â†’ DELETADO em M4.10
â”‚
â”œâ”€â”€ docs/
â”œâ”€â”€ infra/
â””â”€â”€ ...
```
