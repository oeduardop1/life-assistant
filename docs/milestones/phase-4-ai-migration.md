# Fase 4: MigraÃ§Ã£o da IA para Python (v4.x)

> **Objetivo:** Migrar toda a camada de inteligÃªncia artificial (packages/ai/ + tool executors + memory workers) de TypeScript/NestJS para um serviÃ§o Python independente com FastAPI + LangGraph, seguindo o padrÃ£o Strangler Fig.
> **ReferÃªncias:** `docs/ai-python-service-migration-plan.md`, `docs/adr-012-tool-use-vs-rag-analysis.md`, `docs/specs/core/architecture.md`

> **Contexto:** O ecossistema Python domina AI/ML (LangGraph, LangChain, LangSmith, scikit-learn, pandas). A implementaÃ§Ã£o atual em TypeScript (`packages/ai/` â€” 7.677 linhas, 49 arquivos) foi adequada para o MVP mas limita a evoluÃ§Ã£o para multi-agente, RAG futuro, e ferramentas avanÃ§adas de observabilidade de AI. A migraÃ§Ã£o cria um serviÃ§o Python dedicado (`services/ai/`) mantendo NestJS como API REST + auth + dashboard.
>
> **Filosofia:**
> - **Strangler Fig:** Sistema TypeScript e Python coexistem via feature flag (`USE_PYTHON_AI`). Rollback instantÃ¢neo em qualquer ponto.
> - **Milestones atÃ´micos:** Cada milestone produz um sistema funcional e testÃ¡vel. Nunca hÃ¡ estado quebrado entre milestones.
> - **LangGraph substitui, nÃ£o porta:** Muitos componentes TypeScript custom (~1.639 linhas) sÃ£o substituÃ­dos por primitivas LangGraph, nÃ£o portados 1:1.
> - **Python independente do Turbo:** O serviÃ§o Python **NÃƒO** faz parte do pnpm workspace nem do Turborepo pipeline. Python Ã© gerido 100% com ferramentas nativas (uv, ruff, mypy, pytest). O `pnpm dev` usa `concurrently` para iniciar Turbo + Python em paralelo. CI roda jobs Node e Python separados. DecisÃ£o baseada em [Turborepo multi-language docs](https://turborepo.dev/docs/guides/multi-language) e anÃ¡lise de trade-offs â€” o pattern de package.json wrapper Ã© oficialmente suportado pelo Turbo, mas gera artefatos artificiais (node_modules, lockfile entries) sem benefÃ­cio real de cache para Python.

### Insight: O que LangGraph substitui

A migraÃ§Ã£o **NÃƒO Ã© um port 1:1** do TypeScript. LangGraph substitui vÃ¡rios componentes custom:

| Componente TypeScript | Linhas | Equivalente LangGraph/LangChain | Resultado |
|---|---|---|---|
| `tool-loop.service.ts` | 310 | `create_react_agent()` (`langgraph.prebuilt`) | **Eliminado** |
| `LLMPort` interface | 245 | `ChatGoogleGenerativeAI` (`langchain-google-genai`) / `ChatAnthropic` (`langchain-anthropic`) | **Eliminado** |
| `retry.ts` + `rate-limiter.ts` | 382 | `max_retries` + `.with_retry()` + `InMemoryRateLimiter` (LangChain built-in) | **Eliminado** |
| `zod-to-gemini.ts` | 227 | `.bind_tools()` converte Pydantic â†’ formato do provider automaticamente | **Eliminado** |
| `confirmation-state.service.ts` (Redis TTL 5min) | 475 | `interrupt()` / `Command(resume=)` (`langgraph.types`) com PostgreSQL checkpoint (`AsyncPostgresSaver`) | **Redesenhado** |
| Tool definitions (Zod schemas) | ~1.000 | Pydantic models + `@tool` decorator | **Reescrito** |

> ~1.639 linhas de `packages/ai/` nÃ£o precisam ser portadas â€” sÃ£o substituÃ­das por primitivas LangGraph. O cÃ³digo Python serÃ¡ mais enxuto que o TypeScript equivalente.

### InventÃ¡rio do cÃ³digo afetado

**packages/ai/ (7.677 linhas, 49 arquivos) â€” serÃ¡ DELETADO:**

| Categoria | Linhas | Arquivos | Destino |
|---|---|---|---|
| Adapters (Claude + Gemini) | 1.932 | 4 | SubstituÃ­dos por `langchain-google-genai` / `langchain-anthropic` |
| Services (Factory, ToolLoop, Executor) | 1.503 | 7 | SubstituÃ­dos por LangGraph `create_react_agent()` |
| Tool definitions (22 tools + schemas) | 2.159 | 27 | Reescritos como Pydantic + `@tool` decorator |
| Utilities (retry, rate-limit, zod-to-gemini) | 1.484 | 8 | SubstituÃ­dos por primitivas LangChain |
| Ports/Interfaces | 245 | 1 | Eliminados (LangGraph abstrai) |
| Errors + Core | 354 | 2 | Python exception hierarchy |

**apps/api/ â€” cÃ³digo AI-related (~5.700 linhas) â€” serÃ¡ DELETADO ou SIMPLIFICADO:**

| Arquivo | Linhas | AÃ§Ã£o |
|---|---|---|
| `chat.service.ts` | 1.232 | Simplificado para ~200L (proxy SSE) |
| `finance-tool-executor.service.ts` | 1.047 | Deletado (migra para Python) |
| `tracking-tool-executor.service.ts` | 587 | Deletado (migra para Python) |
| `memory-consolidation.processor.ts` | 557 | Simplificado para ~50L (BullMQ trigger â†’ HTTP POST para Python) |
| `confirmation-state.service.ts` | 475 | Deletado (LangGraph interrupt) |
| `contradiction-detector.adapter.ts` | 435 | Deletado (migra para Python) |
| `context-builder.service.ts` | 337 | Deletado (migra para Python) |
| `memory-tool-executor.service.ts` | 297 | Deletado (migra para Python) |
| `consolidation-prompt.ts` | 337 | Deletado (migra para Python) |
| `contradiction-resolution.service.ts` | 311 | Deletado (migra para Python) |
| `contradiction-detector.port.ts` | 86 | Deletado (interface eliminada) |

**Total:** ~11.600 linhas deletadas + ~2.700 simplificadas (~1.800 delta removido) â†’ ~5.000-7.000 linhas Python novas

### Paralelismo entre milestones

- M4.5 (Finance Tools) e M4.6 (Memory Tools) podem rodar **em paralelo** (ambos dependem de M4.4 mas sÃ£o independentes entre si)
- M4.1 pode comeÃ§ar **imediatamente** sem afetar trabalho nas outras fases
- Feature flag permite **rollback instantÃ¢neo** em qualquer ponto da migraÃ§Ã£o

---

## M4.1 â€” Python Service: Scaffold + Infra + CI ğŸŸ¢

**Objetivo:** ServiÃ§o Python bootÃ¡vel com FastAPI, integrado no fluxo de dev local (`pnpm infra:up` + `pnpm dev`) e CI. Nenhuma lÃ³gica de AI â€” apenas infraestrutura.

**ReferÃªncias:** `docs/ai-python-service-migration-plan.md` Â§3, Â§10

**DependÃªncias:** Nenhuma (pode comeÃ§ar imediatamente)

> **DecisÃ£o arquitetural:** O serviÃ§o Python NÃƒO faz parte do pnpm workspace nem do Turborepo. Python Ã© gerido com ferramentas nativas (uv, ruff, mypy, pytest). `pnpm dev` usa `concurrently` para iniciar Turbo (JS/TS) + uvicorn (Python) em paralelo. Esta decisÃ£o segue o princÃ­pio de separaÃ§Ã£o de concerns â€” cada linguagem com seu toolchain nativo, sem artefatos artificiais.

**Tasks:**

**Scaffold do projeto Python (via CLI):**
- [x] Inicializar projeto: `uv init --app --python 3.12 services/ai`
  - Cria: `pyproject.toml`, `.python-version`, `.gitignore`, `README.md`, `main.py`
  - Flag `--no-workspace` se existir `pyproject.toml` na raiz do monorepo (evita auto-join)
- [x] Adicionar dependÃªncias runtime:
  ```bash
  cd services/ai
  uv add fastapi 'uvicorn[standard]' 'sqlalchemy[asyncio]' asyncpg langgraph langgraph-checkpoint-postgres langchain-google-genai langchain-anthropic pydantic pydantic-settings sse-starlette
  ```
- [x] Adicionar dependÃªncias dev:
  ```bash
  uv add --dev pytest pytest-asyncio ruff mypy httpx
  ```
- [x] Configurar tool settings no `pyproject.toml` (seÃ§Ãµes `[tool.ruff]`, `[tool.mypy]`, `[tool.pytest.ini_options]`)
- [x] Remover `main.py` gerado pelo scaffold e reorganizar para estrutura `app/`:
  ```
  services/ai/
  â”œâ”€â”€ app/
  â”‚   â”œâ”€â”€ __init__.py
  â”‚   â”œâ”€â”€ main.py          # FastAPI app + lifespan (startup/shutdown)
  â”‚   â”œâ”€â”€ config.py         # Pydantic Settings (BaseSettings)
  â”‚   â”œâ”€â”€ dependencies.py   # FastAPI Depends() â€” DB session, config
  â”‚   â””â”€â”€ api/
  â”‚       â”œâ”€â”€ routes/
  â”‚       â”‚   â””â”€â”€ health.py # GET /health (status + DB check)
  â”‚       â””â”€â”€ middleware/
  â”‚           â””â”€â”€ auth.py   # Service-to-service auth (Bearer token)
  â”œâ”€â”€ tests/
  â”œâ”€â”€ pyproject.toml
  â”œâ”€â”€ uv.lock
  â””â”€â”€ .python-version
  ```
- [x] Criar `app/main.py` com FastAPI lifespan:
  - Startup: `AsyncPostgresSaver.setup()` (cria tabelas de checkpoint: `checkpoints`, `checkpoint_blobs`, `checkpoint_writes`, `checkpoint_migrations`)
  - Shutdown: dispose engine
- [x] Criar `app/config.py` com Pydantic Settings:
  - `DATABASE_URL`, `GEMINI_API_KEY`, `SERVICE_SECRET`, `ANTHROPIC_API_KEY` (opcional)
  - Loads from root `.env` via `model_config = SettingsConfigDict(env_file="../../.env")`
- [x] Criar `app/dependencies.py` â€” FastAPI `Depends()` com generator `yield` para DB session
- [x] Criar `app/api/routes/health.py` â€” GET /health (status + versÃ£o + check de DB)
- [x] Criar `app/api/middleware/auth.py` â€” service-to-service auth via shared secret (Bearer token)
- [x] Estender `.gitignore` gerado pelo uv: adicionar `__pycache__/`, `.mypy_cache/`, `.pytest_cache/`, `.ruff_cache/`

> **Nota:** `sse-starlette` Ã© dependÃªncia explÃ­cita â€” FastAPI nÃ£o tem classe SSE built-in. Usar `EventSourceResponse` para streaming.
> **Nota:** `REDIS_URL` removido da config Python â€” nÃ£o necessÃ¡rio na fase inicial. ConfirmaÃ§Ã£o usa PostgreSQL (LangGraph checkpoints), nÃ£o Redis TTL. BullMQ scheduling permanece no NestJS.

**IntegraÃ§Ã£o com `pnpm dev` (via `concurrently`):**
- [x] Instalar concurrently: `pnpm add -Dw concurrently`
- [x] Atualizar `package.json` root:
  ```json
  {
    "scripts": {
      "dev": "concurrently -k -p [{name}] -n turbo,ai -c blue,yellow \"turbo run dev\" \"cd services/ai && uv run uvicorn app.main:app --reload --host 0.0.0.0 --port 8000\"",
      "dev:js": "turbo run dev",
      "dev:ai": "cd services/ai && uv run uvicorn app.main:app --reload --host 0.0.0.0 --port 8000"
    }
  }
  ```
- [x] Verificar que `Ctrl+C` mata todos os processos (flag `-k` do concurrently)
- [x] Verificar que output mostra prefixos `[turbo]` e `[ai]` no terminal

**IntegraÃ§Ã£o com `pnpm infra:up` (dev-start.sh):**
- [x] Adicionar porta 8000 ao `check_ports()` existente
- [x] Criar novo Step (entre Service Status e Database Schema):
  ```
  Step 4: Python AI Service Setup
    âœ“ Check Python 3.12+
    âœ“ Check uv package manager
    âœ“ Install dependencies (uv sync)
    âœ“ Python environment ready
  ```
- [x] Implementar `check_python()`:
  - Verificar `python3 --version` >= 3.12
  - Se nÃ£o encontrado: mensagem com instruÃ§Ãµes de instalaÃ§Ã£o
- [x] Implementar `check_uv()`:
  - Verificar `uv --version`
  - Se nÃ£o encontrado: sugerir `curl -LsSf https://astral.sh/uv/install.sh | sh`
- [x] Implementar `setup_python_env()`:
  - `cd services/ai && uv sync` (cria .venv + instala deps)
  - Idempotente: <2s em runs subsequentes
  - VerificaÃ§Ã£o: `uv run python -c "import fastapi; print('OK')"`
- [x] Atualizar summary final para mostrar Python AI Service URL (localhost:8000)
- [x] Renumerar steps: 1-Docker, 2-Supabase, 3-Status, **4-Python**, 5-Database

**Docker (produÃ§Ã£o + CI):**
- [x] Criar `services/ai/Dockerfile`:
  ```dockerfile
  FROM python:3.12-slim AS base
  WORKDIR /app
  RUN pip install uv

  FROM base AS deps
  COPY pyproject.toml uv.lock ./
  RUN uv sync --frozen --no-dev

  FROM base AS runner
  COPY --from=deps /app/.venv /app/.venv
  COPY app/ app/
  ENV PATH="/app/.venv/bin:$PATH"
  EXPOSE 8000
  CMD ["uvicorn", "app.main:app", "--host", "0.0.0.0", "--port", "8000"]
  ```
- [x] Criar `services/ai/.dockerignore` â€” `.venv/`, `__pycache__/`, `.git/`, `tests/`, `.mypy_cache/`
- [x] **NÃƒO** adicionar Python ao docker-compose.yml (Python roda nativo em dev, Docker sÃ³ para produÃ§Ã£o)

**VariÃ¡veis de ambiente:**
- [x] Adicionar ao `.env.example`:
  ```bash
  # Python AI Service
  PYTHON_AI_URL=http://localhost:8000
  SERVICE_SECRET=dev-secret-change-me
  USE_PYTHON_AI=false
  ```
- [x] Adicionar `PYTHON_AI_URL` ao `packages/config/`

**CI (GitHub Actions â€” job separado):**
- [x] Criar `services/ai/tests/conftest.py` â€” fixtures base (async test client via `httpx.AsyncClient`, test DB session)
- [x] Adicionar job `python` no workflow CI:
  ```yaml
  python:
    runs-on: ubuntu-latest
    defaults:
      run:
        working-directory: services/ai
    steps:
      - uses: actions/checkout@v4
      - uses: astral-sh/setup-uv@v5
        with:
          python-version: "3.12"
      - run: uv sync
      - run: uv run ruff check .
      - run: uv run ruff format --check .
      - run: uv run mypy app/
      - run: uv run pytest
  ```
- [x] Job Python roda em **paralelo** com job Node (nÃ£o sequencial)

**DocumentaÃ§Ã£o:**
- [x] Atualizar `CLAUDE.md`:
  - Requirements: adicionar `Python >=3.12, uv`
  - Commands: adicionar `pnpm dev:ai` e explicar `pnpm dev` (agora usa concurrently)
  - Estrutura do monorepo: adicionar `services/ai/`
- [x] Atualizar `DEVELOPMENT.md` (se existir) com setup Python

**Definition of Done:**
- [x] `pnpm infra:up` verifica Python, instala deps via `uv sync`
- [x] `pnpm dev` inicia web (:3000) + api (:4000) + python (:8000) em paralelo
- [x] `curl http://localhost:8000/health` retorna 200
- [x] Request sem Bearer token retorna 401
- [x] CI passa: job Node (turbo) + job Python (ruff, mypy, pytest) em paralelo
- [x] `Ctrl+C` no `pnpm dev` mata todos os processos
- [x] `services/ai/` NÃƒO aparece em `pnpm-workspace.yaml` nem `pnpm-lock.yaml`

### Notas

_ConcluÃ­do em 2026-02-22._

**Melhorias sobre o plano original:**
- Adicionada dependÃªncia `psycopg[binary]` â€” necessÃ¡ria para `langgraph-checkpoint-postgres` funcionar sem `libpq` nativo instalado no sistema
- Dockerfile usa `COPY --from=ghcr.io/astral-sh/uv:latest /uv /uvx /bin/` em vez de `RUN pip install uv` â€” mais eficiente (layer de cache, sem pip)
- CI usa `astral-sh/setup-uv@v7` (plano dizia `@v5`, Context7 confirmou v7 como latest)
- `AsyncPostgresSaver.from_conn_string()` retorna context manager (`async with`) â€” validado via Context7 docs + source code inspection. Plano nÃ£o especificava esse detalhe
- Entradas Python adicionadas no `.gitignore` root em vez de criar `.gitignore` separado em `services/ai/` (jÃ¡ coberto pelo root)
- `README.md` gerado pelo `uv init` removido (desnecessÃ¡rio)
- Auth middleware implementado como `BaseHTTPMiddleware` do Starlette com `PUBLIC_PATHS` incluindo `/health`, `/docs`, `/openapi.json`, `/redoc`
- Testes do `@life-assistant/config` e `apps/api/test/setup.ts` atualizados para incluir `SERVICE_SECRET` nos fixtures (campo obrigatÃ³rio adicionado ao `envSchema`)

**VerificaÃ§Ã£o local:**
- Python: ruff check (0), ruff format (15 files OK), mypy (0 issues, 11 files), pytest (5/5)
- JS/TS: typecheck (10/10), lint (5/6 â€” web failure preexistente), test (5/6 â€” web failures preexistentes)
- Health endpoint: `curl localhost:8000/health` â†’ 200 `{"status":"ok","version":"0.1.0","database":"connected"}`
- Auth: endpoint sem Bearer â†’ 401, `/health` sem auth â†’ 200
- Isolamento: `services/ai/` nÃ£o aparece em `pnpm-workspace.yaml` nem `pnpm-lock.yaml`
- Concurrently rodando com flags corretos (`-k -p [{name}] -n turbo,ai -c blue,yellow`)

---

## M4.2 â€” SQLAlchemy Data Layer + RLS ğŸŸ¢

**Objetivo:** Python consegue ler/escrever no PostgreSQL com Row Level Security, mapeando tabelas do Drizzle.

**ReferÃªncias:** `docs/ai-python-service-migration-plan.md` Â§8, `docs/specs/core/data-conventions.md`, `docs/specs/core/auth-security.md`

**DependÃªncias:** M4.1

> **Contexto:** Drizzle (NestJS) Ã© o source of truth para schema e migrations. SQLAlchemy models sÃ£o mapeamentos passivos â€” nÃ£o geram migrations. PostgreSQL garante integridade via constraints, foreign keys e RLS policies independente de qual ORM escreve.

**Tasks:**

**Engine + Session:**
- [x] Criar `app/db/engine.py`:
  - `create_async_engine("postgresql+asyncpg://...")` com pool config
  - `async_sessionmaker(engine, expire_on_commit=False)` â€” `expire_on_commit=False` obrigatÃ³rio para evitar lazy-loading I/O em async
- [x] Criar `app/db/session.py` â€” context managers RLS-aware que executam `SET LOCAL request.jwt.claim.sub = '{user_id}'` antes de cada operaÃ§Ã£o (matching NestJS `set_config('request.jwt.claim.sub', ...)` e RLS policies que usam `auth.uid()`)
  - Deve ser **obrigatÃ³rio** â€” impossÃ­vel fazer query sem user_id setado
  - Testes que tentam query sem middleware devem falhar com RLS

**Models (mapeamento passivo das tabelas Drizzle):**
- [x] Criar `app/db/models/base.py` â€” `DeclarativeBase` + mixins comuns (`TimestampMixin`, `SoftDeleteMixin`)
- [x] Criar `app/db/models/enums.py` â€” Enums Python (`StrEnum`) espelhando os PostgreSQL `CREATE TYPE` (22 enums usados pelas tabelas modeladas)
- [x] Criar `app/db/models/users.py` â€” `users`, `user_memories` (read-only para Python)
- [x] Criar `app/db/models/tracking.py` â€” `tracking_entries`, `custom_metric_definitions`, `habits`, `habit_completions`
- [x] Criar `app/db/models/finance.py` â€” `incomes`, `bills`, `variable_expenses`, `debts`, `debt_payments`, `investments`, `budgets`
- [x] Criar `app/db/models/memory.py` â€” `knowledge_items`, `memory_consolidations`
- [x] Criar `app/db/models/chat.py` â€” `conversations`, `messages`
- [x] Todos os `Numeric` fields com `asdecimal=False` na definiÃ§Ã£o do model (retorna `float` ao invÃ©s de `Decimal`):
  ```python
  amount = mapped_column(Numeric(precision=12, scale=2, asdecimal=False))  # â†’ float
  ```

> **NUNCA criar SQLAlchemy models para tabelas de checkpoint do LangGraph** (`checkpoints`, `checkpoint_blobs`, `checkpoint_writes`, `checkpoint_migrations`). Essas tabelas sÃ£o gerenciadas exclusivamente pelo `AsyncPostgresSaver.setup()` chamado no lifespan do FastAPI (M4.1).

**Repositories:**
- [x] Criar `app/db/repositories/tracking.py` â€” TrackingRepository (create, find, aggregate, update, delete)
- [x] Criar `app/db/repositories/finance.py` â€” FinanceRepository (summary, bills, expenses, incomes, investments, debts)
- [x] Criar `app/db/repositories/memory.py` â€” MemoryRepository (search knowledge, add knowledge, get user memories)
- [x] Criar `app/db/repositories/chat.py` â€” ChatRepository (save message, get history, get conversation)
- [x] Criar `app/db/repositories/user.py` â€” UserRepository (get user, get settings â€” read-only)

**Schema Drift CI Check:**
- [x] Criar script `services/ai/scripts/check_schema_drift.py`:
  - Conecta ao DB, lÃª `information_schema` real
  - Compara com SQLAlchemy models declarados
  - Falha se tabela/coluna/tipo existir no DB mas nÃ£o no model (ou vice-versa)
- [x] Integrar no CI: roda a cada PR que toca `packages/database/src/schema/` ou `services/ai/app/db/models/`

**Testes:**
- [x] Teste de integraÃ§Ã£o: RLS impede User A de ler dados do User B
- [x] Teste de integraÃ§Ã£o: DECIMAL fields retornam `float`, nÃ£o `Decimal`
- [x] Teste de integraÃ§Ã£o: CRUD completo em cada repository (tracking, finance, memory, chat)
- [x] Teste: session RLS rejeita session sem user_id

**Definition of Done:**
- [x] Python lÃª/escreve em todas as tabelas necessÃ¡rias
- [x] RLS funciona: user A nÃ£o vÃª dados de user B
- [x] DECIMAL â†’ float em todas as queries
- [x] CI detecta schema drift quando Drizzle muda e SQLAlchemy nÃ£o acompanha
- [x] Testes de integraÃ§Ã£o passam

> **Riscos:**
> - DECIMAL handling: Drizzle retorna **string**, SQLAlchemy retorna **`Decimal`** por default. SoluÃ§Ã£o: usar `Numeric(asdecimal=False)` em todos os money fields nos models SQLAlchemy. Testes de integraÃ§Ã£o que comparam outputs dos dois ORMs para as mesmas queries.
> - RLS com SQLAlchemy async pode ter edge cases com connection pooling (`expire_on_commit=False` Ã© obrigatÃ³rio). Testar com mÃºltiplos users concorrentes.
> - Concurrent writes: ambos os serviÃ§os escrevem na mesma tabela (ex: `tracking_entries`). Usar `ON CONFLICT` / upsert patterns. Idempotency keys para write operations via chat.

### Notas

_ConcluÃ­do em 2026-02-23._

**Melhorias sobre o plano original:**
- RLS implementado como context managers em `app/db/session.py` (`get_user_session`, `get_service_session`) em vez de middleware HTTP (`app/db/middleware.py` no plano original). Context managers sÃ£o mais seguros â€” garantem que `SET LOCAL` e a transaÃ§Ã£o estejam sempre no mesmo escopo, e permitem uso direto em workers/scripts sem depender do ciclo HTTP. `get_service_session()` adicional para worker jobs que bypassam RLS via `SET LOCAL role = 'service_role'`
- 22 enums implementados (dos 30 no DB) â€” apenas os referenciados pelas tabelas que Python modela. Enums nÃ£o utilizados (ex: `vault_item_type`, `notification_type`, `export_status`) ficam de fora atÃ© que Python precise dessas tabelas
- Colunas `metadata` nos modelos `TrackingEntry`, `Conversation` e `Message` renomeadas no Python (`entry_metadata`, `conversation_metadata`, `message_metadata`) com mapeamento explÃ­cito `mapped_column("metadata", JSON)` porque `metadata` Ã© atributo reservado do `DeclarativeBase` do SQLAlchemy. A coluna no banco continua `metadata`
- `app/main.py` refatorado para usar `get_async_engine()` e `get_session_factory()` do novo mÃ³dulo `app/db/engine`, com `session_factory` armazenado em `app.state`
- `app/dependencies.py` estendido com `get_db_session()` que injeta sessÃ£o RLS-scoped via FastAPI `Depends()`
- Schema drift check integrado no job `e2e` do CI (apÃ³s migrations, antes do build) â€” requer Supabase rodando, por isso roda no e2e e nÃ£o no job `python`
- Testes de integraÃ§Ã£o (RLS + repositories) usam flag `--run-db` e sÃ£o skipped automaticamente no CI sem Supabase. 16 testes unitÃ¡rios (models) passam sem DB

**VerificaÃ§Ã£o local:**
- Python: ruff check (0 errors), ruff format (34 files OK), mypy (0 issues, 26 files), pytest (16 passed, 14 skipped)
- JS/TS: typecheck (10/10 cached) â€” nenhuma regressÃ£o

---

## M4.3 â€” LangGraph Basic Chat + NestJS Proxy ğŸŸ¢

**Objetivo:** Primeira mensagem end-to-end pelo Python service: Frontend â†’ NestJS â†’ Python â†’ resposta. Chat funcional sem tools.

**ReferÃªncias:** `docs/ai-python-service-migration-plan.md` Â§2, Â§4, Â§9

**DependÃªncias:** M4.2

> **Contexto:** Este milestone estabelece o "pipe" completo. Depois que mensagens fluem end-to-end, os milestones seguintes adicionam tools incrementalmente. O frontend NÃƒO muda â€” NestJS proxeia SSE transparentemente.

**Tasks:**

**LangGraph Core:**
- [x] Criar `app/agents/state.py` â€” `AgentState` TypedDict:
  ```python
  class AgentState(TypedDict):
      messages: Annotated[list, add_messages]
      user_id: str
      conversation_id: str
      current_agent: str | None
  ```
- [x] Criar `app/agents/llm.py` â€” LLM factory baseado em `LLM_PROVIDER` env (Gemini/Anthropic)
- [x] Criar `app/agents/domains/general.py` â€” agente conversacional (sem tools, sÃ³ responde)
  - Usa LLM factory (model configurÃ¡vel via `LLM_MODEL` env, default `gemini-2.5-flash`)
- [x] Criar `app/agents/graph.py` â€” StateGraph bÃ¡sico:
  - START â†’ general_agent â†’ save_response â†’ END
  - `AsyncPostgresSaver` como checkpointer (persistÃªncia de threads)
  - Import: `from langgraph.checkpoint.postgres.aio import AsyncPostgresSaver`
  - `.setup()` chamado no lifespan do FastAPI (M4.1) â€” cria tabelas `checkpoints`, `checkpoint_blobs`, `checkpoint_writes`, `checkpoint_migrations`
- [x] Criar `app/agents/save_response.py` â€” node que salva mensagem do assistente no DB via SQLAlchemy

**Context Builder (versÃ£o simplificada):**
- [x] Criar `app/prompts/system.py` â€” system prompt base:
  - Nome do usuÃ¡rio, timezone, data atual
  - Personalidade conforme `docs/specs/core/ai-personality.md`
- [x] Criar `app/prompts/context_builder.py` (versÃ£o mÃ­nima):
  - User memories formatadas do `user_memories` table
  - Apenas campos essenciais: bio, goals, topOfMind
  - Context builder completo serÃ¡ expandido em M4.6

**SSE Streaming (via `sse-starlette`):**
- [x] Criar `app/api/routes/chat.py`:
  - POST `/chat/invoke` â€” recebe `{ user_id, conversation_id, message }`, retorna SSE stream
  - Usar `EventSourceResponse` de `sse-starlette` (FastAPI nÃ£o tem SSE built-in)
  - SSE events compatÃ­veis com formato atual do frontend:
    - `{ data: { content: "...", done: false } }` â€” text delta
    - `{ data: { content: "...", done: true } }` â€” resposta final
    - `{ data: { content: "", done: true, error: "..." } }` â€” erro (matching NestJS format)
- [x] Carregar histÃ³rico de mensagens do DB quando nÃ£o existe checkpoint (conversas originadas no TypeScript)

**NestJS Proxy:**
- [x] Consumir `pythonAiSchema` no API module via `AppConfigService` (getters: `pythonAiUrl`, `serviceSecret`, `usePythonAi`)
- [x] Criar mÃ©todo `proxyToPython()` no `chat.service.ts`:
  - POST para Python `/chat/invoke` com Bearer `SERVICE_SECRET`
  - Parseia SSE stream do Python via `ReadableStream` reader e emite para o frontend
- [x] Quando `USE_PYTHON_AI=true`: proxy para Python. Quando `false`: usa lÃ³gica TypeScript atual

**Testes:**
- [x] Teste E2E: enviar mensagem simples â†’ receber resposta via Python (SSE streaming)
- [x] Teste: save response node persiste mensagem no DB
- [x] Teste: context builder inclui user memories no system prompt
- [x] Teste: feature flag alterna corretamente entre TypeScript e Python
- [x] Teste: frontend recebe SSE events no formato esperado (sem mudanÃ§as no frontend)

**Definition of Done:**
- [x] Com `USE_PYTHON_AI=true`, chat funciona end-to-end pelo Python (sem tools)
- [x] Com `USE_PYTHON_AI=false`, sistema TypeScript continua funcionando normalmente
- [x] Frontend nÃ£o percebe diferenÃ§a (mesmos SSE events)
- [x] Mensagens sÃ£o salvas no DB pelo Python

> **DecisÃ£o tomada:** Feature flag via environment variable (`USE_PYTHON_AI`), jÃ¡ definida em `packages/config/src/schemas/python-ai.ts`.

**Notas (2026-02-23):**
ImplementaÃ§Ã£o completa do pipe Python end-to-end. **Python (16 arquivos criados, 2 modificados):** `app/agents/` (state.py, llm.py, graph.py, save_response.py, domains/general.py) â€” StateGraph com `general_agent â†’ save_response`, `AsyncPostgresSaver` checkpointer, LLM factory suportando Gemini + Anthropic via `LLM_PROVIDER` env. `app/prompts/` (system.py, context_builder.py) â€” system prompt completo com personalidade Â§4, guardrails Â§7 (CVV 188, Ligue 180), counselor mode Â§5.1, user memories (bio, occupation, family, goals, challenges, topOfMind, values, communication_style). `app/api/routes/chat.py` â€” POST `/chat/invoke` com `EventSourceResponse`, checkpoint-or-DB-fallback para conversas originadas no TypeScript (carrega histÃ³rico do DB se checkpoint nÃ£o existe), `convert_db_messages()` com IDs preservados para dedup do `add_messages` reducer, `await request.is_disconnected()` para disconnect detection. Error SSE retorna mensagem genÃ©rica "Erro ao gerar resposta" (nÃ£o vaza `str(e)` ao cliente). Modificados: `app/main.py` (build graph no lifespan + registra chat router), `app/dependencies.py` (get_checkpointer helper). Reusa cÃ³digo existente de M4.2: `get_user_session()` (RLS), `ChatRepository`, `UserRepository`, `get_settings()`. **NestJS (3 arquivos modificados):** `config.service.ts` (3 getters: pythonAiUrl, serviceSecret, usePythonAi), `chat.service.ts` (`AppConfigService` injetado como 1Âº param do constructor + feature flag check no topo de `processStreamResponse()` + `proxyToPython()` com native `fetch` + `ReadableStream` reader para SSE parsing + `reader.releaseLock()` no finally), `chat.service.spec.ts` (mock do `AppConfigService` com `usePythonAi: false`). **Testes:** 26 Python (pytest) â€” test_llm_factory (4), test_agents (4), test_context_builder (6), test_chat_endpoint (5), test_graph (2), conftest + existing (5). 853 NestJS (jest). Todos passando. `ruff check .` + `mypy app/` + `pnpm typecheck` + `pnpm lint` limpos.

---

## M4.4 â€” Tracking Tools + Habits + Confirmation Framework ğŸŸ¢

**Objetivo:** Primeiros tools funcionando no Python com confirmaÃ§Ã£o via `interrupt()`. Tracking Ã© o domÃ­nio mais simples â€” ideal para validar o framework.

**ReferÃªncias:** `docs/ai-python-service-migration-plan.md` Â§4.5, `docs/specs/domains/tracking.md`, `ADR-015`

**DependÃªncias:** M4.3

> **Contexto:** O framework de confirmaÃ§Ã£o com `interrupt()` / `Command(resume=)` do LangGraph (import de `langgraph.types`) substitui o sistema atual de Redis TTL (5 min) do `confirmation-state.service.ts`. A persistÃªncia passa a ser via PostgreSQL (`AsyncPostgresSaver`), sem TTL por default. Isso Ã© uma **melhoria**: confirmaÃ§Ãµes nÃ£o expiram, sobrevivem a crashes do processo, e o thread pode ser retomado a qualquer momento. Este milestone valida o padrÃ£o que serÃ¡ usado por todos os write tools.
>
> **MudanÃ§a de infra:** Confirmation state migra de Redis (ioredis SETEX 5min) â†’ PostgreSQL (LangGraph checkpoint tables). Python **nÃ£o precisa de Redis** para confirmaÃ§Ãµes.

**Tasks:**

**Confirmation Framework:**
- [x] Criar `app/tools/common/confirmation.py`:
  - Wrapper de `interrupt()` que padroniza o formato de confirmaÃ§Ã£o
  - `generate_confirmation_message()` â€” mensagens em PT (ex: "Registrar peso: 75 kg em 2026-02-23?")
  - `generate_batch_confirmation_message()` â€” batch (ex: "Remover 3 registros?")
  - Constraint de idempotÃªncia documentada: cÃ³digo antes de `interrupt()` re-executa no resume â€” sem side effects antes do interrupt
  - `expiresAt` = now + 24h (soft limit â€” checkpoints PostgreSQL nÃ£o expiram, frontend usa para UX)
- [x] Criar `app/tools/common/confirmable_tool_node.py` â€” `ConfirmableToolNode`:
  - Substitui `ToolNode` do `create_react_agent` para agents com WRITE tools
  - Separa READ tools (executa imediatamente) de WRITE tools (batch em Ãºnico `interrupt()`)
  - 3 aÃ§Ãµes no resume: `confirm` (executa), `reject` (cancela), `edit` (corrige args e executa)
  - Emite SSE events `tool_calls` (antes) e `tool_result` (apÃ³s cada tool)
- [x] Adicionar endpoint POST `/chat/resume` em `app/api/routes/chat.py`:
  - Recebe `{ thread_id, action: "confirm" | "reject" | "edit", edited_args?: dict }`
  - Executa `Command(resume={"action": ..., "args": ...})`
  - Retorna SSE stream com resultado (reutiliza lÃ³gica de streaming)
- [x] Atualizar streaming em `app/api/routes/chat.py`:
  - `stream_mode="messages"` â†’ `stream_mode=["messages", "updates"]` para detectar `__interrupt__`
  - Chunks "updates" com `__interrupt__` â†’ SSE `confirmation_required` + `{ done: true, awaitingConfirmation: true }`
  - Chunks "updates" com tool data â†’ SSE `tool_calls` e `tool_result`
- [x] Implementar detecÃ§Ã£o de confirmaÃ§Ã£o por mensagem em `/chat/invoke`:
  - Verificar interrupt pendente via `graph.get_state(config)` antes de processar
  - Classificar intent via LLM: confirm / reject / correction / unrelated
  - Confirm â†’ `Command(resume={"action": "confirm"})`; Reject â†’ `Command(resume={"action": "reject"})`
  - Correction â†’ `Command(resume={"action": "edit", "args": corrected_args})`
  - Unrelated â†’ rejeitar pendente + processar como nova mensagem
- [x] **NestJS:** Proxy de confirmaÃ§Ã£o para Python:
  - `confirm/:confirmationId` â†’ Python `/chat/resume` action "confirm"
  - `reject/:confirmationId` â†’ Python `/chat/resume` action "reject"
  - Proxy SSE response de volta ao frontend
- [x] SSE event `confirmation_required` compatÃ­vel com frontend atual:
  ```json
  {
    "type": "confirmation_required",
    "data": {
      "confirmationId": "uuid",
      "toolName": "record_metric",
      "toolArgs": { "type": "water", "value": 2000 },
      "message": "Registrar Ã¡gua: 2000ml em 2026-02-22",
      "expiresAt": "ISO string"
    }
  }
  ```
- [x] SSE event `tool_result` apÃ³s execuÃ§Ã£o:
  ```json
  { "type": "tool_result", "data": { "toolName": "record_metric", "result": "...", "success": true } }
  ```

**Tracking Tools (4 tools):**
- [x] Criar `app/tools/tracking/record_metric.py` â€” registra mÃ©trica (WRITE, confirmation)
  - Params: metric_type, value, date (opcional, default hoje), unit (opcional, auto-fill), notes (opcional)
  - ValidaÃ§Ã£o de ranges por tipo (weight 0.1â€“500, water 1â€“20000, mood 1â€“10, sleep 0.1â€“24, etc.)
  - Mapeamento automÃ¡tico metric_type â†’ area/sub_area (ex: weightâ†’health/physical, moodâ†’health/mental)
  - Usa TrackingRepository para INSERT, retorna JSON com entryId
- [x] Criar `app/tools/tracking/get_history.py` â€” histÃ³rico de mÃ©tricas (READ)
  - Params: metric_type, days (opcional, default 30)
  - Retorna entries com UUIDs (para update/delete), stats (count, avg, min, max, sum, trend), variaÃ§Ã£o %
  - Inclui `_note` instruindo o LLM a usar IDs exatos para update/delete
- [x] Criar `app/tools/tracking/update_metric.py` â€” atualiza mÃ©trica existente (WRITE, confirmation)
  - Params: entry_id (UUID exato), value, unit (opcional), reason (opcional â€” audit trail)
  - Ownership verificada via RLS (SET LOCAL request.jwt.claim.sub)
- [x] Criar `app/tools/tracking/delete_metric.py` â€” deleta mÃ©trica (WRITE, confirmation)
  - Params: entry_id (UUID exato), reason (opcional)
  - Delete individual (batch removido â€” LLM alucinava IDs em batch, mesma decisÃ£o do TypeScript M2.1)

**Habit Tools (2 tools):**
- [x] Criar `app/tools/tracking/record_habit.py` â€” registra hÃ¡bito (WRITE, confirmation)
  - Params: habit_name, date (opcional, default hoje), notes (opcional)
  - Fuzzy match por nome: exact case-insensitive â†’ contains bidirecional
  - DetecÃ§Ã£o de duplicata (jÃ¡ completado na data), cÃ¡lculo de streak apÃ³s registro
- [x] Criar `app/tools/tracking/get_habits.py` â€” lista hÃ¡bitos (READ)
  - Params: include_streaks (bool, default true), include_today_status (bool, default true)
  - Retorna hÃ¡bitos com streak atual, longest streak, status de hoje

> **Nota:** `analyze_context` estÃ¡ mapeado para o executor `'memory'` no cÃ³digo (chat.service.ts:121), nÃ£o tracking. Esse tool Ã© implementado em M4.6 (Memory Tools).

**Tracking Agent:**
- [x] Criar `app/agents/domains/tracking.py`:
  - Exporta `TRACKING_TOOLS` (6 tools) e `TRACKING_WRITE_TOOLS` (4 nomes) para uso pelo graph builder
  - Graph construÃ­do via `build_domain_agent_graph()` factory reutilizÃ¡vel (agent_factory.py)
  - System prompt vem do context_builder.py (centralizado, nÃ£o embarcado no agente)
- [x] Atualizar graph principal: `build_domain_agent_graph(llm, TRACKING_TOOLS, TRACKING_WRITE_TOOLS, checkpointer)`
  - Grafo: agent â†’ should_continue â†’ tools (ConfirmableToolNode) â†’ agent (loop) ou save_response â†’ END
  - Loop guard em agent_node previne Gemini de re-chamar WRITE tool apÃ³s sucesso (forÃ§a resposta textual)

**Confirmation Flow Hardening (bugs encontrados durante E2E testing):**
- [x] Salvar mensagem de confirmaÃ§Ã£o no DB ao detectar `__interrupt__` no stream (espelha NestJS L1189-1201)
  - Mensagem persiste apÃ³s page refresh. Metadata inclui `pendingConfirmation` (confirmationId, toolName, toolArgs)
- [x] Reject usa `graph.ainvoke()` em vez de `graph.astream()` â€” resposta curta enviada como evento SSE Ãºnico
  - Corrige bug onde resposta de rejeiÃ§Ã£o nÃ£o aparecia no frontend (perdia-se no pipeline streaming multi-camada)
- [x] Loop guard para re-chamada de WRITE tools â€” Gemini chamava `record_metric` em loop apÃ³s sucesso
  - Detecta ToolMessage de WRITE tool seguida de nova chamada ao mesmo tool; forÃ§a AIMessage textual
- [x] Guard de content blocks vazios do Gemini â€” `[{"type":"text","text":""}]` Ã© truthy mas sem conteÃºdo
  - `tokens_streamed` sÃ³ Ã© setado como `True` quando token extraÃ­do Ã© non-empty
- [x] `skip_save_response` para intent "unrelated" â€” rejeiÃ§Ã£o silenciosa nÃ£o salva "OperaÃ§Ã£o cancelada" como mensagem separada
  - Nova mensagem do fluxo normal inclui menÃ§Ã£o ao cancelamento em resposta Ãºnica combinada
- [x] JSON format para ToolMessage de rejeiÃ§Ã£o â€” `json.dumps({"success": False, "message": "..."})` em vez de plain text
  - Gemini interpretava plain text como resultado de tool a ser re-processado
- [x] Frontend: safety net `useEffect` em `use-chat.ts` â€” quando `done:true` chega sem streaming content, chama `finishStreaming()` diretamente
  - Cobre edge case onde backend termina sem ter feito stream de tokens (ex: resposta via ainvoke)

**Testes:**
- [x] Teste: pipeline SSE de interrupt â€” salva confirmaÃ§Ã£o no DB (`test_invoke_interrupt_saves_confirmation_to_db`), reject via ainvoke envia content (`test_invoke_reject_uses_ainvoke_and_sends_content`). Nota: testa pipeline de streaming, nÃ£o o tool record_metric com ConfirmableToolNode end-to-end (coberto por E2E manual)
- [x] Teste: get_tracking_history retorna dados corretos (`test_get_history_returns_formatted_entries`)
- [x] Teste: update_metric retorna erro quando entry nÃ£o existe (`test_update_metric_not_found`). Nota: ownership real Ã© garantida por RLS (`SET LOCAL`) mas nÃ£o hÃ¡ teste de integraÃ§Ã£o com 2 users â€” requer DB real
- [x] Teste: record_habit com fuzzy match de nome (`test_record_habit_fuzzy_matching`, `test_record_habit_already_completed`)
- [x] Teste: SSE events de confirmaÃ§Ã£o compatÃ­veis com frontend (`test_invoke_interrupt_saves_confirmation_to_db`, `test_resume_confirm_returns_sse`)
- [x] Teste: flow completo "Registra 2L de Ã¡gua hoje" end-to-end (verificaÃ§Ã£o manual â€” 4 cenÃ¡rios: confirm, reject, unrelated, e rejectâ†’re-registerâ†’confirm)
- [x] Teste: loop guard previne re-chamada de WRITE tool (`test_loop_guard_breaks_write_tool_re_call`)
- [x] Teste: empty Gemini blocks nÃ£o escondem loop guard (`test_invoke_empty_gemini_blocks_do_not_shadow_loop_guard`)
- [x] Teste: DB failure no interrupt nÃ£o quebra stream (`test_invoke_interrupt_db_failure_still_streams`)

**Definition of Done:**
- [x] "Registra 2L de Ã¡gua hoje" funciona end-to-end pelo Python (card de confirmaÃ§Ã£o no frontend)
- [x] ConfirmaÃ§Ã£o, rejeiÃ§Ã£o, mensagem nÃ£o-relacionada e re-registro funcionam corretamente
- [x] Dados escritos pelo Python aparecem no dashboard (persistem apÃ³s page refresh)
- [x] Todos os 6 tools passam em testes isolados (82 passed, 14 skipped)

### Notas

_ConcluÃ­do em 2026-02-23._

**Desvios do plano original:**
- `delete_metric` batch removido do tool (repositÃ³rio mantÃ©m `delete_batch()` para uso futuro). DecisÃ£o alinhada com TypeScript M2.1 â€” LLM alucinava IDs quando recebia operaÃ§Ã£o batch. Chamadas paralelas de `delete_metric` individual com UUIDs reais do `get_history` Ã© mais confiÃ¡vel
- `update_metric` nÃ£o suporta alteraÃ§Ã£o de `entry_date` (plano previa). Params reais: `entry_id`, `value`, `unit?`, `reason?`. `reason` adiciona audit trail de correÃ§Ãµes
- `record_habit` sem param `completed` (plano previa). Sempre registra como concluÃ­do â€” "registrar hÃ¡bito" no chat implica completude. Param `notes` adicionado
- Tracking agent implementado como bridge (`tracking.py` exporta tools/write_tools) + factory reutilizÃ¡vel (`agent_factory.py`) em vez de graph customizado por domÃ­nio. Factory serÃ¡ reusada por M4.5 (Finance) e M4.6 (Memory) sem duplicaÃ§Ã£o

**Melhorias sobre o plano original:**
- `record_metric` inclui validaÃ§Ã£o de ranges por tipo (weight 0.1â€“500 kg, water 1â€“20000 ml, mood 1â€“10, etc.) â€” nÃ£o previsto no plano
- `get_history` retorna estatÃ­sticas completas (count, avg, min, max, sum, trend, variaÃ§Ã£o %) + `_note` instruindo LLM a usar IDs exatos â€” nÃ£o previsto no plano
- `get_habits` retorna streaks (atual e recorde) e status de hoje com params configurÃ¡veis â€” excede spec original
- `build_domain_agent_graph()` factory em `agent_factory.py` â€” pattern reutilizÃ¡vel com agent â†’ ConfirmableToolNode â†’ agent loop + save_response, compilado com checkpointer. Elimina duplicaÃ§Ã£o para M4.5/M4.6
- Loop guard no agent_node â€” detecta quando Gemini re-chama WRITE tool apÃ³s ToolMessage de sucesso e forÃ§a resposta textual. Essencial para estabilidade com Gemini
- 7 bugs de confirmation flow descobertos e corrigidos durante E2E testing (vide seÃ§Ã£o "Confirmation Flow Hardening")
- Frontend `use-chat.ts` safety net â€” `useEffect` que detecta `done:true` sem conteÃºdo streamed e chama `finishStreaming()` direto

**VerificaÃ§Ã£o local:**
- Python: ruff check (0 errors), mypy (0 issues, 51 files), pytest (82 passed, 14 skipped)
- TypeScript: typecheck compilado sem erros
- E2E manual: 4 cenÃ¡rios testados (confirm, reject, unrelated intent, rejectâ†’re-registerâ†’confirm) â€” todos funcionando

---

## M4.5 â€” Finance Tools ğŸ”´

**Objetivo:** Todos os 11 tools financeiros migrados para Python. Maior executor em linhas de cÃ³digo (~1.047L no TypeScript).

**ReferÃªncias:** `docs/specs/domains/finance.md`, `apps/api/src/modules/finance/application/services/finance-tool-executor.service.ts`

**DependÃªncias:** M4.4

> **Contexto:** O `finance-tool-executor.service.ts` Ã© o maior executor (1.047 linhas) com lÃ³gica complexa de agregaÃ§Ã£o, cÃ¡lculos mensais, projeÃ§Ãµes e breakdown por categoria. Requer atenÃ§Ã£o especial ao handling de DECIMAL (string no Drizzle, float no Python).

**Tasks:**

**Finance Tools â€” Shared Helpers:**
- [x] Criar `app/tools/finance/_helpers.py` â€” TZ utils + ensure_recurring
  - FunÃ§Ãµes: get_current_month_tz, get_today_tz, get_days_until_due_day, resolve_month_year, get_previous_month, months_diff
  - `ensure_recurring_for_month()` â€” geraÃ§Ã£o lazy de itens recorrentes (bills, incomes, expenses)
- [x] Adicionar mÃ©todos ao `app/db/repositories/finance.py`:
  - get_debt_by_id, get_debt_payments_for_debts (batch), sum_payments_by_month_year

**Finance Tools â€” READ (9 tools):**
- [x] Criar `app/tools/finance/get_finance_summary.py` â€” resumo financeiro mensal
  - Params: period (Literal["current_month", "last_month", "year"], default: "current_month")
  - Retorna: KPIs (income, budgeted, spent, balance), breakdown por entidade, ensure_recurring para 3 tabelas
- [x] Criar `app/tools/finance/get_pending_bills.py` â€” contas pendentes
  - Params: month, year (opcionais, default: mÃªs atual via TZ)
  - Retorna: bills com status pending, daysUntilDue, reclassifica overdue, ensure_recurring
- [x] Criar `app/tools/finance/get_bills.py` â€” todas as contas com status
  - Params: month, year, status (opcionais, status default: "all")
  - Retorna: lista de bills com paid/pending/overdue, daysUntilDue, ensure_recurring
- [x] Criar `app/tools/finance/get_expenses.py` â€” despesas variÃ¡veis
  - Params: month, year (opcionais)
  - Retorna: lista de expenses com variance, percentUsed, ensure_recurring
- [x] Criar `app/tools/finance/get_incomes.py` â€” receitas
  - Params: month, year (opcionais)
  - Retorna: lista de incomes com variance, receivedCount/pendingCount, ensure_recurring
- [x] Criar `app/tools/finance/get_investments.py` â€” investimentos
  - Params: nenhum
  - Retorna: lista com progress, remainingToGoal, monthsToGoal
- [x] Criar `app/tools/finance/get_debt_progress.py` â€” progresso de dÃ­vidas
  - Params: debt_id (opcional), month_year (opcional, YYYY-MM)
  - Retorna: total pago, percentual, parcelas restantes, projeÃ§Ã£o de quitaÃ§Ã£o, regras de visibilidade Â§3.6
- [x] Criar `app/tools/finance/get_debt_payment_history.py` â€” histÃ³rico de pagamentos de dÃ­vida
  - Params: debt_id (obrigatÃ³rio), limit (opcional, default 50)
  - Retorna: lista de pagamentos com paidEarly flag, contexto da dÃ­vida
- [x] Criar `app/tools/finance/get_upcoming_installments.py` â€” prÃ³ximas parcelas
  - Params: month_year (opcional, YYYY-MM, default: mÃªs atual)
  - Retorna: installments com status (paid/paid_early/overdue/pending), regras de visibilidade Â§3.6

**Finance Tools â€” WRITE (2 tools):**
- [ ] Criar `app/tools/finance/mark_bill_paid.py` â€” marcar conta como paga (WRITE, confirmation)
  - Params: bill_id, paid_date (opcional, default: hoje)
  - Verifica que bill pertence ao user e estÃ¡ pendente
- [ ] Criar `app/tools/finance/create_expense.py` â€” criar despesa variÃ¡vel (WRITE, confirmation)
  - Params: description, amount, category, date (opcional)
  - Mapeamento de categorias PTâ†’EN preservado (alimentacaoâ†’food, transporteâ†’transport, etc.)

**Finance Agent Bridge + Graph:**
- [x] Criar `app/agents/domains/finance.py` â€” bridge (re-export FINANCE_TOOLS, FINANCE_WRITE_TOOLS)
- [x] Atualizar `app/agents/graph.py` â€” merge finance + tracking tools no grafo Ãºnico

**LÃ³gica de agregaÃ§Ã£o:**
- [x] Implementar cÃ¡lculos mensais: income - expenses - bills = balance
- [x] Implementar breakdown por categoria com percentuais
- [x] Implementar projeÃ§Ãµes baseadas em histÃ³rico
- [x] Garantir que todos os cÃ¡lculos usam `float` (nÃ£o `Decimal` nem `string`)

**Testes:**
- [x] Teste: cada READ tool isoladamente com mocks (41 testes)
- [x] Teste: get_finance_summary com KPI aggregation e breakdown correto
- [x] Teste: helpers TZ (20 testes) + ensure_recurring (4 testes)
- [ ] Teste: mark_bill_paid com confirmaÃ§Ã£o
- [ ] Teste: create_expense com mapeamento de categoria PTâ†’EN
- [ ] Teste cross-ORM: mesma query financeira via Drizzle e SQLAlchemy retorna mesmos valores
- [ ] Teste: queries complexas ("quanto gastei com alimentaÃ§Ã£o este mÃªs?", "quais contas vencem esta semana?")

**Definition of Done:**
- [ ] Todos os 11 finance tools funcionam no Python
- [ ] Valores financeiros sÃ£o precisos (cross-ORM verification)
- [ ] ConfirmaÃ§Ã£o funciona para mark_bill_paid e create_expense
- [ ] Categorias PTâ†’EN mapeadas corretamente

**Notas (2026-02-23) â€” READ tools session:**
- 9 READ tools implementados: get_finance_summary, get_pending_bills, get_bills, get_expenses, get_incomes, get_investments, get_debt_progress, get_debt_payment_history, get_upcoming_installments
- `_helpers.py`: TZ utils (6 funÃ§Ãµes) + `ensure_recurring_for_month()` genÃ©rico para 3 entidades (Bill, Income, VariableExpense) via `_ENTITY_CONFIG` dict
- `__init__.py`: exports FINANCE_TOOLS (list de 9) e FINANCE_WRITE_TOOLS (set vazio, preparado para WRITE tools)
- Repository: +3 mÃ©todos (get_debt_by_id, get_debt_payments_for_debts batch com guard lista vazia, sum_payments_by_month_year com func.coalesce)
- Graph atualizado: ALL_TOOLS = TRACKING_TOOLS + FINANCE_TOOLS (15 tools total)
- `pyproject.toml`: adicionado `"app/tools/finance/*.py" = ["TCH002"]` per-file-ignores (RunnableConfig necessÃ¡rio em runtime, mesmo padrÃ£o de tracking)
- 41 testes unitÃ¡rios (mocked), 112 total suite passando (ruff + mypy + pytest limpos)
- CorreÃ§Ãµes do milestone: params alinhados com NestJS (period em vez de month/year para summary, month_year YYYY-MM para debts, limit para payment_history)
- E2E manual via Playwright: 9/9 tools testados com dados reais do seed, todos os valores conferem com o banco de dados
- VerificaÃ§Ã£o de tool calls via LangGraph checkpoints: confirmado que a IA chama tools corretamente (paralelo quando possÃ­vel, sequencial para resolver IDs como debt_id)
- WRITE tools (mark_bill_paid, create_expense) serÃ£o implementados na prÃ³xima sessÃ£o

---

## M4.6 â€” Memory Tools + Context Builder Completo ğŸ”´

**Objetivo:** Tools de memÃ³ria migrados e context builder completo (system prompt com todas as instruÃ§Ãµes de tools).

**ReferÃªncias:** `docs/specs/domains/memory.md`, `docs/specs/core/ai-personality.md` Â§4-8, `ADR-012`

**DependÃªncias:** M4.4

> **Nota:** Este milestone pode rodar **em paralelo** com M4.5 (Finance Tools).

**Tasks:**

**Memory Tools (3 tools):**
- [ ] Criar `app/tools/memory/search_knowledge.py` â€” busca em knowledge_items (READ)
  - Params: query, type (opcional), area (opcional), sub_area (opcional)
  - Busca por keyword/filtros em knowledge_items
- [ ] Criar `app/tools/memory/add_knowledge.py` â€” adicionar fato/preferÃªncia/insight (WRITE, confirmation)
  - Params: content, type (fact/preference/insight), area, sub_area (opcionais)
  - Detecta duplicatas antes de inserir
- [ ] Criar `app/tools/memory/analyze_context.py` â€” anÃ¡lise de contexto memÃ³ria (READ)
  - Params: query
  - Retorna knowledge_items relevantes para contexto da conversa

**Memory Agent:**
- [ ] Criar `app/agents/domains/memory.py`:
  - Graph customizado com `ConfirmableToolNode` (confirmation de write tools)
  - 3 tools (2 READ + 1 WRITE)
  - System prompt com regras de memÃ³ria (tipos de knowledge, Ã¡reas, quando adicionar vs buscar)

**Context Builder Completo:**
- [ ] Expandir `app/prompts/context_builder.py` (iniciado em M4.3):
  - User memories completas: bio, occupation, family, goals, challenges, topOfMind, values, learnedPatterns
  - Tool instructions completas (~88 linhas):
    - Memory tools: quando usar search_knowledge vs add_knowledge
    - Tracking tools: confirmaÃ§Ã£o obrigatÃ³ria, nunca inventar IDs, timezone do user
    - Finance tools: mapeamento de categorias, formataÃ§Ã£o monetÃ¡ria
    - Habits tools: match por nome, regras de registro
  - Regras explÃ­citas: "sempre confirme antes de registrar", "nunca invente IDs para update/delete"
  - Counselor mode: instruÃ§Ãµes especiais para conversas tipo "counselor"
- [ ] Integrar context builder no graph principal (substituir versÃ£o simplificada de M4.3)

**Testes:**
- [ ] Teste: search_knowledge com filtros por type/area
- [ ] Teste: add_knowledge com detecÃ§Ã£o de duplicata
- [ ] Teste: context builder produz system prompt equivalente ao TypeScript
- [ ] Teste: counselor mode altera instruÃ§Ãµes corretamente
- [ ] Teste: tool instructions estÃ£o presentes e completas no prompt

**Definition of Done:**
- [ ] Memory tools funcionam no Python
- [ ] Context builder produz system prompt completo e equivalente ao TypeScript
- [ ] "O que vocÃª sabe sobre mim?" retorna informaÃ§Ãµes corretas das user_memories

---

## M4.7 â€” Multi-Agent: Triage + Domain Routing ğŸ”´

**Objetivo:** Arquitetura multi-agente com triage inteligente roteando mensagens para agentes especializados.

**ReferÃªncias:** `docs/ai-python-service-migration-plan.md` Â§4

**DependÃªncias:** M4.4, M4.5, M4.6

> **Contexto:** AtÃ© este ponto, o graph usa um Ãºnico agente com todos os tools. Este milestone implementa a arquitetura final: triage node classifica a intenÃ§Ã£o e roteia para domain agents especializados. Isso permite usar modelo rÃ¡pido (Flash) para triagem e modelo capaz (Pro) para execuÃ§Ã£o, reduzindo custo e latÃªncia.

**Tasks:**

**Triage Node:**
- [ ] Criar `app/agents/triage.py`:
  - Usa modelo rÃ¡pido: `ChatGoogleGenerativeAI(model="gemini-2.0-flash")`
  - Triage prompt com exemplos de roteamento:
    - "Registra 2L de Ã¡gua" â†’ tracking_agent
    - "Quanto gastei este mÃªs?" â†’ finance_agent
    - "O que vocÃª sabe sobre mim?" â†’ memory_agent
    - "Estou me sentindo ansioso" â†’ wellbeing_agent
    - "Bom dia!" â†’ general_agent
  - Retorna `{ current_agent: "tracking_agent" | "finance_agent" | "memory_agent" | "wellbeing_agent" | "general_agent" }`

**Wellbeing Agent (novo):**
- [ ] Criar `app/agents/domains/wellbeing.py`:
  - Sem tools (modo counselor puro)
  - System prompt com instruÃ§Ãµes de counselor mode: reflexÃ£o profunda, perguntas exploratÃ³rias, menos emojis

**Graph Atualizado:**
- [ ] Atualizar `app/agents/graph.py`:
  - START â†’ triage â†’ conditional_edges â†’ [tracking_agent, finance_agent, memory_agent, wellbeing_agent, general_agent] â†’ save_response â†’ END
  - `route_to_agent()` baseado em `state["current_agent"]`
  - Fallback para `general_agent` quando triage retorna intenÃ§Ã£o desconhecida

**Agent Registry:**
- [ ] Cada domain agent usa graph customizado com `ConfirmableToolNode` (WRITE tools) ou `create_react_agent()` (agents sem tools):
  - `tracking_agent`: 6 tools (M4.4)
  - `finance_agent`: 11 tools (M4.5)
  - `memory_agent`: 3 tools (M4.6)
  - `wellbeing_agent`: 0 tools (counselor mode)
  - `general_agent`: 0 tools (conversacional)

> **Nota sobre `create_react_agent`:** Verificado via Context7 (Fev 2026): `create_react_agent` de `langgraph.prebuilt` Ã© a API estÃ¡vel atual. Sem evidÃªncia de deprecation. Usar `create_react_agent` para agents sem WRITE tools (general, wellbeing). Para agents com WRITE tools (tracking, finance, memory), usar graph customizado com `ConfirmableToolNode` para suportar batch confirmation.

**Testes:**
- [ ] Teste: 20+ mensagens classificadas corretamente pelo triage (cobrindo todos os 5 agents)
- [ ] Teste: mensagens ambÃ­guas caem no general_agent
- [ ] Teste: mensagens multi-domÃ­nio ("como estou financeiramente e na saÃºde?") â€” definir estratÃ©gia (rota para o primeiro, ou executa sequencialmente)
- [ ] Teste: wellbeing agent responde com tom de counselor
- [ ] Teste: triage com modelo Flash Ã© significativamente mais rÃ¡pido que Pro

**Definition of Done:**
- [ ] Mensagens sÃ£o roteadas para o agente correto
- [ ] Cada agente executa seus tools especializados
- [ ] Triage usa modelo rÃ¡pido, agents usam modelo capaz
- [ ] Fallback funciona para intenÃ§Ãµes ambÃ­guas

---

## M4.8 â€” Workers: Memory Consolidation + Contradiction Detection ğŸ”´

**Objetivo:** Migrar jobs assÃ­ncronos (memory consolidation, contradiction detection) para Python, mantendo BullMQ como scheduler.

**ReferÃªncias:** `docs/ai-python-service-migration-plan.md` Â§11 Fase 3, `docs/specs/domains/memory.md`

**DependÃªncias:** M4.6

> **Contexto:** `memory-consolidation.processor.ts` (557L) e `contradiction-detector.adapter.ts` (435L) usam LLM para extrair fatos de conversas e detectar contradiÃ§Ãµes. A estratÃ©gia recomendada Ã© manter BullMQ no NestJS como scheduler e chamar Python via HTTP para a lÃ³gica de AI. Isso minimiza mudanÃ§as na infraestrutura de jobs.

**Tasks:**

**Memory Consolidation:**
- [ ] Criar `app/workers/consolidation.py`:
  - Recebe: `{ user_id, timezone, date }`
  - Busca mensagens desde Ãºltima consolidaÃ§Ã£o (via ChatRepository)
  - Usa LLM para extrair fatos, preferÃªncias, insights das mensagens
  - Atualiza `user_memories`: bio, occupation, family, goals, challenges, topOfMind, values, learnedPatterns
  - Cria novos `knowledge_items` (com contradiction detection)
  - Atualiza `knowledge_items` existentes quando informaÃ§Ã£o evolui
  - Registra consolidation log em `memory_consolidations`
- [ ] Criar endpoint POST `/workers/consolidation` em `app/api/routes/workers.py`:
  - Auth via SERVICE_SECRET
  - Recebe job data, executa consolidation, retorna resultado
  - Retorna: `{ usersProcessed, usersConsolidated, usersSkipped, errors, completedAt }`

**Contradiction Detection:**
- [ ] Criar `app/memory/contradiction.py`:
  - Single item: "novo fato torna fato existente obsoleto?"
  - Batch items: check novo fato contra 3+ fatos existentes em uma chamada LLM
  - Parse JSON response do LLM com fallback para output truncado
  - Retorna: `{ is_contradiction, confidence, explanation }`
- [ ] Integrar com consolidation: antes de salvar knowledge_item, detectar contradiÃ§Ãµes

**NestJS Bridge:**
- [ ] Atualizar `memory-consolidation.processor.ts`:
  - Quando `USE_PYTHON_AI=true`: POST para Python `/workers/consolidation` via HTTP
  - Quando `false`: executa lÃ³gica TypeScript atual
  - BullMQ scheduler permanece no NestJS (sem mudanÃ§as no cron/trigger)

**Testes:**
- [ ] Teste: consolidation extrai fatos corretos de conversas
- [ ] Teste: contradictions detectadas (ex: "gosta de cafÃ©" â†’ "parou de tomar cafÃ©")
- [ ] Teste: user_memories atualizadas corretamente apÃ³s consolidation
- [ ] Teste: knowledge_items criados sem duplicatas
- [ ] Teste: endpoint /workers/consolidation retorna resultado esperado
- [ ] Teste: batch contradiction detection com mÃºltiplos fatos

**Definition of Done:**
- [ ] Consolidation job roda via BullMQ â†’ HTTP â†’ Python â†’ resultado
- [ ] Fatos extraÃ­dos corretamente de conversas
- [ ] Contradictions detectadas com confianÃ§a adequada
- [ ] Resultado equivalente ao sistema TypeScript

> **DecisÃ£o tomada:** NestJS BullMQ mantÃ©m o scheduling e chama Python via HTTP (opÃ§Ã£o A â€” menor mudanÃ§a). Existe um pacote oficial `bullmq` para Python (v2.19.5) com classe `Worker`, mas estÃ¡ classificado como **Alpha** e nÃ£o suporta todas as features do Node.js â€” por isso a decisÃ£o de manter o scheduler no NestJS. Se no futuro Python precisar de jobs prÃ³prios, considerar APScheduler ou Celery.
>
> **PadrÃ£o de comunicaÃ§Ã£o:** NestJS BullMQ (cron trigger + retry + job history) â†’ HTTP POST â†’ Python (AI/LLM execution logic) â†’ JSON response. BullMQ retry config permanece no NestJS â€” Python nÃ£o precisa implementar retry de job.

---

## M4.9 â€” Feature Parity + Parallel Validation ğŸ”´

**Objetivo:** Validar que o sistema Python produz resultados funcionalmente equivalentes ao TypeScript em todos os cenÃ¡rios antes de deletar cÃ³digo.

**ReferÃªncias:** Todos os milestones anteriores (M4.1-M4.8)

**DependÃªncias:** M4.7, M4.8

> **Contexto:** Este milestone Ã© uma "safety net" antes da limpeza. Roda ambos os sistemas em paralelo e compara resultados. Qualquer discrepÃ¢ncia Ã© corrigida antes de prosseguir para M4.10.

**Tasks:**

**Suite de Paridade (50+ cenÃ¡rios):**
- [ ] Mensagens simples:
  - "Bom dia" â†’ general agent responde
  - "Como vocÃª estÃ¡?" â†’ general agent
  - Conversa tipo counselor â†’ wellbeing agent
- [ ] Tracking com confirmaÃ§Ã£o:
  - "Registra 2L de Ã¡gua hoje" â†’ confirm â†’ verificar DB
  - "Registra 2L de Ã¡gua hoje" â†’ reject â†’ nada salvo
  - "Quanto peso eu registrei esta semana?" â†’ read â†’ dados corretos
  - "Apaga o registro de Ã¡gua de ontem" â†’ confirm â†’ delete
  - "Atualiza meu peso de hoje para 75kg" â†’ confirm â†’ update
  - "Registra que fiz exercÃ­cio hoje" â†’ confirm â†’ habit entry
- [ ] Finance queries:
  - "Quanto gastei este mÃªs?" â†’ summary correto
  - "Quais contas vencem esta semana?" â†’ pending bills
  - "Registra gasto de R$50 com almoÃ§o" â†’ confirm â†’ expense criada
  - "Marca conta de luz como paga" â†’ confirm â†’ bill updated
  - "Como estÃ£o minhas dÃ­vidas?" â†’ debt progress
- [ ] Memory:
  - "O que vocÃª sabe sobre mim?" â†’ user memories
  - "Lembra que eu prefiro cafÃ© sem aÃ§Ãºcar" â†’ confirm â†’ knowledge added
  - Busca em knowledge_items com filtros
- [ ] Multi-tool:
  - "Como estou financeiramente e na saÃºde?" â†’ mÃºltiplos agents/tools
- [ ] Edge cases:
  - Timeout de LLM â†’ error handling graceful
  - Tool nÃ£o encontrado â†’ error message
  - ConfirmaÃ§Ã£o apÃ³s 5+ minutos â†’ behavior correto (LangGraph checkpoints persistem em PostgreSQL sem TTL por default, diferente do Redis 5min anterior)
  - Mensagem vazia â†’ rejection ou resposta default

**SSE Event Compatibility:**
- [ ] Verificar que todos os SSE events emitidos pelo Python tÃªm o mesmo formato do TypeScript:
  - `tool_calls` (iteration, toolCalls array)
  - `tool_result` (toolName, result, success)
  - `confirmation_required` (confirmationId, toolName, toolArgs, message, expiresAt)
  - Final response `{ content, done: true }`
  - Error `{ content, done: true, error }`
  - `{ done: true, awaitingConfirmation: true }`
- [ ] Frontend funciona sem nenhuma mudanÃ§a de cÃ³digo

**Performance:**
- [ ] Load testing: 50 concurrent chat requests ao Python service
- [ ] Verificar latÃªncia do proxy NestJS â†’ Python (deve ser <50ms overhead)
- [ ] Verificar que triage com Flash model < 500ms
- [ ] Validar `InMemoryRateLimiter` do LangChain sob carga (single-process). Se insuficiente em produÃ§Ã£o com mÃºltiplos workers uvicorn, avaliar Redis-based rate limiter como melhoria futura

**Observabilidade:**
- [ ] Sentry configurado para Python service (error tracking)
- [ ] Structured logging (JSON) com request_id para correlaÃ§Ã£o com NestJS
- [ ] Health check inclui status do DB (Python nÃ£o depende de Redis)

**Testes:**
- [ ] Suite completa de paridade passa (50+ cenÃ¡rios)
- [ ] Frontend funciona sem mudanÃ§as
- [ ] Load test: sem erros em 50 concurrent requests
- [ ] Sentry captura erros do Python service

**Definition of Done:**
- [ ] Todos os cenÃ¡rios produzem resultados funcionalmente equivalentes
- [ ] Frontend funciona identicamente com `USE_PYTHON_AI=true` e `false`
- [ ] Performance aceitÃ¡vel sob carga
- [ ] Observabilidade configurada

---

## M4.10 â€” NestJS Cleanup + Production Deploy ğŸ”´

**Objetivo:** Deletar todo o cÃ³digo TypeScript AI obsoleto (~13.400 linhas), simplificar NestJS para proxy, deploy em produÃ§Ã£o.

**ReferÃªncias:** `docs/ai-python-service-migration-plan.md` Â§5, Â§7, Â§12

**DependÃªncias:** M4.9

> **Contexto:** Este Ã© o milestone de maior risco â€” deleta ~13.400 linhas de cÃ³digo AI em produÃ§Ã£o (~11.600 deletadas + ~2.700 simplificadas). A safety net Ã© o M4.9 (validaÃ§Ã£o de paridade) e o deploy strategy (blue-green ou canary). Rollback Ã© possÃ­vel revertendo o commit + `USE_PYTHON_AI=false`.

**Tasks:**

**Deletar packages/ai/ (~7.677 linhas):**
- [ ] Deletar diretÃ³rio `packages/ai/` inteiro
- [ ] Remover `@life-assistant/ai` do `pnpm-workspace.yaml`
- [ ] Remover dependÃªncias npm: `@anthropic-ai/sdk`, `@google/genai`, `zod-to-json-schema`
- [ ] Remover referÃªncias em `tsconfig` base

**Deletar tool executors do NestJS:**
- [ ] Deletar `tracking-tool-executor.service.ts` (~587L)
- [ ] Deletar `finance-tool-executor.service.ts` (~1.047L)
- [ ] Deletar `memory-tool-executor.service.ts` (~297L)
- [ ] Remover providers dos respectivos modules

**Deletar serviÃ§os AI do NestJS:**
- [ ] Deletar `confirmation-state.service.ts` (~475L)
- [ ] Deletar `context-builder.service.ts` (~337L)
- [ ] Deletar `contradiction-detector.adapter.ts` (~435L)

**Simplificar memory consolidation:**
- [ ] Remover lÃ³gica LLM do `memory-consolidation.processor.ts` (~557L)
- [ ] Manter apenas: BullMQ trigger â†’ HTTP POST para Python `/workers/consolidation`
- [ ] Resultado: ~50 linhas (de ~557)

**Simplificar chat.service.ts:**
- [ ] Remover lÃ³gica de tool loop TypeScript
- [ ] Remover imports de `@life-assistant/ai`
- [ ] Remover feature flag `USE_PYTHON_AI` (Python Ã© o Ãºnico caminho)
- [ ] Resultado: ~200 linhas (de ~1.232) â€” apenas: salvar msg do user + proxy HTTP/SSE para Python

**Simplificar chat.module.ts:**
- [ ] Remover providers de AI/tools/confirmation
- [ ] Manter apenas: ChatController, ChatService (proxy), ChatRepository, MessageRepository

**Atualizar monorepo:**
- [ ] Remover imports quebrados em todo o codebase
- [ ] Atualizar `CLAUDE.md` â€” remover referÃªncias a `packages/ai/`, adicionar `services/ai/`
- [ ] Atualizar `docs/specs/core/architecture.md` â€” nova arquitetura de 3 serviÃ§os

**Testes de regressÃ£o:**
- [ ] `pnpm typecheck` â€” sem erros de tipo
- [ ] `pnpm lint` â€” sem erros de lint
- [ ] `pnpm test` â€” todos os testes unitÃ¡rios passam
- [ ] `pnpm test:e2e` â€” todos os testes E2E passam (Playwright)
- [ ] Testes de paridade de M4.9 ainda passam

**Deploy produÃ§Ã£o:**
- [ ] Railway: criar serviÃ§o Python AI (Nixpacks, Python buildpack)
- [ ] Railway: configurar internal networking (`python-ai.railway.internal:8000`)
- [ ] Railway: configurar env vars (DATABASE_URL, GEMINI_API_KEY, SERVICE_SECRET)
- [ ] Deploy strategy: blue-green ou canary
- [ ] Monitoramento pÃ³s-deploy: 24-48h de observaÃ§Ã£o
- [ ] Verificar Sentry: sem novos erros no Python service
- [ ] Verificar logs: requests fluindo corretamente NestJS â†’ Python

**Definition of Done:**
- [ ] `packages/ai/` deletado (0 linhas)
- [ ] NestJS `chat.service.ts` Ã© ~200L de proxy (de ~1.232L)
- [ ] `pnpm typecheck && pnpm lint && pnpm test` passam
- [ ] `pnpm test:e2e` passa
- [ ] ProduÃ§Ã£o estÃ¡vel por 48h sem novos erros
- [ ] Total removido: **~11.600 linhas deletadas** + **~2.700 simplificadas** (~1.800 delta removido)

> **Riscos:**
> - RegressÃµes em edge cases de confirmaÃ§Ã£o (SSE event ordering diferente)
> - Imports quebrados em arquivos nÃ£o cobertos pelos testes
> - Performance em produÃ§Ã£o diferente de local (latÃªncia Railway internal networking)
> - Rollback plan: reverter commit + `USE_PYTHON_AI=false` no NestJS (requer que packages/ai/ ainda exista no git history)

---

## Resumo Quantitativo

| MÃ©trica | Valor |
|---|---|
| Milestones | 10 (M4.1 â€” M4.10) |
| Linhas deletadas do NestJS | **~11.600** (deletadas) + **~2.700** (simplificadas, ~1.800 delta removido) |
| Linhas adicionadas no NestJS | ~160 (proxy SSE + config + feature flag) |
| Novo cÃ³digo Python | **~5.000-7.000** (estimativa â€” Python mais conciso que TypeScript equivalente) |
| SQLAlchemy models | ~120-200 linhas (mapeamento passivo + CI check) |
| Pacote deletado | `packages/ai/` (**7.677 linhas**, 49 arquivos) |
| Novo diretÃ³rio | `services/ai/` (Python AI Service) |
| ServiÃ§os NestJS intactos | Auth, REST controllers, domain services, repositories, BullMQ (scheduler) |
| MudanÃ§as no frontend | Nenhuma (SSE events mantÃªm mesmo formato) |

### Estrutura do monorepo apÃ³s migraÃ§Ã£o

```
life-assistant/
â”œâ”€â”€ apps/
â”‚   â”œâ”€â”€ web/                    # Next.js (sem mudanÃ§as)
â”‚   â””â”€â”€ api/                    # NestJS (simplificado â€” sem AI code)
â”‚
â”œâ”€â”€ services/
â”‚   â””â”€â”€ ai/                     # Python AI Service (NOVO)
â”‚       â”œâ”€â”€ app/
â”‚       â”‚   â”œâ”€â”€ agents/         # LangGraph agents + graph
â”‚       â”‚   â”œâ”€â”€ api/            # FastAPI routes + middleware
â”‚       â”‚   â”œâ”€â”€ db/             # SQLAlchemy models + repositories
â”‚       â”‚   â”œâ”€â”€ memory/         # Contradiction detection
â”‚       â”‚   â”œâ”€â”€ prompts/        # System prompt + context builder
â”‚       â”‚   â”œâ”€â”€ tools/          # 20 tool implementations
â”‚       â”‚   â””â”€â”€ workers/        # Memory consolidation
â”‚       â”œâ”€â”€ tests/
â”‚       â”œâ”€â”€ pyproject.toml
â”‚       â””â”€â”€ Dockerfile
â”‚
â”œâ”€â”€ packages/
â”‚   â”œâ”€â”€ database/               # Drizzle schemas + migrations (source of truth)
â”‚   â”œâ”€â”€ config/                 # Zod config (NestJS)
â”‚   â””â”€â”€ shared/                 # Shared enums/constants
â”‚   # packages/ai/ â†’ DELETADO em M4.10
â”‚
â”œâ”€â”€ docs/
â”œâ”€â”€ infra/
â””â”€â”€ ...
```
